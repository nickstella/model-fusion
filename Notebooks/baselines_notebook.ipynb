{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alecabodi/ethz_model_fusion/.venv/lib/python3.11/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "/Users/alecabodi/ethz_model_fusion/.venv/lib/python3.11/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "/Users/alecabodi/ethz_model_fusion/.venv/lib/python3.11/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
      "/Users/alecabodi/ethz_model_fusion/.venv/lib/python3.11/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
      "/Users/alecabodi/ethz_model_fusion/.venv/lib/python3.11/site-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.nce_loss = AmdimNCELoss(tclip)\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Setting up parameters -------\n",
      "The parameters are: \n",
      " {'gpu_id': -1, 'debug': False, 'config_file': None, 'same_model': -1, 'load_models': '', 'eval_aligned': False, 'tensorboard': False, 'tensorboard_root': './tensorboard', 'to_download': True, 'disable_bias': True, 'dataset': 'cifar10', 'cifar_style_data': True, 'no_random_trainloaders': False, 'num_models': 2, 'model_name': 'resnet18_nobias_nobn', 'second_model_name': None, 'width_ratio': 1, 'handle_skips': True, 'n_epochs': 1, 'enable_dropout': False, 'batch_size_train': 32, 'batch_size_test': 32, 'learning_rate': 0.001, 'momentum': 0.5, 'log_interval': 100, 'retrain_epochs': 0, 'skip_retrain': -1, 'retrain_seed': -1, 'retrain_lr_decay': -1, 'retrain_lr_decay_factor': None, 'retrain_lr_decay_epochs': None, 'retrain_avg_only': False, 'retrain_geometric_only': False, 'reinit_trainloaders': False, 'deterministic': False, 'geom_ensemble_type': 'acts', 'exact': True, 'unbalanced': False, 'normalize_acts': False, 'normalize_wts': False, 'past_correction': True, 'activation_seed': 42, 'update_acts': False, 'activation_histograms': True, 'act_num_samples': 200, 'softmax_temperature': 1, 'activation_mode': None, 'activation_normalize': False, 'center_acts': False, 'skip_last_layer': True, 'skip_last_layer_type': 'average', 'prelu_acts': False, 'pool_acts': False, 'pool_relu': False, 'print_distances': False, 'importance': None, 'proper_marginals': False, 'correction': True, 'ground_metric': 'euclidean', 'ground_metric_normalize': 'log', 'not_squared': False, 'ground_metric_eff': False, 'dist_normalize': False, 'clip_gm': True, 'clip_min': 0, 'clip_max': 5, 'tmap_stats': False, 'ensemble_step': 0.5}\n",
      "------- Loading models -------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33macabodi\u001b[0m (\u001b[33mmodel-fusion\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/alecabodi/ethz_model_fusion/Notebooks/wandb/run-20231229_190319-qt1jdjpi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/model-fusion/ethz_model_fusion-Notebooks/runs/qt1jdjpi' target=\"_blank\">lucky-dew-18</a></strong> to <a href='https://wandb.ai/model-fusion/ethz_model_fusion-Notebooks' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/model-fusion/ethz_model_fusion-Notebooks' target=\"_blank\">https://wandb.ai/model-fusion/ethz_model_fusion-Notebooks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/model-fusion/ethz_model_fusion-Notebooks/runs/qt1jdjpi' target=\"_blank\">https://wandb.ai/model-fusion/ethz_model_fusion-Notebooks/runs/qt1jdjpi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-wcf4o6c8:v14, 1473.97MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:3.9\n",
      "/Users/alecabodi/ethz_model_fusion/.venv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'loss_module' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_module'])`.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-wcf4o6c8:v14, 1473.97MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:3.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading all the models\n",
      "------- Prediction based ensembling -------\n",
      "------- Naive ensembling of weights -------\n",
      "------- Evaluating models -------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alecabodi/ethz_model_fusion/.venv/lib/python3.11/site-packages/pytorch_lightning/loggers/wandb.py:395: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alecabodi/ethz_model_fusion/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.0800\n",
      "Testing DataLoader 0: 100%|██████████| 313/313 [01:32<00:00,  3.39it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        val_loss            1.0804282426834106\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>trainer/global_step</td><td>0</td></tr><tr><td>val_loss</td><td>1.08043</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lucky-dew-18</strong> at: <a href='https://wandb.ai/model-fusion/ethz_model_fusion-Notebooks/runs/qt1jdjpi' target=\"_blank\">https://wandb.ai/model-fusion/ethz_model_fusion-Notebooks/runs/qt1jdjpi</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231229_190319-qt1jdjpi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from Experiments import baselines_experiment\n",
    "from model_fusion.datasets import DataModuleType\n",
    "from model_fusion.models import ModelType\n",
    "from model_fusion.config import BASE_DATA_DIR\n",
    "\n",
    "batch_size = 32\n",
    "max_epochs = 1\n",
    "datamodule_type = DataModuleType.CIFAR10\n",
    "datamodule_hparams = {'batch_size': batch_size, 'data_dir': BASE_DATA_DIR}\n",
    "\n",
    "model_type = ModelType.VGG11\n",
    "model_hparams = {'num_classes': 10, 'num_channels': 3, 'bias': False}\n",
    "\n",
    "# same checkpoint for debugging purposes\n",
    "checkpointA = 'model-fusion/Model Fusion/model-wcf4o6c8:v14'\n",
    "checkpointB = 'model-fusion/Model Fusion/model-wcf4o6c8:v14'\n",
    "\n",
    "wandb_tag = \"baseline ensembles\"\n",
    "\n",
    "baselines_experiment.run_baselines(\n",
    "    batch_size=batch_size,\n",
    "    max_epochs=max_epochs,\n",
    "    datamodule_type=datamodule_type,\n",
    "    datamodule_hparams=datamodule_hparams,\n",
    "    model_type=model_type,\n",
    "    model_hparams=model_hparams,\n",
    "    checkpointA=checkpointA,\n",
    "    checkpointB=checkpointB,\n",
    "    wandb_tag=wandb_tag,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
