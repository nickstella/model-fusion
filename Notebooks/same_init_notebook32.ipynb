{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pl_bolts\\__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pl_bolts\\__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pl_bolts\\models\\self_supervised\\amdim\\amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pl_bolts\\models\\self_supervised\\amdim\\amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pl_bolts\\losses\\self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.nce_loss = AmdimNCELoss(tclip)\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "import torch\n",
    "import lightning\n",
    "import copy\n",
    "from pathlib import Path\n",
    "from model_fusion.config import BASE_DATA_DIR, CHECKPOINT_DIR\n",
    "from model_fusion.datasets import DataModuleType\n",
    "from model_fusion.models import ModelType\n",
    "from model_fusion.models.lightning import BaseModel\n",
    "from Experiments import lmc_experiment\n",
    "from model_fusion import lmc_utils\n",
    "from Experiments import baselines_experiment\n",
    "from Experiments import otfusion_experiment\n",
    "from Experiments import pyhessian_experiment\n",
    "from model_fusion.train import setup_training, setup_testing\n",
    "\n",
    "\n",
    "# set seed for numpy based calculations\n",
    "NUMPY_SEED = 100\n",
    "np.random.seed(NUMPY_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Loading models -------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.025, 'momentum': 0.9, 'optimizer': 'sgd', 'max_epochs': 200, 'min_epochs': 50, 'model_seed': 42, 'model_type': 'ModelType.RESNET18', 'loss_module': 'CrossEntropyLoss', 'lr_scheduler': 'plateau', 'weight_decay': 0.0001, 'model_hparams': {'bias': False, 'num_classes': 10, 'num_channels': 3}, 'early_stopping': True, 'datamodule_type': 'DataModuleType.CIFAR10', 'lr_decay_factor': 0.1, 'lightning_params': {'lr': 0.025, 'momentum': 0.9, 'optimizer': 'sgd', 'model_seed': 42, 'lr_scheduler': 'plateau', 'weight_decay': 0.0001, 'lr_decay_factor': 0.1, 'lr_monitor_metric': 'val_loss'}, 'lr_monitor_metric': 'val_loss', 'datamodule_hparams': {'seed': 42, 'data_dir': 'data', 'batch_size': 32, 'data_augmentation': True}, 'model_hparams/bias': False, 'model_hparams/num_classes': 10, 'model_hparams/num_channels': 3}\n",
      "{'seed': 42, 'data_dir': 'data', 'batch_size': 32, 'data_augmentation': False}\n",
      "{'bias': False, 'num_classes': 10, 'num_channels': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mframbelli\u001b[0m (\u001b[33mmodel-fusion\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\Notebooks\\wandb\\run-20240109_160953-90dnlajr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/model-fusion/model-fusion/runs/90dnlajr' target=\"_blank\">happy-dragon-136</a></strong> to <a href='https://wandb.ai/model-fusion/model-fusion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/model-fusion/model-fusion' target=\"_blank\">https://wandb.ai/model-fusion/model-fusion</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/model-fusion/model-fusion/runs/90dnlajr' target=\"_blank\">https://wandb.ai/model-fusion/model-fusion/runs/90dnlajr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-bbecqkxs:best_k, 85.20MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-uw0w0e3e:best_k, 85.20MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:5.0\n"
     ]
    }
   ],
   "source": [
    "print(\"------- Loading models -------\")\n",
    "\n",
    "# select wandb run names\n",
    "runA = 'bbecqkxs'\n",
    "runB = 'uw0w0e3e'#same init\n",
    "\n",
    "api = wandb.Api()\n",
    "run = api.run(f'model-fusion/Model Fusion/{runA}')\n",
    "\n",
    "print(run.config)\n",
    "\n",
    "batch_size = run.config['datamodule_hparams'].get('batch_size')\n",
    "\n",
    "datamodule_type_str = run.config['datamodule_type'].split('.')[1].lower()\n",
    "datamodule_type = DataModuleType(datamodule_type_str)\n",
    "datamodule_hparams = run.config['datamodule_hparams']\n",
    "datamodule_hparams['data_augmentation'] = False\n",
    "\n",
    "model_type_str = run.config['model_type'].split('.')[1].lower()\n",
    "model_type = ModelType(model_type_str)\n",
    "\n",
    "model_hparams = run.config['model_hparams']\n",
    "\n",
    "print(datamodule_hparams)\n",
    "print(model_hparams)\n",
    "\n",
    "checkpointA = f'model-fusion/Model Fusion/model-{runA}:best_k'\n",
    "checkpointB = f'model-fusion/Model Fusion/model-{runB}:best_k'\n",
    "\n",
    "run = wandb.init()\n",
    "\n",
    "artifact = run.use_artifact(checkpointA, type='model')\n",
    "artifact_dir = artifact.download(root=CHECKPOINT_DIR)\n",
    "modelA = BaseModel.load_from_checkpoint(Path(artifact_dir)/\"model.ckpt\")\n",
    "\n",
    "artifact = run.use_artifact(checkpointB, type='model')\n",
    "artifact_dir = artifact.download(root=CHECKPOINT_DIR)\n",
    "modelB = BaseModel.load_from_checkpoint(Path(artifact_dir)/\"model.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Computing LMC barrier before alignment-------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Alpha: 0.00 (model 2), Train average loss: 0.06414 Train barrier:  0\n",
      "Alpha: 1.00 (model 1), Train average loss: 0.05230 Train barrier:  0\n",
      "Alpha: 0.05, Train average loss: 0.06797 Train barrier 0.004422431013319225\n",
      "Alpha: 0.10, Train average loss: 0.09279 Train barrier 0.02982961874008179\n",
      "Alpha: 0.15, Train average loss: 0.15056 Train barrier 0.08819919179677964\n",
      "Alpha: 0.20, Train average loss: 0.25939 Train barrier 0.19761568625503115\n",
      "Alpha: 0.25, Train average loss: 0.43492 Train barrier 0.37373842813836206\n",
      "Alpha: 0.30, Train average loss: 0.67574 Train barrier 0.6151541226863861\n",
      "Alpha: 0.35, Train average loss: 0.94946 Train barrier 0.8894601447727944\n",
      "Alpha: 0.40, Train average loss: 1.19807 Train barrier 1.1386674537261328\n",
      "Alpha: 0.45, Train average loss: 1.36940 Train barrier 1.3105919216116269\n",
      "Alpha: 0.50, Train average loss: 1.43791 Train barrier 1.379688645945655\n",
      "Alpha: 0.55, Train average loss: 1.39764 Train barrier 1.3400118963493242\n",
      "Alpha: 0.60, Train average loss: 1.25274 Train barrier 1.195699727373653\n",
      "Alpha: 0.65, Train average loss: 1.02298 Train barrier 0.9665405332048734\n",
      "Alpha: 0.70, Train average loss: 0.75372 Train barrier 0.6978682493580712\n",
      "Alpha: 0.75, Train average loss: 0.50264 Train barrier 0.4473752247585191\n",
      "Alpha: 0.80, Train average loss: 0.30859 Train barrier 0.25391917884879645\n",
      "Alpha: 0.85, Train average loss: 0.18022 Train barrier 0.12614762905041377\n",
      "Alpha: 0.90, Train average loss: 0.10555 Train barrier 0.05206808259487152\n",
      "Alpha: 0.95, Train average loss: 0.06742 Train barrier 0.014530540457036757\n",
      "Loss model 1: 0.05230, Loss model 2: 0.06414, Alpha argmax: 0.50000\n",
      "Barrier: 1.37969\n"
     ]
    }
   ],
   "source": [
    "# LMC barrier\n",
    "print(\"------- Computing LMC barrier before alignment-------\")\n",
    "\n",
    "lmc_experiment.run_lmc(\n",
    "    datamodule_type=datamodule_type,\n",
    "    modelA=modelA,\n",
    "    modelB=modelB,\n",
    "    granularity=21\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Computing baselines -------\n",
      "------- Prediction based ensembling -------\n",
      "------- Naive ensembling of weights -------\n",
      "------- Evaluating baselines -------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:395: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Evaluating base models -------\n",
      "Testing DataLoader 0: 100%|██████████| 10/10 [00:02<00:00,  3.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy           0.906499981880188\n",
      "        val_loss            0.37029629945755005\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Testing DataLoader 0: 100%|██████████| 10/10 [00:02<00:00,  4.19it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy           0.91239994764328\n",
      "        val_loss            0.3800816833972931\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "------- Evaluating prediction ensembling -------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.3059, Accuracy: 92.10%\n",
      "------- Evaluating vanilla averaging -------\n",
      "Testing DataLoader 0: 100%|██████████| 10/10 [00:03<00:00,  2.99it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy          0.5575000047683716\n",
      "        val_loss            1.4506338834762573\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁</td></tr><tr><td>val_accuracy</td><td>██▁</td></tr><tr><td>val_loss</td><td>▁▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>trainer/global_step</td><td>0</td></tr><tr><td>val_accuracy</td><td>0.5575</td></tr><tr><td>val_loss</td><td>1.45063</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">happy-dragon-136</strong> at: <a href='https://wandb.ai/model-fusion/model-fusion/runs/90dnlajr' target=\"_blank\">https://wandb.ai/model-fusion/model-fusion/runs/90dnlajr</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240109_160953-90dnlajr\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Baselines (prediction ensembling, vanilla averaging)\n",
    "print(\"------- Computing baselines -------\")\n",
    "\n",
    "wandb_tag = f'baselines-{runA}-{runB}'\n",
    "\n",
    "vanilla_averaging_model = baselines_experiment.run_baselines(\n",
    "    datamodule_type=datamodule_type,\n",
    "    datamodule_hparams=datamodule_hparams,\n",
    "    model_type=model_type,\n",
    "    model_hparams=model_hparams,\n",
    "    modelA=modelA,\n",
    "    modelB=modelB,\n",
    "    wandb_tag=wandb_tag,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Computing model fusion -------\n",
      "------- Setting up parameters -------\n",
      "{'seed': 42, 'data_dir': 'data', 'batch_size': 32, 'data_augmentation': False}\n",
      "The parameters are: \n",
      " {'eval_aligned': True, 'num_models': 2, 'width_ratio': 1, 'handle_skips': True, 'exact': True, 'activation_seed': 21, 'activation_histograms': True, 'ground_metric': 'euclidean', 'ground_metric_normalize': 'none', 'same_model': False, 'geom_ensemble_type': 'acts', 'act_num_samples': 200, 'skip_last_layer': False, 'skip_last_layer_type': 'average', 'softmax_temperature': 1, 'past_correction': True, 'correction': True, 'normalize_acts': False, 'normalize_wts': False, 'activation_normalize': False, 'center_acts': False, 'prelu_acts': False, 'pool_acts': False, 'pool_relu': False, 'importance': None, 'proper_marginals': False, 'not_squared': True, 'ground_metric_eff': False, 'dist_normalize': False, 'clip_gm': False, 'clip_min': 0, 'clip_max': 5, 'tmap_stats': False, 'ensemble_step': 0.5, 'reg': 0.01}\n",
      "------- OT model fusion -------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Computing activations\n",
      "this was continued,  \n",
      "this was continued,  loss_module\n",
      "this was continued,  accuracy\n",
      "this was continued,  model\n",
      "set forward hook for layer named:  model.conv1\n",
      "this was continued,  model.bn1\n",
      "this was continued,  model.layer1\n",
      "this was continued,  model.layer1.0\n",
      "set forward hook for layer named:  model.layer1.0.conv1\n",
      "this was continued,  model.layer1.0.bn1\n",
      "set forward hook for layer named:  model.layer1.0.conv2\n",
      "this was continued,  model.layer1.0.bn2\n",
      "this was continued,  model.layer1.0.shortcut\n",
      "this was continued,  model.layer1.1\n",
      "set forward hook for layer named:  model.layer1.1.conv1\n",
      "this was continued,  model.layer1.1.bn1\n",
      "set forward hook for layer named:  model.layer1.1.conv2\n",
      "this was continued,  model.layer1.1.bn2\n",
      "this was continued,  model.layer1.1.shortcut\n",
      "this was continued,  model.layer2\n",
      "this was continued,  model.layer2.0\n",
      "set forward hook for layer named:  model.layer2.0.conv1\n",
      "this was continued,  model.layer2.0.bn1\n",
      "set forward hook for layer named:  model.layer2.0.conv2\n",
      "this was continued,  model.layer2.0.bn2\n",
      "this was continued,  model.layer2.0.shortcut\n",
      "set forward hook for layer named:  model.layer2.0.shortcut.0\n",
      "this was continued,  model.layer2.0.shortcut.1\n",
      "this was continued,  model.layer2.1\n",
      "set forward hook for layer named:  model.layer2.1.conv1\n",
      "this was continued,  model.layer2.1.bn1\n",
      "set forward hook for layer named:  model.layer2.1.conv2\n",
      "this was continued,  model.layer2.1.bn2\n",
      "this was continued,  model.layer2.1.shortcut\n",
      "this was continued,  model.layer3\n",
      "this was continued,  model.layer3.0\n",
      "set forward hook for layer named:  model.layer3.0.conv1\n",
      "this was continued,  model.layer3.0.bn1\n",
      "set forward hook for layer named:  model.layer3.0.conv2\n",
      "this was continued,  model.layer3.0.bn2\n",
      "this was continued,  model.layer3.0.shortcut\n",
      "set forward hook for layer named:  model.layer3.0.shortcut.0\n",
      "this was continued,  model.layer3.0.shortcut.1\n",
      "this was continued,  model.layer3.1\n",
      "set forward hook for layer named:  model.layer3.1.conv1\n",
      "this was continued,  model.layer3.1.bn1\n",
      "set forward hook for layer named:  model.layer3.1.conv2\n",
      "this was continued,  model.layer3.1.bn2\n",
      "this was continued,  model.layer3.1.shortcut\n",
      "this was continued,  model.layer4\n",
      "this was continued,  model.layer4.0\n",
      "set forward hook for layer named:  model.layer4.0.conv1\n",
      "this was continued,  model.layer4.0.bn1\n",
      "set forward hook for layer named:  model.layer4.0.conv2\n",
      "this was continued,  model.layer4.0.bn2\n",
      "this was continued,  model.layer4.0.shortcut\n",
      "set forward hook for layer named:  model.layer4.0.shortcut.0\n",
      "this was continued,  model.layer4.0.shortcut.1\n",
      "this was continued,  model.layer4.1\n",
      "set forward hook for layer named:  model.layer4.1.conv1\n",
      "this was continued,  model.layer4.1.bn1\n",
      "set forward hook for layer named:  model.layer4.1.conv2\n",
      "this was continued,  model.layer4.1.bn2\n",
      "this was continued,  model.layer4.1.shortcut\n",
      "set forward hook for layer named:  model.fc\n",
      "this was continued,  \n",
      "this was continued,  loss_module\n",
      "this was continued,  accuracy\n",
      "this was continued,  model\n",
      "set forward hook for layer named:  model.conv1\n",
      "this was continued,  model.bn1\n",
      "this was continued,  model.layer1\n",
      "this was continued,  model.layer1.0\n",
      "set forward hook for layer named:  model.layer1.0.conv1\n",
      "this was continued,  model.layer1.0.bn1\n",
      "set forward hook for layer named:  model.layer1.0.conv2\n",
      "this was continued,  model.layer1.0.bn2\n",
      "this was continued,  model.layer1.0.shortcut\n",
      "this was continued,  model.layer1.1\n",
      "set forward hook for layer named:  model.layer1.1.conv1\n",
      "this was continued,  model.layer1.1.bn1\n",
      "set forward hook for layer named:  model.layer1.1.conv2\n",
      "this was continued,  model.layer1.1.bn2\n",
      "this was continued,  model.layer1.1.shortcut\n",
      "this was continued,  model.layer2\n",
      "this was continued,  model.layer2.0\n",
      "set forward hook for layer named:  model.layer2.0.conv1\n",
      "this was continued,  model.layer2.0.bn1\n",
      "set forward hook for layer named:  model.layer2.0.conv2\n",
      "this was continued,  model.layer2.0.bn2\n",
      "this was continued,  model.layer2.0.shortcut\n",
      "set forward hook for layer named:  model.layer2.0.shortcut.0\n",
      "this was continued,  model.layer2.0.shortcut.1\n",
      "this was continued,  model.layer2.1\n",
      "set forward hook for layer named:  model.layer2.1.conv1\n",
      "this was continued,  model.layer2.1.bn1\n",
      "set forward hook for layer named:  model.layer2.1.conv2\n",
      "this was continued,  model.layer2.1.bn2\n",
      "this was continued,  model.layer2.1.shortcut\n",
      "this was continued,  model.layer3\n",
      "this was continued,  model.layer3.0\n",
      "set forward hook for layer named:  model.layer3.0.conv1\n",
      "this was continued,  model.layer3.0.bn1\n",
      "set forward hook for layer named:  model.layer3.0.conv2\n",
      "this was continued,  model.layer3.0.bn2\n",
      "this was continued,  model.layer3.0.shortcut\n",
      "set forward hook for layer named:  model.layer3.0.shortcut.0\n",
      "this was continued,  model.layer3.0.shortcut.1\n",
      "this was continued,  model.layer3.1\n",
      "set forward hook for layer named:  model.layer3.1.conv1\n",
      "this was continued,  model.layer3.1.bn1\n",
      "set forward hook for layer named:  model.layer3.1.conv2\n",
      "this was continued,  model.layer3.1.bn2\n",
      "this was continued,  model.layer3.1.shortcut\n",
      "this was continued,  model.layer4\n",
      "this was continued,  model.layer4.0\n",
      "set forward hook for layer named:  model.layer4.0.conv1\n",
      "this was continued,  model.layer4.0.bn1\n",
      "set forward hook for layer named:  model.layer4.0.conv2\n",
      "this was continued,  model.layer4.0.bn2\n",
      "this was continued,  model.layer4.0.shortcut\n",
      "set forward hook for layer named:  model.layer4.0.shortcut.0\n",
      "this was continued,  model.layer4.0.shortcut.1\n",
      "this was continued,  model.layer4.1\n",
      "set forward hook for layer named:  model.layer4.1.conv1\n",
      "this was continued,  model.layer4.1.bn1\n",
      "set forward hook for layer named:  model.layer4.1.conv2\n",
      "this was continued,  model.layer4.1.bn2\n",
      "this was continued,  model.layer4.1.shortcut\n",
      "set forward hook for layer named:  model.fc\n",
      "Activations computed across 200 samples out of 45000\n",
      "***********\n",
      "min of act: -13.026793479919434, max: 12.658839225769043, mean: -0.011049232445657253\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 12.658839225769043, mean: 0.34468042850494385\n",
      "***********\n",
      "min of act: -45.22306442260742, max: 14.352783203125, mean: -3.4580273628234863\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 14.352783203125, mean: 0.008328213356435299\n",
      "***********\n",
      "min of act: -7.304907321929932, max: 11.420360565185547, mean: 0.2823680341243744\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 11.420360565185547, mean: 0.3249450623989105\n",
      "***********\n",
      "min of act: -38.53377151489258, max: 12.634749412536621, mean: -4.005962371826172\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 12.634749412536621, mean: 0.010698075406253338\n",
      "***********\n",
      "min of act: -8.301993370056152, max: 12.032195091247559, mean: 0.21421976387500763\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 12.032195091247559, mean: 0.29388222098350525\n",
      "***********\n",
      "min of act: -46.63582992553711, max: 33.3905029296875, mean: -1.7405743598937988\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 33.3905029296875, mean: 0.3049854040145874\n",
      "***********\n",
      "min of act: -71.04664611816406, max: 55.62591552734375, mean: -2.255397081375122\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 55.62591552734375, mean: 0.8692861795425415\n",
      "***********\n",
      "min of act: -10.31888198852539, max: 13.215635299682617, mean: 0.05767606571316719\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 13.215635299682617, mean: 0.381287157535553\n",
      "***********\n",
      "min of act: -112.18091583251953, max: 70.82884216308594, mean: -10.714159965515137\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 70.82884216308594, mean: 0.05492167919874191\n",
      "***********\n",
      "min of act: -38.31587600708008, max: 74.54537963867188, mean: 0.13982723653316498\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 74.54537963867188, mean: 0.7429721355438232\n",
      "***********\n",
      "min of act: -118.89129638671875, max: 102.9465560913086, mean: -6.734028339385986\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 102.9465560913086, mean: 0.5499641299247742\n",
      "***********\n",
      "min of act: -132.30538940429688, max: 181.24139404296875, mean: -7.196269512176514\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 181.24139404296875, mean: 1.1007720232009888\n",
      "***********\n",
      "min of act: -35.06045913696289, max: 47.8276481628418, mean: -1.1339137554168701\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 47.8276481628418, mean: 0.6998069286346436\n",
      "***********\n",
      "min of act: -190.14639282226562, max: 175.56961059570312, mean: -16.45050811767578\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 175.56961059570312, mean: 0.31269580125808716\n",
      "***********\n",
      "min of act: -98.90692138671875, max: 135.78260803222656, mean: -3.881181240081787\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 135.78260803222656, mean: 0.7402786016464233\n",
      "***********\n",
      "min of act: -126.8451919555664, max: 145.42166137695312, mean: -6.850537300109863\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 145.42166137695312, mean: 0.6469621062278748\n",
      "***********\n",
      "min of act: -247.1476593017578, max: 186.6340789794922, mean: -10.058123588562012\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 186.6340789794922, mean: 0.5912513136863708\n",
      "***********\n",
      "min of act: -52.54418182373047, max: 53.638397216796875, mean: -1.7984520196914673\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 53.638397216796875, mean: 0.34126004576683044\n",
      "***********\n",
      "min of act: -133.46449279785156, max: 81.48041534423828, mean: -3.174445152282715\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 81.48041534423828, mean: 0.41496211290359497\n",
      "***********\n",
      "min of act: -98.95993041992188, max: 153.10983276367188, mean: -5.541122913360596\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 153.10983276367188, mean: 0.2872031033039093\n",
      "***********\n",
      "min of act: -32.613067626953125, max: 91.81171417236328, mean: 0.02171914651989937\n",
      "***********\n",
      "min of act: -12.916267395019531, max: 13.502442359924316, mean: -0.01165253296494484\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 13.502442359924316, mean: 0.3496991693973541\n",
      "***********\n",
      "min of act: -43.82094955444336, max: 11.761809349060059, mean: -3.427093744277954\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 11.761809349060059, mean: 0.005547544453293085\n",
      "***********\n",
      "min of act: -5.404383182525635, max: 13.043869018554688, mean: 0.3119508624076843\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 13.043869018554688, mean: 0.3374182879924774\n",
      "***********\n",
      "min of act: -38.04118347167969, max: 17.86797523498535, mean: -4.639275550842285\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 17.86797523498535, mean: 0.010016705840826035\n",
      "***********\n",
      "min of act: -8.312494277954102, max: 13.511011123657227, mean: 0.2429351657629013\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 13.511011123657227, mean: 0.3119793236255646\n",
      "***********\n",
      "min of act: -48.171077728271484, max: 33.09108352661133, mean: -2.1065235137939453\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 33.09108352661133, mean: 0.31392666697502136\n",
      "***********\n",
      "min of act: -79.68777465820312, max: 60.909942626953125, mean: -2.7916476726531982\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 60.909942626953125, mean: 0.8431521058082581\n",
      "***********\n",
      "min of act: -10.260477066040039, max: 18.96763038635254, mean: 0.0017357559408992529\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 18.96763038635254, mean: 0.37484923005104065\n",
      "***********\n",
      "min of act: -132.2325897216797, max: 80.96463012695312, mean: -11.356393814086914\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 80.96463012695312, mean: 0.052599892020225525\n",
      "***********\n",
      "min of act: -46.2180290222168, max: 76.0321273803711, mean: 0.07578957825899124\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 76.0321273803711, mean: 0.723814070224762\n",
      "***********\n",
      "min of act: -106.06584930419922, max: 83.68338775634766, mean: -7.2258124351501465\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 83.68338775634766, mean: 0.5728010535240173\n",
      "***********\n",
      "min of act: -144.89048767089844, max: 163.80662536621094, mean: -8.223355293273926\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 163.80662536621094, mean: 1.1693353652954102\n",
      "***********\n",
      "min of act: -32.00057601928711, max: 40.89030456542969, mean: -1.1347635984420776\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 40.89030456542969, mean: 0.6450931429862976\n",
      "***********\n",
      "min of act: -205.33851623535156, max: 183.10635375976562, mean: -20.074995040893555\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 183.10635375976562, mean: 0.3069598972797394\n",
      "***********\n",
      "min of act: -91.2252426147461, max: 192.8799591064453, mean: -4.009257793426514\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 192.8799591064453, mean: 0.8169814348220825\n",
      "***********\n",
      "min of act: -137.48782348632812, max: 163.8905029296875, mean: -8.38919448852539\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 163.8905029296875, mean: 0.6955726146697998\n",
      "***********\n",
      "min of act: -167.05856323242188, max: 189.51620483398438, mean: -11.403769493103027\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 189.51620483398438, mean: 0.6903318762779236\n",
      "***********\n",
      "min of act: -43.0443000793457, max: 74.15506744384766, mean: -2.1302340030670166\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 74.15506744384766, mean: 0.36267367005348206\n",
      "***********\n",
      "min of act: -182.62423706054688, max: 74.37660217285156, mean: -3.93129825592041\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 74.37660217285156, mean: 0.4735964238643646\n",
      "***********\n",
      "min of act: -143.30712890625, max: 205.41456604003906, mean: -7.022397518157959\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 205.41456604003906, mean: 0.32007652521133423\n",
      "***********\n",
      "min of act: -30.12851333618164, max: 89.45350646972656, mean: 0.008724547922611237\n",
      "activations for idx 1 at layer model.fc have the following shape  torch.Size([200, 1, 10])\n",
      "-----------\n",
      "INIT\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 0 ------------- \n",
      " \n",
      "Previous layer shape is  None\n",
      "In layer model.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 12.999646186828613, Mean : 4.176920413970947, Min : 0.5832949280738831, Std: 2.1149747371673584\n",
      "At layer idx 0 and shape torch.Size([64, 3, 3, 3]), the OT cost is  162.12124693393707\n",
      "Tmap stats (before correction) \n",
      ": For layer model.conv1.weight, frobenius norm from the joe's transport map is 0.12401959300041199\n",
      "shape of T_var is  torch.Size([64, 64])\n",
      "T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0156, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0156,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0156, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0156, 0.0000],\n",
      "        [0.0156, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var stats: max 0.9999935626983643, min 0.0, mean 0.015624897554516792, std 0.12403393536806107 \n",
      "the transport map is  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "Shape of aligned wt is  torch.Size([64, 3, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 1 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([64, 3, 3, 3])\n",
      "In layer model.layer1.0.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 4.025468349456787, Mean : 0.3005621135234833, Min : 7.1889594437379856e-06, Std: 0.608890175819397\n",
      "At layer idx 1 and shape torch.Size([64, 64, 3, 3]), the OT cost is  40.33973130543018\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer1.0.conv1.weight, frobenius norm from the joe's transport map is 0.12401959300041199\n",
      "shape of T_var is  torch.Size([64, 64])\n",
      "T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0156, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var stats: max 0.9999935626983643, min 0.0, mean 0.015624897554516792, std 0.12403393536806107 \n",
      "the transport map is  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "Shape of aligned wt is  torch.Size([64, 64, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 2 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([64, 64, 3, 3])\n",
      "In layer model.layer1.0.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 12.165878295898438, Mean : 4.000954627990723, Min : 0.5830835103988647, Std: 1.998805284500122\n",
      "At layer idx 2 and shape torch.Size([64, 64, 3, 3]), the OT cost is  173.37178027629852\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer1.0.conv2.weight, frobenius norm from the joe's transport map is 0.12401959300041199\n",
      "shape of T_var is  torch.Size([64, 64])\n",
      "T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0156, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0156,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0156, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0156, 0.0000],\n",
      "        [0.0156, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var stats: max 0.9999935626983643, min 0.0, mean 0.015624897554516792, std 0.12403393536806107 \n",
      "the transport map is  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "Shape of aligned wt is  torch.Size([64, 64, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 3 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([64, 64, 3, 3])\n",
      "In layer model.layer1.1.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 6.178369522094727, Mean : 0.45318418741226196, Min : 0.0, Std: 0.9279011487960815\n",
      "At layer idx 3 and shape torch.Size([64, 64, 3, 3]), the OT cost is  68.29107849572028\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer1.1.conv1.weight, frobenius norm from the joe's transport map is 0.12401959300041199\n",
      "shape of T_var is  torch.Size([64, 64])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999935626983643, min 0.0, mean 0.015624897554516792, std 0.12403393536806107 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([64, 64, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 4 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([64, 64, 3, 3])\n",
      "In layer model.layer1.1.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 11.635408401489258, Mean : 3.819423198699951, Min : 0.541092038154602, Std: 1.9281681776046753\n",
      "At layer idx 4 and shape torch.Size([64, 64, 3, 3]), the OT cost is  183.6422199010849\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer1.1.conv2.weight, frobenius norm from the joe's transport map is 0.12401959300041199\n",
      "shape of T_var is  torch.Size([64, 64])\n",
      "T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0156, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0156,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0156, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0156, 0.0000],\n",
      "        [0.0156, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var stats: max 0.9999935626983643, min 0.0, mean 0.015624897554516792, std 0.12403393536806107 \n",
      "the transport map is  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "Shape of aligned wt is  torch.Size([64, 64, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 5 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([64, 64, 3, 3])\n",
      "In layer model.layer2.0.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 18.422622680664062, Mean : 4.516233921051025, Min : 0.06853015720844269, Std: 3.2619361877441406\n",
      "At layer idx 5 and shape torch.Size([128, 64, 3, 3]), the OT cost is  194.2560370862484\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer2.0.conv1.weight, frobenius norm from the joe's transport map is 0.08804240077733994\n",
      "shape of T_var is  torch.Size([128, 128])\n",
      "T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0078, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var stats: max 0.9999872446060181, min 0.0, mean 0.007812399882823229, std 0.08804396539926529 \n",
      "the transport map is  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "Shape of aligned wt is  torch.Size([128, 64, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 6 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([128, 64, 3, 3])\n",
      "In layer model.layer2.0.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 36.12409973144531, Mean : 9.998276710510254, Min : 0.36357325315475464, Std: 6.236356258392334\n",
      "At layer idx 6 and shape torch.Size([128, 128, 3, 3]), the OT cost is  497.1939529180527\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer2.0.conv2.weight, frobenius norm from the joe's transport map is 0.08804240077733994\n",
      "shape of T_var is  torch.Size([128, 128])\n",
      "T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0078,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0078, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var stats: max 0.9999872446060181, min 0.0, mean 0.007812399882823229, std 0.08804396539926529 \n",
      "the transport map is  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "Shape of aligned wt is  torch.Size([128, 128, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 7 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([128, 128, 3, 3])\n",
      "In layer model.layer2.0.shortcut.0.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 9.940409660339355, Mean : 3.1056880950927734, Min : 0.38520386815071106, Std: 1.7438145875930786\n",
      "At layer idx 7 and shape torch.Size([128, 64, 1, 1]), the OT cost is  85.93848996569432\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer2.0.shortcut.0.weight, frobenius norm from the joe's transport map is 0.08804240077733994\n",
      "shape of T_var is  torch.Size([128, 128])\n",
      "T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0078,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var stats: max 0.9999872446060181, min 0.0, mean 0.007812399882823229, std 0.08804396539926529 \n",
      "the transport map is  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "Shape of aligned wt is  torch.Size([128, 64, 1])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 8 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([128, 64, 1, 1])\n",
      "In layer model.layer2.1.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 19.831584930419922, Mean : 1.2629036903381348, Min : 1.9419770978856832e-05, Std: 2.801126003265381\n",
      "averaging multiple T_var's\n",
      "At layer idx 8 and shape torch.Size([128, 128, 3, 3]), the OT cost is  151.15742485621013\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer2.1.conv1.weight, frobenius norm from the joe's transport map is 0.08804240077733994\n",
      "shape of T_var is  torch.Size([128, 128])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999872446060181, min 0.0, mean 0.007812399882823229, std 0.08804396539926529 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([128, 128, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 9 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([128, 128, 3, 3])\n",
      "In layer model.layer2.1.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 33.68712615966797, Mean : 8.909236907958984, Min : 0.28225505352020264, Std: 5.822738170623779\n",
      "At layer idx 9 and shape torch.Size([128, 128, 3, 3]), the OT cost is  464.170107960701\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer2.1.conv2.weight, frobenius norm from the joe's transport map is 0.08804240077733994\n",
      "shape of T_var is  torch.Size([128, 128])\n",
      "T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0078,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0078, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var stats: max 0.9999872446060181, min 0.0, mean 0.007812399882823229, std 0.08804396539926529 \n",
      "the transport map is  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "Shape of aligned wt is  torch.Size([128, 128, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 10 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([128, 128, 3, 3])\n",
      "In layer model.layer3.0.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 34.51148986816406, Mean : 5.864948272705078, Min : 0.0007740282453596592, Std: 6.147965431213379\n",
      "At layer idx 10 and shape torch.Size([256, 128, 3, 3]), the OT cost is  267.6818543653935\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer3.0.conv1.weight, frobenius norm from the joe's transport map is 0.06237781047821045\n",
      "shape of T_var is  torch.Size([256, 256])\n",
      "T_var before correction  tensor([[0.0039, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var after correction  tensor([[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237668916583061 \n",
      "the transport map is  tensor([[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "Shape of aligned wt is  torch.Size([256, 128, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 11 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([256, 128, 3, 3])\n",
      "In layer model.layer3.0.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 53.13702392578125, Mean : 10.353221893310547, Min : 0.003798169083893299, Std: 9.329266548156738\n",
      "At layer idx 11 and shape torch.Size([256, 256, 3, 3]), the OT cost is  456.7113423794508\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer3.0.conv2.weight, frobenius norm from the joe's transport map is 0.06237781047821045\n",
      "shape of T_var is  torch.Size([256, 256])\n",
      "T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0039, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237668916583061 \n",
      "the transport map is  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "Shape of aligned wt is  torch.Size([256, 256, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 12 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([256, 256, 3, 3])\n",
      "In layer model.layer3.0.shortcut.0.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 19.149009704589844, Mean : 4.822330474853516, Min : 0.14344774186611176, Std: 3.4128029346466064\n",
      "At layer idx 12 and shape torch.Size([256, 128, 1, 1]), the OT cost is  145.83111761230975\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer3.0.shortcut.0.weight, frobenius norm from the joe's transport map is 0.06237781047821045\n",
      "shape of T_var is  torch.Size([256, 256])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237668916583061 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([256, 128, 1])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 13 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([256, 128, 1, 1])\n",
      "In layer model.layer3.1.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 43.228267669677734, Mean : 3.747617244720459, Min : 1.374277508148225e-05, Std: 6.611489295959473\n",
      "averaging multiple T_var's\n",
      "At layer idx 13 and shape torch.Size([256, 256, 3, 3]), the OT cost is  274.1669131089002\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer3.1.conv1.weight, frobenius norm from the joe's transport map is 0.06237781047821045\n",
      "shape of T_var is  torch.Size([256, 256])\n",
      "T_var before correction  tensor([[0.0000, 0.0039, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0039, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var after correction  tensor([[0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237668916583061 \n",
      "the transport map is  tensor([[0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "Shape of aligned wt is  torch.Size([256, 256, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 14 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([256, 256, 3, 3])\n",
      "In layer model.layer3.1.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 51.76500701904297, Mean : 7.795782089233398, Min : 0.0016229720786213875, Std: 8.607612609863281\n",
      "At layer idx 14 and shape torch.Size([256, 256, 3, 3]), the OT cost is  404.6029357910156\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer3.1.conv2.weight, frobenius norm from the joe's transport map is 0.06237781047821045\n",
      "shape of T_var is  torch.Size([256, 256])\n",
      "T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0039, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237668916583061 \n",
      "the transport map is  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "Shape of aligned wt is  torch.Size([256, 256, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 15 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([256, 256, 3, 3])\n",
      "In layer model.layer4.0.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 38.349727630615234, Mean : 4.2213311195373535, Min : 3.865910002787132e-06, Std: 6.080348968505859\n",
      "At layer idx 15 and shape torch.Size([512, 256, 3, 3]), the OT cost is  174.91532134450972\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer4.0.conv1.weight, frobenius norm from the joe's transport map is 0.04415099322795868\n",
      "shape of T_var is  torch.Size([512, 512])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999488592147827, min 0.0, mean 0.0019530251156538725, std 0.044148821383714676 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([512, 256, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 16 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([512, 256, 3, 3])\n",
      "In layer model.layer4.0.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 45.17051696777344, Mean : 4.158454895019531, Min : 3.106380518147489e-06, Std: 6.939640998840332\n",
      "At layer idx 16 and shape torch.Size([512, 512, 3, 3]), the OT cost is  189.10909670218825\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer4.0.conv2.weight, frobenius norm from the joe's transport map is 0.04415099322795868\n",
      "shape of T_var is  torch.Size([512, 512])\n",
      "T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0020]])\n",
      "T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.9999]])\n",
      "T_var stats: max 0.9999488592147827, min 0.0, mean 0.0019530252320691943, std 0.044148821383714676 \n",
      "the transport map is  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.9999]])\n",
      "Shape of aligned wt is  torch.Size([512, 512, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 17 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([512, 512, 3, 3])\n",
      "In layer model.layer4.0.shortcut.0.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 13.182197570800781, Mean : 1.937320351600647, Min : 0.015680570155382156, Std: 2.1486306190490723\n",
      "At layer idx 17 and shape torch.Size([512, 256, 1, 1]), the OT cost is  64.68852282315493\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer4.0.shortcut.0.weight, frobenius norm from the joe's transport map is 0.04415099322795868\n",
      "shape of T_var is  torch.Size([512, 512])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999488592147827, min 0.0, mean 0.0019530252320691943, std 0.044148821383714676 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([512, 256, 1])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 18 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([512, 256, 1, 1])\n",
      "In layer model.layer4.1.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 21.521656036376953, Mean : 2.5919747352600098, Min : 0.0005674413405358791, Std: 3.4141833782196045\n",
      "averaging multiple T_var's\n",
      "At layer idx 18 and shape torch.Size([512, 512, 3, 3]), the OT cost is  99.7817602828145\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer4.1.conv1.weight, frobenius norm from the joe's transport map is 0.04415099322795868\n",
      "shape of T_var is  torch.Size([512, 512])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999488592147827, min 0.0, mean 0.0019530252320691943, std 0.044148821383714676 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([512, 512, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 19 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([512, 512, 3, 3])\n",
      "In layer model.layer4.1.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 36.709625244140625, Mean : 2.1584017276763916, Min : 0.0, Std: 5.117686748504639\n",
      "At layer idx 19 and shape torch.Size([512, 512, 3, 3]), the OT cost is  134.7834890000522\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer4.1.conv2.weight, frobenius norm from the joe's transport map is 0.04415099322795868\n",
      "shape of T_var is  torch.Size([512, 512])\n",
      "T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0020]])\n",
      "T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.9999]])\n",
      "T_var stats: max 0.9999488592147827, min 0.0, mean 0.0019530252320691943, std 0.044148821383714676 \n",
      "the transport map is  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.9999]])\n",
      "Shape of aligned wt is  torch.Size([512, 512, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 20 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([512, 512, 3, 3])\n",
      "In layer model.fc.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 296.29046630859375, Mean : 201.28163146972656, Min : 52.82987594604492, Std: 69.19804382324219\n",
      "At layer idx 20 and shape torch.Size([10, 512]), the OT cost is  52.829878616333005\n",
      "Tmap stats (before correction) \n",
      ": For layer model.fc.weight, frobenius norm from the joe's transport map is 0.30000001192092896\n",
      "shape of T_var is  torch.Size([10, 10])\n",
      "T_var before correction  tensor([[0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.1000]])\n",
      "T_var after correction  tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]])\n",
      "T_var stats: max 0.9999990463256836, min 0.0, mean 0.09999990463256836, std 0.3015110492706299 \n",
      "the transport map is  tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]])\n",
      "Shape of aligned wt is  torch.Size([10, 512])\n",
      "EXIT\n",
      "len of model_state_dict is  21\n",
      "len of new_params is  21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240109_161801-m7gypnxp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/model-fusion/Model%20Fusion/runs/m7gypnxp' target=\"_blank\">resnet18_cifar10_batch_size_32_aligned_modelA</a></strong> to <a href='https://wandb.ai/model-fusion/Model%20Fusion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/model-fusion/Model%20Fusion' target=\"_blank\">https://wandb.ai/model-fusion/Model%20Fusion</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/model-fusion/Model%20Fusion/runs/m7gypnxp' target=\"_blank\">https://wandb.ai/model-fusion/Model%20Fusion/runs/m7gypnxp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 313/313 [00:04<00:00, 65.57it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy          0.7854999899864197\n",
      "        val_loss            0.6301218271255493\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>trainer/global_step</td><td>0</td></tr><tr><td>val_accuracy</td><td>0.7855</td></tr><tr><td>val_loss</td><td>0.63012</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18_cifar10_batch_size_32_aligned_modelA</strong> at: <a href='https://wandb.ai/model-fusion/Model%20Fusion/runs/m7gypnxp' target=\"_blank\">https://wandb.ai/model-fusion/Model%20Fusion/runs/m7gypnxp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240109_161801-m7gypnxp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# model parameters:  21\n",
      "# new parameters:  21\n",
      "fusing:  model.conv1.weight\n",
      "fusing:  model.layer1.0.conv1.weight\n",
      "fusing:  model.layer1.0.conv2.weight\n",
      "fusing:  model.layer1.1.conv1.weight\n",
      "fusing:  model.layer1.1.conv2.weight\n",
      "fusing:  model.layer2.0.conv1.weight\n",
      "fusing:  model.layer2.0.conv2.weight\n",
      "fusing:  model.layer2.0.shortcut.0.weight\n",
      "fusing:  model.layer2.1.conv1.weight\n",
      "fusing:  model.layer2.1.conv2.weight\n",
      "fusing:  model.layer3.0.conv1.weight\n",
      "fusing:  model.layer3.0.conv2.weight\n",
      "fusing:  model.layer3.0.shortcut.0.weight\n",
      "fusing:  model.layer3.1.conv1.weight\n",
      "fusing:  model.layer3.1.conv2.weight\n",
      "fusing:  model.layer4.0.conv1.weight\n",
      "fusing:  model.layer4.0.conv2.weight\n",
      "fusing:  model.layer4.0.shortcut.0.weight\n",
      "fusing:  model.layer4.1.conv1.weight\n",
      "fusing:  model.layer4.1.conv2.weight\n",
      "fusing:  model.fc.weight\n",
      "------- Evaluating ot fusion model -------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240109_161815-8t4hiuis</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/model-fusion/Model%20Fusion/runs/8t4hiuis' target=\"_blank\">resnet18_cifar10_batch_size_32_ot_model_fusion-bbecqkxs-uw0w0e3e</a></strong> to <a href='https://wandb.ai/model-fusion/Model%20Fusion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/model-fusion/Model%20Fusion' target=\"_blank\">https://wandb.ai/model-fusion/Model%20Fusion</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/model-fusion/Model%20Fusion/runs/8t4hiuis' target=\"_blank\">https://wandb.ai/model-fusion/Model%20Fusion/runs/8t4hiuis</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 313/313 [00:04<00:00, 72.47it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy           0.781499981880188\n",
      "        val_loss            0.7478806376457214\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>trainer/global_step</td><td>0</td></tr><tr><td>val_accuracy</td><td>0.7815</td></tr><tr><td>val_loss</td><td>0.74788</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18_cifar10_batch_size_32_ot_model_fusion-bbecqkxs-uw0w0e3e</strong> at: <a href='https://wandb.ai/model-fusion/Model%20Fusion/runs/8t4hiuis' target=\"_blank\">https://wandb.ai/model-fusion/Model%20Fusion/runs/8t4hiuis</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240109_161815-8t4hiuis\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OT model fusion + eval aligned model\n",
    "print(\"------- Computing model fusion -------\")\n",
    "\n",
    "wandb_tag = f\"ot_model_fusion-{runA}-{runB}\"\n",
    "\n",
    "ot_fused_model, modelA_aligned = otfusion_experiment.run_otfusion(\n",
    "    batch_size=batch_size,\n",
    "    datamodule_type=datamodule_type,\n",
    "    datamodule_hparams=datamodule_hparams,\n",
    "    model_type=model_type,\n",
    "    model_hparams=model_hparams,\n",
    "    modelA=modelA,\n",
    "    modelB=modelB,\n",
    "    wandb_tag=wandb_tag\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Computing LMC barrier after alignment -------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Alpha: 0.00 (model 2), Train average loss: 0.06414 Train barrier:  0\n",
      "Alpha: 1.00 (model 1), Train average loss: 0.52097 Train barrier:  0\n",
      "Alpha: 0.05, Train average loss: 0.06640 Train barrier -0.020585532479153734\n",
      "Alpha: 0.10, Train average loss: 0.08008 Train barrier -0.029741123794847057\n",
      "Alpha: 0.15, Train average loss: 0.10757 Train barrier -0.025095993782414353\n",
      "Alpha: 0.20, Train average loss: 0.15264 Train barrier -0.0028634620798958788\n",
      "Alpha: 0.25, Train average loss: 0.21757 Train barrier 0.03921992217832143\n",
      "Alpha: 0.30, Train average loss: 0.30126 Train barrier 0.10006847901079388\n",
      "Alpha: 0.35, Train average loss: 0.39911 Train barrier 0.17507457478973595\n",
      "Alpha: 0.40, Train average loss: 0.50299 Train barrier 0.25611559307840137\n",
      "Alpha: 0.45, Train average loss: 0.60303 Train barrier 0.33331129045353997\n",
      "Alpha: 0.50, Train average loss: 0.68980 Train barrier 0.3972465532541275\n",
      "Alpha: 0.55, Train average loss: 0.75628 Train barrier 0.4408828560683462\n",
      "Alpha: 0.60, Train average loss: 0.79837 Train barrier 0.46012629346847533\n",
      "Alpha: 0.65, Train average loss: 0.81515 Train barrier 0.4540643135216501\n",
      "Alpha: 0.70, Train average loss: 0.80787 Train barrier 0.42394342392550566\n",
      "Alpha: 0.75, Train average loss: 0.77943 Train barrier 0.37266269163688026\n",
      "Alpha: 0.80, Train average loss: 0.73416 Train barrier 0.3045539221074846\n",
      "Alpha: 0.85, Train average loss: 0.67795 Train barrier 0.22550600071880555\n",
      "Alpha: 0.90, Train average loss: 0.61815 Train barrier 0.1428626737621096\n",
      "Alpha: 0.95, Train average loss: 0.56295 Train barrier 0.06481451241837599\n",
      "Loss model 1: 0.52097, Loss model 2: 0.06414, Alpha argmax: 0.60000\n",
      "Barrier: 0.46013\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Vanilla loss pre fine-tuning: 1.4379087098227608\n",
      "Fused loss pre fine-tuning: 0.6897995880444845\n"
     ]
    }
   ],
   "source": [
    "# LMC barrier\n",
    "print(\"------- Computing LMC barrier after alignment -------\")\n",
    "\n",
    "lmc_experiment.run_lmc(\n",
    "    datamodule_type=datamodule_type,\n",
    "    modelA=modelA_aligned,\n",
    "    modelB=modelB,\n",
    "    granularity=21\n",
    ")\n",
    "\n",
    "# Losses for ot fusion model and vanilla averaging model\n",
    "datamodule_hparams_lmc = {'batch_size': 1024, 'data_dir': BASE_DATA_DIR}\n",
    "datamodule_lmc = datamodule_type.get_data_module(**datamodule_hparams)\n",
    "datamodule_lmc.prepare_data()\n",
    "datamodule_lmc.setup('fit')\n",
    "\n",
    "vanilla_loss = lmc_utils.compute_loss(vanilla_averaging_model, datamodule_lmc)\n",
    "fused_loss = lmc_utils.compute_loss(ot_fused_model, datamodule_lmc)\n",
    "\n",
    "print(f\"Vanilla loss pre fine-tuning: {vanilla_loss}\")\n",
    "print(f\"Fused loss pre fine-tuning: {fused_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuning otfused model    #DONE\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "from model_fusion.train import get_wandb_logger\n",
    "\n",
    "_, datamodule, trainer = None, None, None\n",
    "\n",
    "min_epochs = 50\n",
    "max_epochs = 100\n",
    "datamodule_hparams['batch_size'] = 32\n",
    "datamodule_hparams['data_augmentation']=True\n",
    "\n",
    "datamodule = datamodule_type.get_data_module(**datamodule_hparams)\n",
    "lightning_params = {'optimizer': 'sgd', 'lr': 0.01, 'momentum': 0.95, 'weight_decay': 0.0001, 'lr_scheduler': 'plateau', 'lr_decay_factor': 0.5, 'lr_monitor_metric': 'val_loss'}\n",
    "otfused_lit_model = BaseModel(model_type=model_type, model_hparams=model_hparams, model=copy.deepcopy(ot_fused_model.model), **lightning_params)\n",
    "\n",
    "\n",
    "logger_config = {'model_hparams': model_hparams} | {'datamodule_hparams': datamodule_hparams} | {'lightning_params': lightning_params} | {'min_epochs': min_epochs, 'max_epochs': max_epochs, 'model_type': model_type, 'datamodule_type': datamodule_type, 'early_stopping': True}\n",
    "logger = get_wandb_logger(\"otfusion finetuning\", logger_config, [])\n",
    "callbacks = []\n",
    "monitor = 'val_loss'\n",
    "patience = 20\n",
    "callbacks.append(EarlyStopping(monitor=monitor, patience=patience))\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"val_accuracy\", mode=\"max\")\n",
    "callbacks.append(checkpoint_callback)\n",
    "trainer = lightning.Trainer(min_epochs=min_epochs, max_epochs=max_epochs, logger=logger, callbacks=callbacks, deterministic='warn')\n",
    "\n",
    "\n",
    "datamodule.prepare_data()\n",
    "\n",
    "datamodule.setup('fit')\n",
    "\n",
    "trainer.fit(otfused_lit_model, train_dataloaders=datamodule.train_dataloader(), val_dataloaders=datamodule.val_dataloader())\n",
    "\n",
    "\n",
    "datamodule.setup('test')\n",
    "trainer.test(otfused_lit_model, dataloaders=datamodule.test_dataloader())\n",
    "\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finetuning vanilla averaged model\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "from model_fusion.train import get_wandb_logger\n",
    "\n",
    "_, datamodule, trainer = None, None, None\n",
    "\n",
    "min_epochs = 50\n",
    "max_epochs = 100\n",
    "datamodule_hparams['batch_size'] = 32\n",
    "datamodule_hparams['data_augmentation']=True\n",
    "\n",
    "datamodule = datamodule_type.get_data_module(**datamodule_hparams)\n",
    "lightning_params = {'optimizer': 'sgd', 'lr': 0.01, 'momentum': 0.95, 'weight_decay': 0.0001, 'lr_scheduler': 'plateau', 'lr_decay_factor': 0.5, 'lr_monitor_metric': 'val_loss'}\n",
    "\n",
    "vanilla_averaged_lit_model = BaseModel(model_type=model_type, model_hparams=model_hparams, model=copy.deepcopy(vanilla_averaging_model.model), **lightning_params)\n",
    "\n",
    "logger_config = {'model_hparams': model_hparams} | {'datamodule_hparams': datamodule_hparams} | {'lightning_params': lightning_params} | {'min_epochs': min_epochs, 'max_epochs': max_epochs, 'model_type': model_type, 'datamodule_type': datamodule_type, 'early_stopping': True}\n",
    "logger = get_wandb_logger(\"vanilla finetuning\", logger_config, [])\n",
    "callbacks = []\n",
    "monitor = 'val_loss'\n",
    "patience = 20\n",
    "callbacks.append(EarlyStopping(monitor=monitor, patience=patience))\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"val_accuracy\", mode=\"max\")\n",
    "callbacks.append(checkpoint_callback)\n",
    "trainer = lightning.Trainer(min_epochs=min_epochs, max_epochs=max_epochs, logger=logger, callbacks=callbacks, deterministic='warn')\n",
    "\n",
    "\n",
    "datamodule.prepare_data()\n",
    "\n",
    "datamodule.setup('fit')\n",
    "\n",
    "\n",
    "trainer.fit(vanilla_averaged_lit_model, train_dataloaders=datamodule.train_dataloader(), val_dataloaders=datamodule.val_dataloader())\n",
    "\n",
    "datamodule.setup('test')\n",
    "\n",
    "trainer.test(vanilla_averaged_lit_model, dataloaders=datamodule.test_dataloader())\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing ot fused model finetuned\n",
    "#runFT = 'j1go7qte'\n",
    "runFT = '0a6mj32n'\n",
    "\n",
    "\n",
    "api = wandb.Api()\n",
    "run = api.run(f'model-fusion/Model Fusion/{runFT}')\n",
    "\n",
    "print(run.config)\n",
    "\n",
    "batch_size = run.config['datamodule_hparams'].get('batch_size')\n",
    "\n",
    "datamodule_type_str = run.config['datamodule_type'].split('.')[1].lower()\n",
    "datamodule_type = DataModuleType(datamodule_type_str)\n",
    "datamodule_hparams = run.config['datamodule_hparams']\n",
    "datamodule_hparams['data_augmentation'] = False\n",
    "\n",
    "model_type_str = run.config['model_type'].split('.')[1].lower()\n",
    "model_type = ModelType(model_type_str)\n",
    "\n",
    "model_hparams = run.config['model_hparams']\n",
    "\n",
    "print(datamodule_hparams)\n",
    "print(model_hparams)\n",
    "\n",
    "checkpointFT = f'model-fusion/Model Fusion/model-{runFT}:best_k'\n",
    "\n",
    "\n",
    "run = wandb.init()\n",
    "\n",
    "artifact = run.use_artifact(checkpointFT, type='model')\n",
    "artifact_dir = artifact.download(root=CHECKPOINT_DIR)\n",
    "otfused_lit_model = BaseModel.load_from_checkpoint(Path(artifact_dir)/\"model.ckpt\")\n",
    "wandb_tags = [f\"{model_type.value}\", f\"{datamodule_type.value}\"]\n",
    "\n",
    "datamodule, trainer = setup_testing(f'eval finetuning {runFT}', model_type, model_hparams, datamodule_type, datamodule_hparams, wandb_tags)\n",
    "\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup('test')\n",
    "\n",
    "trainer.test(otfused_lit_model, dataloaders=datamodule.test_dataloader())\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "finetuned_loss = lmc_utils.compute_loss(otfused_lit_model, datamodule_lmc)\n",
    "\n",
    "print(f\"Finetuned otfused loss: {finetuned_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing vanilla model finetuned\n",
    "#runFT = 'vyu3hupf'\n",
    "runFT= 'sm4quce8'\n",
    "\n",
    "api = wandb.Api()\n",
    "run = api.run(f'model-fusion/Model Fusion/{runFT}')\n",
    "\n",
    "print(run.config)\n",
    "\n",
    "batch_size = run.config['datamodule_hparams'].get('batch_size')\n",
    "\n",
    "datamodule_type_str = run.config['datamodule_type'].split('.')[1].lower()\n",
    "datamodule_type = DataModuleType(datamodule_type_str)\n",
    "datamodule_hparams = run.config['datamodule_hparams']\n",
    "datamodule_hparams['data_augmentation'] = False\n",
    "\n",
    "model_type_str = run.config['model_type'].split('.')[1].lower()\n",
    "model_type = ModelType(model_type_str)\n",
    "\n",
    "model_hparams = run.config['model_hparams']\n",
    "\n",
    "print(datamodule_hparams)\n",
    "print(model_hparams)\n",
    "\n",
    "checkpointFT = f'model-fusion/Model Fusion/model-{runFT}:best_k'\n",
    "\n",
    "\n",
    "run = wandb.init()\n",
    "\n",
    "artifact = run.use_artifact(checkpointFT, type='model')\n",
    "artifact_dir = artifact.download(root=CHECKPOINT_DIR)\n",
    "vanilla_averaged_lit_model = BaseModel.load_from_checkpoint(Path(artifact_dir)/\"model.ckpt\")\n",
    "wandb_tags = [f\"{model_type.value}\", f\"{datamodule_type.value}\"]\n",
    "\n",
    "datamodule, trainer = setup_testing(f'eval finetuning {runFT}', model_type, model_hparams, datamodule_type, datamodule_hparams, wandb_tags)\n",
    "\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup('test')\n",
    "\n",
    "trainer.test(vanilla_averaged_lit_model, dataloaders=datamodule.test_dataloader())\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "finetuned_loss = lmc_utils.compute_loss(vanilla_averaged_lit_model, datamodule_lmc)\n",
    "\n",
    "print(f\"Finetuned vanilla loss: {finetuned_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Computing sharpness -------\n",
      "------- Model A -------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:251: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at ..\\torch\\csrc\\autograd\\engine.cpp:1176.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top Hessian eigenvalue of this model is 2.4751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***Trace:  126.4693598429362\n",
      "------- Model B -------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "The top Hessian eigenvalue of this model is 2.3408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***Trace:  107.5655019124349\n",
      "------- OT fusion model -------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "The top Hessian eigenvalue of this model is 3.4143\n",
      "\n",
      "***Trace:  139.10491234915597\n"
     ]
    }
   ],
   "source": [
    "# Pyhessian (compute sharpness and eigenspectrum of base models, vanilla avg, ot fusion and finetuned solutions)\n",
    "print(\"------- Computing sharpness -------\")\n",
    "\n",
    "print(\"------- Model A -------\")\n",
    "hessian_comp = pyhessian_experiment.run_pyhessian(datamodule_type=datamodule_type, model=modelA, compute_density=False, figure_name='modelA.pdf') \n",
    "print(\"------- Model B -------\")\n",
    "hessian_comp = pyhessian_experiment.run_pyhessian(datamodule_type=datamodule_type, model=modelB, compute_density=False, figure_name='modelB.pdf')\n",
    "\n",
    "#print(\"------- Model A aligned to B -------\")\n",
    "#hessian_comp = pyhessian_experiment.run_pyhessian(datamodule_type=datamodule_type,model=modelA_aligned,  compute_density=False, figure_name='modelA_aligned.pdf')\n",
    "\n",
    "print(\"------- OT fusion model -------\")\n",
    "hessian_comp = pyhessian_experiment.run_pyhessian(datamodule_type=datamodule_type, model=ot_fused_model,  compute_density=False, figure_name='otmodel32.pdf')\n",
    "\n",
    "#print(\"------- Vanilla avg model (finetuned) -------\")\n",
    "#hessian_comp = pyhessian_experiment.run_pyhessian(datamodule_type=datamodule_type,model=vanilla_averaged_lit_model,  compute_density=False, figure_name='vanilla_avg.pdf')\n",
    "\n",
    "#print(\"------- OT fusion model (finetuned) -------\")\n",
    "#hessian_comp = pyhessian_experiment.run_pyhessian(datamodule_type=datamodule_type, model=otfused_lit_model, num_batches=30, compute_density=False, figure_name='otmodel.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Vanilla avg model -------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "The top Hessian eigenvalue of this model is 3.5128\n",
      "\n",
      "***Trace:  66.47115256146687\n"
     ]
    }
   ],
   "source": [
    "print(\"------- Vanilla avg model -------\")\n",
    "hessian_comp = pyhessian_experiment.run_pyhessian(datamodule_type=datamodule_type,model=vanilla_averaging_model,  compute_density=False, figure_name='vanilla_avg.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
