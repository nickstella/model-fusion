{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pl_bolts\\__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pl_bolts\\__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pl_bolts\\models\\self_supervised\\amdim\\amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pl_bolts\\models\\self_supervised\\amdim\\amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pl_bolts\\losses\\self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.nce_loss = AmdimNCELoss(tclip)\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "import torch\n",
    "import lightning\n",
    "import copy\n",
    "from pathlib import Path\n",
    "from model_fusion.config import BASE_DATA_DIR, CHECKPOINT_DIR\n",
    "from model_fusion.datasets import DataModuleType\n",
    "from model_fusion.models import ModelType\n",
    "from model_fusion.models.lightning import BaseModel\n",
    "from Experiments import lmc_experiment\n",
    "from model_fusion import lmc_utils\n",
    "from Experiments import baselines_experiment\n",
    "from Experiments import otfusion_experiment\n",
    "from Experiments import pyhessian_experiment\n",
    "from model_fusion.train import setup_training, setup_testing\n",
    "\n",
    "\n",
    "# set seed for numpy based calculations\n",
    "NUMPY_SEED = 100\n",
    "np.random.seed(NUMPY_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Loading models -------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.1, 'model': None, 'momentum': 0.9, 'optimizer': 'sgd', 'max_epochs': 200, 'min_epochs': 50, 'model_seed': 42, 'model_type': 'ModelType.RESNET18', 'loss_module': 'CrossEntropyLoss', 'lr_scheduler': 'plateau', 'weight_decay': 0.0001, 'model_hparams': {'bias': False, 'num_classes': 10, 'num_channels': 3}, 'early_stopping': True, 'datamodule_type': 'DataModuleType.CIFAR10', 'lr_decay_factor': 0.1, 'lightning_params': {'lr': 0.1, 'momentum': 0.9, 'optimizer': 'sgd', 'model_seed': 42, 'lr_scheduler': 'plateau', 'weight_decay': 0.0001, 'lr_decay_factor': 0.1, 'lr_monitor_metric': 'val_loss'}, 'lr_monitor_metric': 'val_loss', 'datamodule_hparams': {'seed': 42, 'data_dir': 'data', 'batch_size': 512, 'data_augmentation': True}, 'model_hparams/bias': False, 'model_hparams/num_classes': 10, 'model_hparams/num_channels': 3}\n",
      "{'seed': 42, 'data_dir': 'data', 'batch_size': 512, 'data_augmentation': False}\n",
      "{'bias': False, 'num_classes': 10, 'num_channels': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mframbelli\u001b[0m (\u001b[33mmodel-fusion\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\Notebooks\\wandb\\run-20240110_144228-1uobkka5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/model-fusion/model-fusion/runs/1uobkka5' target=\"_blank\">colorful-deluge-151</a></strong> to <a href='https://wandb.ai/model-fusion/model-fusion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/model-fusion/model-fusion' target=\"_blank\">https://wandb.ai/model-fusion/model-fusion</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/model-fusion/model-fusion/runs/1uobkka5' target=\"_blank\">https://wandb.ai/model-fusion/model-fusion/runs/1uobkka5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-kvuejplb:best_k, 85.20MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-kwdhgbfv:best_k, 85.20MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.4\n"
     ]
    }
   ],
   "source": [
    "print(\"------- Loading models -------\")\n",
    "\n",
    "# select wandb run names\n",
    "runA = 'kvuejplb'\n",
    "runB = 'kwdhgbfv'#same init\n",
    "\n",
    "api = wandb.Api()\n",
    "run = api.run(f'model-fusion/Model Fusion/{runA}')\n",
    "\n",
    "print(run.config)\n",
    "\n",
    "batch_size = run.config['datamodule_hparams'].get('batch_size')\n",
    "\n",
    "datamodule_type_str = run.config['datamodule_type'].split('.')[1].lower()\n",
    "datamodule_type = DataModuleType(datamodule_type_str)\n",
    "datamodule_hparams = run.config['datamodule_hparams']\n",
    "datamodule_hparams['data_augmentation'] = False\n",
    "\n",
    "model_type_str = run.config['model_type'].split('.')[1].lower()\n",
    "model_type = ModelType(model_type_str)\n",
    "\n",
    "model_hparams = run.config['model_hparams']\n",
    "\n",
    "print(datamodule_hparams)\n",
    "print(model_hparams)\n",
    "\n",
    "checkpointA = f'model-fusion/Model Fusion/model-{runA}:best_k'\n",
    "checkpointB = f'model-fusion/Model Fusion/model-{runB}:best_k'\n",
    "\n",
    "run = wandb.init()\n",
    "\n",
    "artifact = run.use_artifact(checkpointA, type='model')\n",
    "artifact_dir = artifact.download(root=CHECKPOINT_DIR)\n",
    "modelA = BaseModel.load_from_checkpoint(Path(artifact_dir)/\"model.ckpt\")\n",
    "\n",
    "artifact = run.use_artifact(checkpointB, type='model')\n",
    "artifact_dir = artifact.download(root=CHECKPOINT_DIR)\n",
    "modelB = BaseModel.load_from_checkpoint(Path(artifact_dir)/\"model.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Computing LMC barrier before alignment-------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Alpha: 0.00 (model 2), Train average loss: 0.07371 Train barrier:  0\n",
      "Alpha: 1.00 (model 1), Train average loss: 0.03120 Train barrier:  0\n",
      "Alpha: 0.05, Train average loss: 0.07760 Train barrier 0.006010890418208306\n",
      "Alpha: 0.10, Train average loss: 0.11883 Train barrier 0.04936614853259588\n",
      "Alpha: 0.15, Train average loss: 0.22575 Train barrier 0.15841357156741948\n",
      "Alpha: 0.20, Train average loss: 0.43995 Train barrier 0.37474012482133173\n",
      "Alpha: 0.25, Train average loss: 0.79192 Train barrier 0.7288391512542135\n",
      "Alpha: 0.30, Train average loss: 1.23702 Train barrier 1.1760678752377631\n",
      "Alpha: 0.35, Train average loss: 1.64869 Train barrier 1.5898577185870044\n",
      "Alpha: 0.40, Train average loss: 1.94675 Train barrier 1.8900409890221226\n",
      "Alpha: 0.45, Train average loss: 2.12768 Train barrier 2.073103892385877\n",
      "Alpha: 0.50, Train average loss: 2.20460 Train barrier 2.1521445777871544\n",
      "Alpha: 0.55, Train average loss: 2.17905 Train barrier 2.1287184584721097\n",
      "Alpha: 0.60, Train average loss: 2.05196 Train barrier 2.0037602336476246\n",
      "Alpha: 0.65, Train average loss: 1.81500 Train barrier 1.768922013159179\n",
      "Alpha: 0.70, Train average loss: 1.44952 Train barrier 1.4055688371501036\n",
      "Alpha: 0.75, Train average loss: 0.99298 Train barrier 0.9511520016214086\n",
      "Alpha: 0.80, Train average loss: 0.56823 Train barrier 0.5285241870019172\n",
      "Alpha: 0.85, Train average loss: 0.27457 Train barrier 0.23699888985479872\n",
      "Alpha: 0.90, Train average loss: 0.11681 Train barrier 0.08136248564968507\n",
      "Alpha: 0.95, Train average loss: 0.05065 Train barrier 0.017321549255069763\n",
      "Loss model 1: 0.03120, Loss model 2: 0.07371, Alpha argmax: 0.50000\n",
      "Barrier: 2.15214\n"
     ]
    }
   ],
   "source": [
    "# LMC barrier\n",
    "print(\"------- Computing LMC barrier before alignment-------\")\n",
    "\n",
    "lmc_experiment.run_lmc(\n",
    "    datamodule_type=datamodule_type,\n",
    "    modelA=modelA,\n",
    "    modelB=modelB,\n",
    "    granularity=21\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Computing baselines -------\n",
      "------- Prediction based ensembling -------\n",
      "------- Naive ensembling of weights -------\n",
      "------- Evaluating baselines -------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:395: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Evaluating base models -------\n",
      "Testing DataLoader 0: 100%|██████████| 10/10 [00:02<00:00,  3.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy          0.9038000106811523\n",
      "        val_loss            0.42905566096305847\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Testing DataLoader 0: 100%|██████████| 10/10 [00:02<00:00,  4.06it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy          0.8983999490737915\n",
      "        val_loss             0.47519651055336\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "------- Evaluating prediction ensembling -------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.3707, Accuracy: 91.39%\n",
      "------- Evaluating vanilla averaging -------\n",
      "Testing DataLoader 0: 100%|██████████| 10/10 [00:03<00:00,  3.01it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy          0.19380000233650208\n",
      "        val_loss             2.201833486557007\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁</td></tr><tr><td>val_accuracy</td><td>██▁</td></tr><tr><td>val_loss</td><td>▁▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>trainer/global_step</td><td>0</td></tr><tr><td>val_accuracy</td><td>0.1938</td></tr><tr><td>val_loss</td><td>2.20183</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">effortless-moon-138</strong> at: <a href='https://wandb.ai/model-fusion/model-fusion/runs/up6wwpi4' target=\"_blank\">https://wandb.ai/model-fusion/model-fusion/runs/up6wwpi4</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240109_173437-up6wwpi4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Baselines (prediction ensembling, vanilla averaging)\n",
    "print(\"------- Computing baselines -------\")\n",
    "\n",
    "wandb_tag = f'baselines-{runA}-{runB}'\n",
    "\n",
    "vanilla_averaging_model = baselines_experiment.run_baselines(\n",
    "    datamodule_type=datamodule_type,\n",
    "    datamodule_hparams=datamodule_hparams,\n",
    "    model_type=model_type,\n",
    "    model_hparams=model_hparams,\n",
    "    modelA=modelA,\n",
    "    modelB=modelB,\n",
    "    wandb_tag=wandb_tag,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Computing model fusion -------\n",
      "------- Setting up parameters -------\n",
      "{'seed': 42, 'data_dir': 'data', 'batch_size': 512, 'data_augmentation': False}\n",
      "The parameters are: \n",
      " {'eval_aligned': True, 'num_models': 2, 'width_ratio': 1, 'handle_skips': True, 'exact': True, 'activation_seed': 21, 'activation_histograms': True, 'ground_metric': 'euclidean', 'ground_metric_normalize': 'none', 'same_model': False, 'geom_ensemble_type': 'acts', 'act_num_samples': 200, 'skip_last_layer': False, 'skip_last_layer_type': 'average', 'softmax_temperature': 1, 'past_correction': True, 'correction': True, 'normalize_acts': False, 'normalize_wts': False, 'activation_normalize': False, 'center_acts': False, 'prelu_acts': False, 'pool_acts': False, 'pool_relu': False, 'importance': None, 'proper_marginals': False, 'not_squared': True, 'ground_metric_eff': False, 'dist_normalize': False, 'clip_gm': False, 'clip_min': 0, 'clip_max': 5, 'tmap_stats': False, 'ensemble_step': 0.5, 'reg': 0.01}\n",
      "------- OT model fusion -------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Computing activations\n",
      "this was continued,  \n",
      "this was continued,  loss_module\n",
      "this was continued,  accuracy\n",
      "this was continued,  model\n",
      "set forward hook for layer named:  model.conv1\n",
      "this was continued,  model.bn1\n",
      "this was continued,  model.layer1\n",
      "this was continued,  model.layer1.0\n",
      "set forward hook for layer named:  model.layer1.0.conv1\n",
      "this was continued,  model.layer1.0.bn1\n",
      "set forward hook for layer named:  model.layer1.0.conv2\n",
      "this was continued,  model.layer1.0.bn2\n",
      "this was continued,  model.layer1.0.shortcut\n",
      "this was continued,  model.layer1.1\n",
      "set forward hook for layer named:  model.layer1.1.conv1\n",
      "this was continued,  model.layer1.1.bn1\n",
      "set forward hook for layer named:  model.layer1.1.conv2\n",
      "this was continued,  model.layer1.1.bn2\n",
      "this was continued,  model.layer1.1.shortcut\n",
      "this was continued,  model.layer2\n",
      "this was continued,  model.layer2.0\n",
      "set forward hook for layer named:  model.layer2.0.conv1\n",
      "this was continued,  model.layer2.0.bn1\n",
      "set forward hook for layer named:  model.layer2.0.conv2\n",
      "this was continued,  model.layer2.0.bn2\n",
      "this was continued,  model.layer2.0.shortcut\n",
      "set forward hook for layer named:  model.layer2.0.shortcut.0\n",
      "this was continued,  model.layer2.0.shortcut.1\n",
      "this was continued,  model.layer2.1\n",
      "set forward hook for layer named:  model.layer2.1.conv1\n",
      "this was continued,  model.layer2.1.bn1\n",
      "set forward hook for layer named:  model.layer2.1.conv2\n",
      "this was continued,  model.layer2.1.bn2\n",
      "this was continued,  model.layer2.1.shortcut\n",
      "this was continued,  model.layer3\n",
      "this was continued,  model.layer3.0\n",
      "set forward hook for layer named:  model.layer3.0.conv1\n",
      "this was continued,  model.layer3.0.bn1\n",
      "set forward hook for layer named:  model.layer3.0.conv2\n",
      "this was continued,  model.layer3.0.bn2\n",
      "this was continued,  model.layer3.0.shortcut\n",
      "set forward hook for layer named:  model.layer3.0.shortcut.0\n",
      "this was continued,  model.layer3.0.shortcut.1\n",
      "this was continued,  model.layer3.1\n",
      "set forward hook for layer named:  model.layer3.1.conv1\n",
      "this was continued,  model.layer3.1.bn1\n",
      "set forward hook for layer named:  model.layer3.1.conv2\n",
      "this was continued,  model.layer3.1.bn2\n",
      "this was continued,  model.layer3.1.shortcut\n",
      "this was continued,  model.layer4\n",
      "this was continued,  model.layer4.0\n",
      "set forward hook for layer named:  model.layer4.0.conv1\n",
      "this was continued,  model.layer4.0.bn1\n",
      "set forward hook for layer named:  model.layer4.0.conv2\n",
      "this was continued,  model.layer4.0.bn2\n",
      "this was continued,  model.layer4.0.shortcut\n",
      "set forward hook for layer named:  model.layer4.0.shortcut.0\n",
      "this was continued,  model.layer4.0.shortcut.1\n",
      "this was continued,  model.layer4.1\n",
      "set forward hook for layer named:  model.layer4.1.conv1\n",
      "this was continued,  model.layer4.1.bn1\n",
      "set forward hook for layer named:  model.layer4.1.conv2\n",
      "this was continued,  model.layer4.1.bn2\n",
      "this was continued,  model.layer4.1.shortcut\n",
      "set forward hook for layer named:  model.fc\n",
      "this was continued,  \n",
      "this was continued,  loss_module\n",
      "this was continued,  accuracy\n",
      "this was continued,  model\n",
      "set forward hook for layer named:  model.conv1\n",
      "this was continued,  model.bn1\n",
      "this was continued,  model.layer1\n",
      "this was continued,  model.layer1.0\n",
      "set forward hook for layer named:  model.layer1.0.conv1\n",
      "this was continued,  model.layer1.0.bn1\n",
      "set forward hook for layer named:  model.layer1.0.conv2\n",
      "this was continued,  model.layer1.0.bn2\n",
      "this was continued,  model.layer1.0.shortcut\n",
      "this was continued,  model.layer1.1\n",
      "set forward hook for layer named:  model.layer1.1.conv1\n",
      "this was continued,  model.layer1.1.bn1\n",
      "set forward hook for layer named:  model.layer1.1.conv2\n",
      "this was continued,  model.layer1.1.bn2\n",
      "this was continued,  model.layer1.1.shortcut\n",
      "this was continued,  model.layer2\n",
      "this was continued,  model.layer2.0\n",
      "set forward hook for layer named:  model.layer2.0.conv1\n",
      "this was continued,  model.layer2.0.bn1\n",
      "set forward hook for layer named:  model.layer2.0.conv2\n",
      "this was continued,  model.layer2.0.bn2\n",
      "this was continued,  model.layer2.0.shortcut\n",
      "set forward hook for layer named:  model.layer2.0.shortcut.0\n",
      "this was continued,  model.layer2.0.shortcut.1\n",
      "this was continued,  model.layer2.1\n",
      "set forward hook for layer named:  model.layer2.1.conv1\n",
      "this was continued,  model.layer2.1.bn1\n",
      "set forward hook for layer named:  model.layer2.1.conv2\n",
      "this was continued,  model.layer2.1.bn2\n",
      "this was continued,  model.layer2.1.shortcut\n",
      "this was continued,  model.layer3\n",
      "this was continued,  model.layer3.0\n",
      "set forward hook for layer named:  model.layer3.0.conv1\n",
      "this was continued,  model.layer3.0.bn1\n",
      "set forward hook for layer named:  model.layer3.0.conv2\n",
      "this was continued,  model.layer3.0.bn2\n",
      "this was continued,  model.layer3.0.shortcut\n",
      "set forward hook for layer named:  model.layer3.0.shortcut.0\n",
      "this was continued,  model.layer3.0.shortcut.1\n",
      "this was continued,  model.layer3.1\n",
      "set forward hook for layer named:  model.layer3.1.conv1\n",
      "this was continued,  model.layer3.1.bn1\n",
      "set forward hook for layer named:  model.layer3.1.conv2\n",
      "this was continued,  model.layer3.1.bn2\n",
      "this was continued,  model.layer3.1.shortcut\n",
      "this was continued,  model.layer4\n",
      "this was continued,  model.layer4.0\n",
      "set forward hook for layer named:  model.layer4.0.conv1\n",
      "this was continued,  model.layer4.0.bn1\n",
      "set forward hook for layer named:  model.layer4.0.conv2\n",
      "this was continued,  model.layer4.0.bn2\n",
      "this was continued,  model.layer4.0.shortcut\n",
      "set forward hook for layer named:  model.layer4.0.shortcut.0\n",
      "this was continued,  model.layer4.0.shortcut.1\n",
      "this was continued,  model.layer4.1\n",
      "set forward hook for layer named:  model.layer4.1.conv1\n",
      "this was continued,  model.layer4.1.bn1\n",
      "set forward hook for layer named:  model.layer4.1.conv2\n",
      "this was continued,  model.layer4.1.bn2\n",
      "this was continued,  model.layer4.1.shortcut\n",
      "set forward hook for layer named:  model.fc\n",
      "Activations computed across 200 samples out of 45000\n",
      "***********\n",
      "min of act: -13.362442016601562, max: 13.10811996459961, mean: -0.008857262320816517\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 13.10811996459961, mean: 0.3289381265640259\n",
      "***********\n",
      "min of act: -33.88827896118164, max: 16.554704666137695, mean: -1.912351131439209\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 16.554704666137695, mean: 0.09716645628213882\n",
      "***********\n",
      "min of act: -31.209030151367188, max: 21.33432388305664, mean: -0.11654552072286606\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 21.33432388305664, mean: 0.3780379295349121\n",
      "***********\n",
      "min of act: -47.2103157043457, max: 21.672910690307617, mean: -2.415830612182617\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 21.672910690307617, mean: 0.05553625896573067\n",
      "***********\n",
      "min of act: -12.335691452026367, max: 20.33963966369629, mean: 0.06610829383134842\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 20.33963966369629, mean: 0.3572257459163666\n",
      "***********\n",
      "min of act: -34.43425369262695, max: 42.5583381652832, mean: -0.7730550765991211\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 42.5583381652832, mean: 0.4590519666671753\n",
      "***********\n",
      "min of act: -55.181297302246094, max: 57.426368713378906, mean: -0.482168048620224\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 57.426368713378906, mean: 1.3626245260238647\n",
      "***********\n",
      "min of act: -9.301450729370117, max: 14.9022855758667, mean: 0.2288341224193573\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 14.9022855758667, mean: 0.43293365836143494\n",
      "***********\n",
      "min of act: -113.22850036621094, max: 85.3048095703125, mean: -7.65878438949585\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 85.3048095703125, mean: 0.11125416308641434\n",
      "***********\n",
      "min of act: -31.38698959350586, max: 52.661590576171875, mean: 0.8058706521987915\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 52.661590576171875, mean: 1.2560384273529053\n",
      "***********\n",
      "min of act: -116.84086608886719, max: 94.85639190673828, mean: -5.033640384674072\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 94.85639190673828, mean: 0.5776384472846985\n",
      "***********\n",
      "min of act: -107.59683227539062, max: 108.04084777832031, mean: -3.5866057872772217\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 108.04084777832031, mean: 1.3200851678848267\n",
      "***********\n",
      "min of act: -53.22268295288086, max: 61.837345123291016, mean: -0.815194845199585\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 61.837345123291016, mean: 1.006083607673645\n",
      "***********\n",
      "min of act: -138.73973083496094, max: 110.1626968383789, mean: -8.522795677185059\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 110.1626968383789, mean: 0.42698749899864197\n",
      "***********\n",
      "min of act: -60.60978698730469, max: 106.6637954711914, mean: -1.920046091079712\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 106.6637954711914, mean: 0.9287551641464233\n",
      "***********\n",
      "min of act: -98.0317153930664, max: 86.03001403808594, mean: -4.141026973724365\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 86.03001403808594, mean: 0.6149389743804932\n",
      "***********\n",
      "min of act: -108.56238555908203, max: 83.74758911132812, mean: -5.208799362182617\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 83.74758911132812, mean: 0.5257832407951355\n",
      "***********\n",
      "min of act: -27.825546264648438, max: 28.857511520385742, mean: -1.3035662174224854\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 28.857511520385742, mean: 0.3283763825893402\n",
      "***********\n",
      "min of act: -91.23963928222656, max: 43.78093719482422, mean: -2.4742114543914795\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 43.78093719482422, mean: 0.29616838693618774\n",
      "***********\n",
      "min of act: -57.04471206665039, max: 88.73379516601562, mean: -1.1605849266052246\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 88.73379516601562, mean: 0.505962610244751\n",
      "***********\n",
      "min of act: -26.77887725830078, max: 76.01844787597656, mean: 0.08616738766431808\n",
      "***********\n",
      "min of act: -10.5657377243042, max: 10.203322410583496, mean: -0.012479628436267376\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 10.203322410583496, mean: 0.323037326335907\n",
      "***********\n",
      "min of act: -35.83376693725586, max: 21.6776180267334, mean: -1.7043291330337524\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 21.6776180267334, mean: 0.13309963047504425\n",
      "***********\n",
      "min of act: -48.05381393432617, max: 37.82942199707031, mean: -0.2914557158946991\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 37.82942199707031, mean: 0.5098441243171692\n",
      "***********\n",
      "min of act: -70.5979995727539, max: 31.492891311645508, mean: -3.614651918411255\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 31.492891311645508, mean: 0.06104487180709839\n",
      "***********\n",
      "min of act: -22.438257217407227, max: 32.19631576538086, mean: 0.11429392546415329\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 32.19631576538086, mean: 0.4586906433105469\n",
      "***********\n",
      "min of act: -48.86055374145508, max: 55.26173400878906, mean: -0.3860662877559662\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 55.26173400878906, mean: 0.6904184818267822\n",
      "***********\n",
      "min of act: -94.15283966064453, max: 119.57064819335938, mean: -0.11652511358261108\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 119.57064819335938, mean: 2.25016188621521\n",
      "***********\n",
      "min of act: -8.61896800994873, max: 23.271690368652344, mean: 0.24860899150371552\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 23.271690368652344, mean: 0.4876769781112671\n",
      "***********\n",
      "min of act: -190.5164794921875, max: 81.0873794555664, mean: -13.908687591552734\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 81.0873794555664, mean: 0.16608062386512756\n",
      "***********\n",
      "min of act: -58.49225616455078, max: 99.94375610351562, mean: 1.6566097736358643\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 99.94375610351562, mean: 2.111280679702759\n",
      "***********\n",
      "min of act: -230.67578125, max: 157.87020874023438, mean: -9.37508773803711\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 157.87020874023438, mean: 1.0052987337112427\n",
      "***********\n",
      "min of act: -162.7349853515625, max: 181.09869384765625, mean: -5.820991516113281\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 181.09869384765625, mean: 2.238739252090454\n",
      "***********\n",
      "min of act: -69.74822235107422, max: 72.20316314697266, mean: -1.6074868440628052\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 72.20316314697266, mean: 1.7492775917053223\n",
      "***********\n",
      "min of act: -329.89752197265625, max: 209.79153442382812, mean: -15.364645957946777\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 209.79153442382812, mean: 0.8001559376716614\n",
      "***********\n",
      "min of act: -186.48916625976562, max: 169.38766479492188, mean: -4.557028770446777\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 169.38766479492188, mean: 1.4504125118255615\n",
      "***********\n",
      "min of act: -133.31271362304688, max: 113.82720947265625, mean: -7.619266986846924\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 113.82720947265625, mean: 0.9685786962509155\n",
      "***********\n",
      "min of act: -147.0205078125, max: 122.01619720458984, mean: -9.304340362548828\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 122.01619720458984, mean: 0.6822395324707031\n",
      "***********\n",
      "min of act: -61.2843132019043, max: 41.4089241027832, mean: -2.717245101928711\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 41.4089241027832, mean: 0.44817695021629333\n",
      "***********\n",
      "min of act: -128.95797729492188, max: 65.72003173828125, mean: -3.1569645404815674\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 65.72003173828125, mean: 0.41698217391967773\n",
      "***********\n",
      "min of act: -72.55267333984375, max: 113.85193634033203, mean: -2.160092353820801\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 113.85193634033203, mean: 0.5712788105010986\n",
      "***********\n",
      "min of act: -29.701242446899414, max: 76.55903625488281, mean: 0.06878288835287094\n",
      "activations for idx 1 at layer model.fc have the following shape  torch.Size([200, 1, 10])\n",
      "-----------\n",
      "INIT\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 0 ------------- \n",
      " \n",
      "Previous layer shape is  None\n",
      "In layer model.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 12.783203125, Mean : 3.8775296211242676, Min : 0.49702709913253784, Std: 2.092996120452881\n",
      "At layer idx 0 and shape torch.Size([64, 3, 3, 3]), the OT cost is  159.35918307304382\n",
      "Tmap stats (before correction) \n",
      ": For layer model.conv1.weight, frobenius norm from the joe's transport map is 0.12401959300041199\n",
      "shape of T_var is  torch.Size([64, 64])\n",
      "T_var before correction  tensor([[0.0156, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0156,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0156]],\n",
      "       device='cuda:0')\n",
      "T_var after correction  tensor([[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000]],\n",
      "       device='cuda:0')\n",
      "T_var stats: max 0.9999935626983643, min 0.0, mean 0.015624899417161942, std 0.12403393536806107 \n",
      "the transport map is  tensor([[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000]],\n",
      "       device='cuda:0')\n",
      "Shape of aligned wt is  torch.Size([64, 3, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 1 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([64, 3, 3, 3])\n",
      "In layer model.layer1.0.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 11.180118560791016, Mean : 2.576376438140869, Min : 0.15129956603050232, Std: 1.940932273864746\n",
      "At layer idx 1 and shape torch.Size([64, 64, 3, 3]), the OT cost is  182.54201474900765\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer1.0.conv1.weight, frobenius norm from the joe's transport map is 0.12401959300041199\n",
      "shape of T_var is  torch.Size([64, 64])\n",
      "T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0156]],\n",
      "       device='cuda:0')\n",
      "T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000]],\n",
      "       device='cuda:0')\n",
      "T_var stats: max 0.9999935626983643, min 0.0, mean 0.015624899417161942, std 0.12403393536806107 \n",
      "the transport map is  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000]],\n",
      "       device='cuda:0')\n",
      "Shape of aligned wt is  torch.Size([64, 64, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 2 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([64, 64, 3, 3])\n",
      "In layer model.layer1.0.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 20.928695678710938, Mean : 6.689272403717041, Min : 0.9036325216293335, Std: 3.448634386062622\n",
      "At layer idx 2 and shape torch.Size([64, 64, 3, 3]), the OT cost is  385.2578992843628\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer1.0.conv2.weight, frobenius norm from the joe's transport map is 0.12401959300041199\n",
      "shape of T_var is  torch.Size([64, 64])\n",
      "T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0156,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0156]],\n",
      "       device='cuda:0')\n",
      "T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000]],\n",
      "       device='cuda:0')\n",
      "T_var stats: max 0.9999935626983643, min 0.0, mean 0.015624899417161942, std 0.12403393536806107 \n",
      "the transport map is  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000]],\n",
      "       device='cuda:0')\n",
      "Shape of aligned wt is  torch.Size([64, 64, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 3 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([64, 64, 3, 3])\n",
      "In layer model.layer1.1.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 11.977821350097656, Mean : 1.8624622821807861, Min : 0.004215252585709095, Std: 2.0057320594787598\n",
      "At layer idx 3 and shape torch.Size([64, 64, 3, 3]), the OT cost is  172.6572009382071\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer1.1.conv1.weight, frobenius norm from the joe's transport map is 0.12401959300041199\n",
      "shape of T_var is  torch.Size([64, 64])\n",
      "T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0156, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0156, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "T_var stats: max 0.9999935626983643, min 0.0, mean 0.015624899417161942, std 0.12403393536806107 \n",
      "the transport map is  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "Shape of aligned wt is  torch.Size([64, 64, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 4 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([64, 64, 3, 3])\n",
      "In layer model.layer1.1.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 20.314563751220703, Mean : 6.414848327636719, Min : 0.7812788486480713, Std: 3.3701043128967285\n",
      "At layer idx 4 and shape torch.Size([64, 64, 3, 3]), the OT cost is  388.6181592941284\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer1.1.conv2.weight, frobenius norm from the joe's transport map is 0.12401959300041199\n",
      "shape of T_var is  torch.Size([64, 64])\n",
      "T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0156,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0156]],\n",
      "       device='cuda:0')\n",
      "T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000]],\n",
      "       device='cuda:0')\n",
      "T_var stats: max 0.9999935626983643, min 0.0, mean 0.015624898485839367, std 0.12403393536806107 \n",
      "the transport map is  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000]],\n",
      "       device='cuda:0')\n",
      "Shape of aligned wt is  torch.Size([64, 64, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 5 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([64, 64, 3, 3])\n",
      "In layer model.layer2.0.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 22.948787689208984, Mean : 6.578146457672119, Min : 0.3768293857574463, Std: 4.064815521240234\n",
      "At layer idx 5 and shape torch.Size([128, 64, 3, 3]), the OT cost is  281.8250322517706\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer2.0.conv1.weight, frobenius norm from the joe's transport map is 0.08804240077733994\n",
      "shape of T_var is  torch.Size([128, 128])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "T_var stats: max 0.9999872446060181, min 0.0, mean 0.007812400348484516, std 0.08804396539926529 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "Shape of aligned wt is  torch.Size([128, 64, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 6 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([128, 64, 3, 3])\n",
      "In layer model.layer2.0.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 56.9411506652832, Mean : 16.745098114013672, Min : 1.2497162818908691, Std: 9.854698181152344\n",
      "At layer idx 6 and shape torch.Size([128, 128, 3, 3]), the OT cost is  819.4935418069363\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer2.0.conv2.weight, frobenius norm from the joe's transport map is 0.08804240077733994\n",
      "shape of T_var is  torch.Size([128, 128])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "T_var stats: max 0.9999872446060181, min 0.0, mean 0.007812400348484516, std 0.08804396539926529 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "Shape of aligned wt is  torch.Size([128, 128, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 7 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([128, 128, 3, 3])\n",
      "In layer model.layer2.0.shortcut.0.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 9.566641807556152, Mean : 3.5115184783935547, Min : 0.579506516456604, Std: 1.6543505191802979\n",
      "At layer idx 7 and shape torch.Size([128, 64, 1, 1]), the OT cost is  126.53120761737227\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer2.0.shortcut.0.weight, frobenius norm from the joe's transport map is 0.08804240077733994\n",
      "shape of T_var is  torch.Size([128, 128])\n",
      "T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0078, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "T_var stats: max 0.9999872446060181, min 0.0, mean 0.007812400348484516, std 0.08804396539926529 \n",
      "the transport map is  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "Shape of aligned wt is  torch.Size([128, 64, 1])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 8 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([128, 64, 1, 1])\n",
      "In layer model.layer2.1.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 27.80461311340332, Mean : 2.732069969177246, Min : 0.0015466103795915842, Std: 4.364954948425293\n",
      "averaging multiple T_var's\n",
      "At layer idx 8 and shape torch.Size([128, 128, 3, 3]), the OT cost is  244.03805270418525\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer2.1.conv1.weight, frobenius norm from the joe's transport map is 0.08804240077733994\n",
      "shape of T_var is  torch.Size([128, 128])\n",
      "T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0078, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "T_var stats: max 0.9999872446060181, min 0.0, mean 0.007812400348484516, std 0.08804396539926529 \n",
      "the transport map is  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "Shape of aligned wt is  torch.Size([128, 128, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 9 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([128, 128, 3, 3])\n",
      "In layer model.layer2.1.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 54.25444030761719, Mean : 15.866340637207031, Min : 1.2015239000320435, Std: 9.450857162475586\n",
      "At layer idx 9 and shape torch.Size([128, 128, 3, 3]), the OT cost is  803.9843016266823\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer2.1.conv2.weight, frobenius norm from the joe's transport map is 0.08804240077733994\n",
      "shape of T_var is  torch.Size([128, 128])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "T_var stats: max 0.9999872446060181, min 0.0, mean 0.007812400348484516, std 0.08804396539926529 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "Shape of aligned wt is  torch.Size([128, 128, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 10 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([128, 128, 3, 3])\n",
      "In layer model.layer3.0.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 44.54659652709961, Mean : 7.935025215148926, Min : 0.0022505526430904865, Std: 8.049650192260742\n",
      "At layer idx 10 and shape torch.Size([256, 128, 3, 3]), the OT cost is  341.73788052180316\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer3.0.conv1.weight, frobenius norm from the joe's transport map is 0.06237781047821045\n",
      "shape of T_var is  torch.Size([256, 256])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237669289112091 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "Shape of aligned wt is  torch.Size([256, 128, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 11 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([256, 128, 3, 3])\n",
      "In layer model.layer3.0.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 62.421478271484375, Mean : 14.097941398620605, Min : 0.05297984182834625, Std: 11.009233474731445\n",
      "At layer idx 11 and shape torch.Size([256, 256, 3, 3]), the OT cost is  580.516378974542\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer3.0.conv2.weight, frobenius norm from the joe's transport map is 0.06237781047821045\n",
      "shape of T_var is  torch.Size([256, 256])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237669289112091 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "Shape of aligned wt is  torch.Size([256, 256, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 12 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([256, 256, 3, 3])\n",
      "In layer model.layer3.0.shortcut.0.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 31.985719680786133, Mean : 8.98831558227539, Min : 0.4179815649986267, Std: 5.836762428283691\n",
      "At layer idx 12 and shape torch.Size([256, 128, 1, 1]), the OT cost is  284.3081917203963\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer3.0.shortcut.0.weight, frobenius norm from the joe's transport map is 0.06237781047821045\n",
      "shape of T_var is  torch.Size([256, 256])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237669289112091 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "Shape of aligned wt is  torch.Size([256, 128, 1])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 13 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([256, 128, 1, 1])\n",
      "In layer model.layer3.1.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 48.95700454711914, Mean : 6.474983215332031, Min : 0.0006203231168910861, Std: 8.219277381896973\n",
      "averaging multiple T_var's\n",
      "At layer idx 13 and shape torch.Size([256, 256, 3, 3]), the OT cost is  367.1467072276864\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer3.1.conv1.weight, frobenius norm from the joe's transport map is 0.06237781047821045\n",
      "shape of T_var is  torch.Size([256, 256])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237669289112091 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "Shape of aligned wt is  torch.Size([256, 256, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 14 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([256, 256, 3, 3])\n",
      "In layer model.layer3.1.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 58.62628936767578, Mean : 10.660332679748535, Min : 0.008125574328005314, Std: 10.063668251037598\n",
      "At layer idx 14 and shape torch.Size([256, 256, 3, 3]), the OT cost is  506.24873435497284\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer3.1.conv2.weight, frobenius norm from the joe's transport map is 0.06237781047821045\n",
      "shape of T_var is  torch.Size([256, 256])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237669289112091 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "Shape of aligned wt is  torch.Size([256, 256, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 15 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([256, 256, 3, 3])\n",
      "In layer model.layer4.0.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 35.0353889465332, Mean : 4.7468671798706055, Min : 1.59151604748331e-05, Std: 5.94332218170166\n",
      "At layer idx 15 and shape torch.Size([512, 256, 3, 3]), the OT cost is  178.11100249085575\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer4.0.conv1.weight, frobenius norm from the joe's transport map is 0.04415099322795868\n",
      "shape of T_var is  torch.Size([512, 512])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "T_var stats: max 0.9999488592147827, min 0.0, mean 0.0019530251156538725, std 0.044148821383714676 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "Shape of aligned wt is  torch.Size([512, 256, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 16 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([512, 256, 3, 3])\n",
      "In layer model.layer4.0.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 31.021957397460938, Mean : 3.7388510704040527, Min : 0.0, Std: 5.186460494995117\n",
      "At layer idx 16 and shape torch.Size([512, 512, 3, 3]), the OT cost is  152.34927530307323\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer4.0.conv2.weight, frobenius norm from the joe's transport map is 0.04415099322795868\n",
      "shape of T_var is  torch.Size([512, 512])\n",
      "T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0020, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9999, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "T_var stats: max 0.9999488592147827, min 0.0, mean 0.0019530251156538725, std 0.044148821383714676 \n",
      "the transport map is  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9999, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "Shape of aligned wt is  torch.Size([512, 512, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 17 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([512, 512, 3, 3])\n",
      "In layer model.layer4.0.shortcut.0.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 11.707887649536133, Mean : 2.057394504547119, Min : 0.005461016204208136, Std: 2.039292335510254\n",
      "At layer idx 17 and shape torch.Size([512, 256, 1, 1]), the OT cost is  66.78798618726432\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer4.0.shortcut.0.weight, frobenius norm from the joe's transport map is 0.04415099322795868\n",
      "shape of T_var is  torch.Size([512, 512])\n",
      "T_var before correction  tensor([[0.0020, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "T_var after correction  tensor([[0.9999, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "T_var stats: max 0.9999488592147827, min 0.0, mean 0.0019530251156538725, std 0.044148821383714676 \n",
      "the transport map is  tensor([[0.9999, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "Shape of aligned wt is  torch.Size([512, 256, 1])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 18 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([512, 256, 1, 1])\n",
      "In layer model.layer4.1.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 16.64794921875, Mean : 2.110619068145752, Min : 0.0001239692501258105, Std: 2.782703399658203\n",
      "averaging multiple T_var's\n",
      "At layer idx 18 and shape torch.Size([512, 512, 3, 3]), the OT cost is  80.46800544578582\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer4.1.conv1.weight, frobenius norm from the joe's transport map is 0.04415099322795868\n",
      "shape of T_var is  torch.Size([512, 512])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "T_var stats: max 0.9999488592147827, min 0.0, mean 0.0019530251156538725, std 0.044148821383714676 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "Shape of aligned wt is  torch.Size([512, 512, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 19 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([512, 512, 3, 3])\n",
      "In layer model.layer4.1.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 29.757312774658203, Mean : 3.270477533340454, Min : 8.752797839406412e-06, Std: 4.788403511047363\n",
      "At layer idx 19 and shape torch.Size([512, 512, 3, 3]), the OT cost is  136.6679454818368\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer4.1.conv2.weight, frobenius norm from the joe's transport map is 0.04415099322795868\n",
      "shape of T_var is  torch.Size([512, 512])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "T_var stats: max 0.9999488592147827, min 0.0, mean 0.0019530251156538725, std 0.044148821383714676 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "Shape of aligned wt is  torch.Size([512, 512, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 20 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([512, 512, 3, 3])\n",
      "In layer model.fc.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 348.47125244140625, Mean : 241.0518035888672, Min : 61.97772216796875, Std: 86.02312469482422\n",
      "At layer idx 20 and shape torch.Size([10, 512]), the OT cost is  61.977727127075205\n",
      "Tmap stats (before correction) \n",
      ": For layer model.fc.weight, frobenius norm from the joe's transport map is 0.30000001192092896\n",
      "shape of T_var is  torch.Size([10, 10])\n",
      "T_var before correction  tensor([[0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.1000]], device='cuda:0')\n",
      "T_var after correction  tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='cuda:0')\n",
      "T_var stats: max 0.9999990463256836, min 0.0, mean 0.09999990463256836, std 0.3015110492706299 \n",
      "the transport map is  tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='cuda:0')\n",
      "Shape of aligned wt is  torch.Size([10, 512])\n",
      "EXIT\n",
      "len of model_state_dict is  21\n",
      "len of new_params is  21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:395: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 20/20 [00:02<00:00,  7.23it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy          0.7070000171661377\n",
      "        val_loss            0.8264163136482239\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>trainer/global_step</td><td>0</td></tr><tr><td>val_accuracy</td><td>0.707</td></tr><tr><td>val_loss</td><td>0.82642</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">colorful-deluge-151</strong> at: <a href='https://wandb.ai/model-fusion/model-fusion/runs/1uobkka5' target=\"_blank\">https://wandb.ai/model-fusion/model-fusion/runs/1uobkka5</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240110_144228-1uobkka5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# model parameters:  21\n",
      "# new parameters:  21\n",
      "fusing:  model.conv1.weight\n",
      "fusing:  model.layer1.0.conv1.weight\n",
      "fusing:  model.layer1.0.conv2.weight\n",
      "fusing:  model.layer1.1.conv1.weight\n",
      "fusing:  model.layer1.1.conv2.weight\n",
      "fusing:  model.layer2.0.conv1.weight\n",
      "fusing:  model.layer2.0.conv2.weight\n",
      "fusing:  model.layer2.0.shortcut.0.weight\n",
      "fusing:  model.layer2.1.conv1.weight\n",
      "fusing:  model.layer2.1.conv2.weight\n",
      "fusing:  model.layer3.0.conv1.weight\n",
      "fusing:  model.layer3.0.conv2.weight\n",
      "fusing:  model.layer3.0.shortcut.0.weight\n",
      "fusing:  model.layer3.1.conv1.weight\n",
      "fusing:  model.layer3.1.conv2.weight\n",
      "fusing:  model.layer4.0.conv1.weight\n",
      "fusing:  model.layer4.0.conv2.weight\n",
      "fusing:  model.layer4.0.shortcut.0.weight\n",
      "fusing:  model.layer4.1.conv1.weight\n",
      "fusing:  model.layer4.1.conv2.weight\n",
      "fusing:  model.fc.weight\n",
      "------- Evaluating ot fusion model -------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240110_144328-x6bcscfj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/model-fusion/Model%20Fusion/runs/x6bcscfj' target=\"_blank\">resnet18_cifar10_batch_size_512_ot_model_fusion-kvuejplb-kwdhgbfv</a></strong> to <a href='https://wandb.ai/model-fusion/Model%20Fusion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/model-fusion/Model%20Fusion' target=\"_blank\">https://wandb.ai/model-fusion/Model%20Fusion</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/model-fusion/Model%20Fusion/runs/x6bcscfj' target=\"_blank\">https://wandb.ai/model-fusion/Model%20Fusion/runs/x6bcscfj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 20/20 [00:02<00:00,  7.35it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy           0.638700008392334\n",
      "        val_loss            1.1329255104064941\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>trainer/global_step</td><td>0</td></tr><tr><td>val_accuracy</td><td>0.6387</td></tr><tr><td>val_loss</td><td>1.13293</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18_cifar10_batch_size_512_ot_model_fusion-kvuejplb-kwdhgbfv</strong> at: <a href='https://wandb.ai/model-fusion/Model%20Fusion/runs/x6bcscfj' target=\"_blank\">https://wandb.ai/model-fusion/Model%20Fusion/runs/x6bcscfj</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240110_144328-x6bcscfj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OT model fusion + eval aligned model\n",
    "print(\"------- Computing model fusion -------\")\n",
    "\n",
    "wandb_tag = f\"ot_model_fusion-{runA}-{runB}\"\n",
    "\n",
    "ot_fused_model, modelA_aligned = otfusion_experiment.run_otfusion(\n",
    "    batch_size=batch_size,\n",
    "    datamodule_type=datamodule_type,\n",
    "    datamodule_hparams=datamodule_hparams,\n",
    "    model_type=model_type,\n",
    "    model_hparams=model_hparams,\n",
    "    modelA=modelA,\n",
    "    modelB=modelB,\n",
    "    wandb_tag=wandb_tag\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Computing LMC barrier after alignment -------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Alpha: 0.00 (model 2), Train average loss: 0.07371 Train barrier:  0\n",
      "Alpha: 1.00 (model 1), Train average loss: 0.72209 Train barrier:  0\n",
      "Alpha: 0.05, Train average loss: 0.07697 Train barrier -0.02916156642205185\n",
      "Alpha: 0.10, Train average loss: 0.10224 Train barrier -0.036304237036572595\n",
      "Alpha: 0.15, Train average loss: 0.15637 Train barrier -0.014599689911140357\n",
      "Alpha: 0.20, Train average loss: 0.24447 Train barrier 0.041083947186999814\n",
      "Alpha: 0.25, Train average loss: 0.36551 Train barrier 0.1297019925869173\n",
      "Alpha: 0.30, Train average loss: 0.51276 Train barrier 0.2445321886877218\n",
      "Alpha: 0.35, Train average loss: 0.67392 Train barrier 0.37328084529009126\n",
      "Alpha: 0.40, Train average loss: 0.83399 Train barrier 0.5009275867025057\n",
      "Alpha: 0.45, Train average loss: 0.97836 Train barrier 0.6128798741125397\n",
      "Alpha: 0.50, Train average loss: 1.09665 Train barrier 0.6987496351248689\n",
      "Alpha: 0.55, Train average loss: 1.18302 Train barrier 0.7527008062273264\n",
      "Alpha: 0.60, Train average loss: 1.23587 Train barrier 0.7731380515019097\n",
      "Alpha: 0.65, Train average loss: 1.25561 Train barrier 0.7604565573940674\n",
      "Alpha: 0.70, Train average loss: 1.24359 Train barrier 0.7160201133986314\n",
      "Alpha: 0.75, Train average loss: 1.20154 Train barrier 0.6415471540613307\n",
      "Alpha: 0.80, Train average loss: 1.13201 Train barrier 0.5395940224183929\n",
      "Alpha: 0.85, Train average loss: 1.03950 Train barrier 0.41466901689867164\n",
      "Alpha: 0.90, Train average loss: 0.93179 Train barrier 0.27453956410951086\n",
      "Alpha: 0.95, Train average loss: 0.82063 Train barrier 0.1309579530282151\n",
      "Loss model 1: 0.72209, Loss model 2: 0.07371, Alpha argmax: 0.60000\n",
      "Barrier: 0.77314\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Vanilla loss pre fine-tuning: 2.20458828163147\n",
      "Fused loss pre fine-tuning: 1.096652448018392\n"
     ]
    }
   ],
   "source": [
    "# LMC barrier\n",
    "print(\"------- Computing LMC barrier after alignment -------\")\n",
    "\n",
    "lmc_experiment.run_lmc(\n",
    "    datamodule_type=datamodule_type,\n",
    "    modelA=modelA_aligned,\n",
    "    modelB=modelB,\n",
    "    granularity=21\n",
    ")\n",
    "\n",
    "# Losses for ot fusion model and vanilla averaging model\n",
    "datamodule_hparams_lmc = {'batch_size': 1024, 'data_dir': BASE_DATA_DIR}\n",
    "datamodule_lmc = datamodule_type.get_data_module(**datamodule_hparams)\n",
    "datamodule_lmc.prepare_data()\n",
    "datamodule_lmc.setup('fit')\n",
    "\n",
    "vanilla_loss = lmc_utils.compute_loss(vanilla_averaging_model, datamodule_lmc)\n",
    "fused_loss = lmc_utils.compute_loss(ot_fused_model, datamodule_lmc)\n",
    "\n",
    "print(f\"Vanilla loss pre fine-tuning: {vanilla_loss}\")\n",
    "print(f\"Fused loss pre fine-tuning: {fused_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Computing sharpness -------\n",
      "------- Model A -------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:251: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at ..\\torch\\csrc\\autograd\\engine.cpp:1176.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top Hessian eigenvalue of this model is 8.0340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***Trace:  231.17194213867188\n",
      "------- Model B -------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "The top Hessian eigenvalue of this model is 8.3102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***Trace:  310.123238881429\n",
      "------- OT fusion model -------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "The top Hessian eigenvalue of this model is 10.7434\n",
      "\n",
      "***Trace:  245.226900100708\n"
     ]
    }
   ],
   "source": [
    "# Pyhessian (compute sharpness and eigenspectrum of base models, vanilla avg, ot fusion and finetuned solutions)\n",
    "print(\"------- Computing sharpness -------\")\n",
    "\n",
    "print(\"------- Model A -------\")\n",
    "hessian_comp = pyhessian_experiment.run_pyhessian(datamodule_type=datamodule_type, model=modelA, compute_density=False, figure_name='modelA.pdf') \n",
    "print(\"------- Model B -------\")\n",
    "hessian_comp = pyhessian_experiment.run_pyhessian(datamodule_type=datamodule_type, model=modelB, compute_density=False, figure_name='modelB.pdf')\n",
    "\n",
    "print(\"------- OT fusion model -------\")\n",
    "hessian_comp = pyhessian_experiment.run_pyhessian(datamodule_type=datamodule_type, model=ot_fused_model,  compute_density=False, figure_name='otmodel32.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Vanilla avg model -------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "The top Hessian eigenvalue of this model is 7.5738\n",
      "\n",
      "***Trace:  42.57940704639142\n"
     ]
    }
   ],
   "source": [
    "print(\"------- Vanilla avg model -------\")\n",
    "hessian_comp = pyhessian_experiment.run_pyhessian(datamodule_type=datamodule_type,model=vanilla_averaging_model,  compute_density=False, figure_name='vanilla_avg.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model A aligned to B -------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:251: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at ..\\torch\\csrc\\autograd\\engine.cpp:1176.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top Hessian eigenvalue of this model is 26.4193\n",
      "\n",
      "***Trace:  743.5815560477121\n"
     ]
    }
   ],
   "source": [
    "print(\"------- Model A aligned to B -------\")\n",
    "hessian_comp = pyhessian_experiment.run_pyhessian(datamodule_type=datamodule_type,model=modelA_aligned,  compute_density=False, figure_name='modelA_aligned.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r'C:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\Resnet_cifar10_models'\n",
    "\n",
    "modelB_name = 'model512B.t7'\n",
    "torch.save(modelB.state_dict(), save_path + '\\\\' + modelB_name)\n",
    "\n",
    "modelA_aligned_name = 'model512A_aligned_to512B.t7'\n",
    "torch.save(modelA_aligned.state_dict(), save_path + '\\\\' + modelA_aligned_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
