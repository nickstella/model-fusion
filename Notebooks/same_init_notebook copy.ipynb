{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pl_bolts\\__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pl_bolts\\__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pl_bolts\\models\\self_supervised\\amdim\\amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pl_bolts\\models\\self_supervised\\amdim\\amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pl_bolts\\losses\\self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.nce_loss = AmdimNCELoss(tclip)\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from model_fusion.config import BASE_DATA_DIR, CHECKPOINT_DIR\n",
    "from model_fusion.datasets import DataModuleType\n",
    "from model_fusion.models import ModelType\n",
    "from model_fusion.models.lightning import BaseModel \n",
    "from Experiments import lmc_experiment\n",
    "from Experiments import baselines_experiment\n",
    "from Experiments import otfusion_experiment\n",
    "import pyhessian as hessian\n",
    "from Experiments import pyhessian_experiment\n",
    "from model_fusion.plot_density import get_esd_plot\n",
    "\n",
    "# set seed for numpy based calculations\n",
    "NUMPY_SEED = 100\n",
    "np.random.seed(NUMPY_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Loading models -------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.025, 'momentum': 0.9, 'optimizer': 'sgd', 'max_epochs': 200, 'min_epochs': 50, 'model_seed': 42, 'model_type': 'ModelType.RESNET18', 'loss_module': 'CrossEntropyLoss', 'lr_scheduler': 'plateau', 'weight_decay': 0.0001, 'model_hparams': {'bias': False, 'num_classes': 10, 'num_channels': 3}, 'early_stopping': True, 'datamodule_type': 'DataModuleType.CIFAR10', 'lr_decay_factor': 0.1, 'lightning_params': {'lr': 0.025, 'momentum': 0.9, 'optimizer': 'sgd', 'model_seed': 42, 'lr_scheduler': 'plateau', 'weight_decay': 0.0001, 'lr_decay_factor': 0.1, 'lr_monitor_metric': 'val_loss'}, 'lr_monitor_metric': 'val_loss', 'datamodule_hparams': {'seed': 42, 'data_dir': 'data', 'batch_size': 32, 'data_augmentation': True}, 'model_hparams/bias': False, 'model_hparams/num_classes': 10, 'model_hparams/num_channels': 3}\n",
      "{'seed': 42, 'data_dir': 'data', 'batch_size': 32, 'data_augmentation': True}\n",
      "{'bias': False, 'num_classes': 10, 'num_channels': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mframbelli\u001b[0m (\u001b[33mmodel-fusion\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\Notebooks\\wandb\\run-20240104_185546-8dmquqxa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/model-fusion/model-fusion/runs/8dmquqxa' target=\"_blank\">glorious-water-28</a></strong> to <a href='https://wandb.ai/model-fusion/model-fusion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/model-fusion/model-fusion' target=\"_blank\">https://wandb.ai/model-fusion/model-fusion</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/model-fusion/model-fusion/runs/8dmquqxa' target=\"_blank\">https://wandb.ai/model-fusion/model-fusion/runs/8dmquqxa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-bbecqkxs:best_k, 85.20MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-k9q16yq1:best_k, 85.20MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.4\n"
     ]
    }
   ],
   "source": [
    "print(\"------- Loading models -------\")\n",
    "\n",
    "# select wandb run names\n",
    "runA = 'bbecqkxs'\n",
    "runB = 'k9q16yq1'\n",
    "\n",
    "api = wandb.Api()\n",
    "run = api.run(f'model-fusion/Model Fusion/{runA}')\n",
    "\n",
    "print(run.config)\n",
    "\n",
    "batch_size = run.config['datamodule_hparams'].get('batch_size')\n",
    "\n",
    "datamodule_type_str = run.config['datamodule_type'].split('.')[1].lower()\n",
    "datamodule_type = DataModuleType(datamodule_type_str)\n",
    "datamodule_hparams = run.config['datamodule_hparams']\n",
    "\n",
    "model_type_str = run.config['model_type'].split('.')[1].lower()\n",
    "model_type = ModelType(model_type_str)\n",
    "\n",
    "# model_hparams = list(filter(lambda x: 'model_hparams/' in x[0], run.config.items()))\n",
    "# model_hparams = {k.split('/')[1]: v for k, v in model_hparams}\n",
    "\n",
    "model_hparams = run.config['model_hparams']\n",
    "\n",
    "print(datamodule_hparams)\n",
    "print(model_hparams)\n",
    "\n",
    "checkpointA = f'model-fusion/Model Fusion/model-{runA}:best_k'\n",
    "checkpointB = f'model-fusion/Model Fusion/model-{runB}:best_k'\n",
    "\n",
    "run = wandb.init()\n",
    "\n",
    "artifact = run.use_artifact(checkpointA, type='model')\n",
    "artifact_dir = artifact.download(root=CHECKPOINT_DIR)\n",
    "modelA = BaseModel.load_from_checkpoint(Path(artifact_dir)/\"model.ckpt\")\n",
    "\n",
    "torch.save(modelA.model.state_dict(), 'model0.ckpt')\n",
    "\n",
    "artifact = run.use_artifact(checkpointB, type='model')\n",
    "artifact_dir = artifact.download(root=CHECKPOINT_DIR)\n",
    "modelB = BaseModel.load_from_checkpoint(Path(artifact_dir)/\"model.ckpt\")\n",
    "\n",
    "torch.save(modelB.model.state_dict(), 'model1.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Computing LMC barrier -------\n"
     ]
    }
   ],
   "source": [
    "# LMC barrier\n",
    "print(\"------- Computing LMC barrier -------\")\n",
    "\n",
    "# # lmc_experiment.run_lmc(\n",
    "#     datamodule_type=datamodule_type,\n",
    "#     modelA=modelA,\n",
    "#     modelB=modelB,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Computing baselines -------\n",
      "------- Prediction based ensembling -------\n",
      "------- Naive ensembling of weights -------\n",
      "------- Evaluating baselines -------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:395: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Evaluating base models -------\n",
      "Testing DataLoader 0: 100%|██████████| 10/10 [00:03<00:00,  3.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy           0.906499981880188\n",
      "        val_loss            0.37029629945755005\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Testing DataLoader 0: 100%|██████████| 10/10 [00:02<00:00,  4.09it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy           0.918999969959259\n",
      "        val_loss            0.3654583990573883\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "------- Evaluating prediction ensembling -------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.3027, Accuracy: 92.50%\n",
      "------- Evaluating vanilla averaging -------\n",
      "Testing DataLoader 0: 100%|██████████| 10/10 [00:03<00:00,  2.75it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy          0.17899999022483826\n",
      "        val_loss             2.287587881088257\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁</td></tr><tr><td>val_accuracy</td><td>██▁</td></tr><tr><td>val_loss</td><td>▁▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>trainer/global_step</td><td>0</td></tr><tr><td>val_accuracy</td><td>0.179</td></tr><tr><td>val_loss</td><td>2.28759</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stellar-vortex-25</strong> at: <a href='https://wandb.ai/model-fusion/model-fusion/runs/i8yfwn4b' target=\"_blank\">https://wandb.ai/model-fusion/model-fusion/runs/i8yfwn4b</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240104_181925-i8yfwn4b\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Baselines (prediction ensembling, vanilla averaging)\n",
    "print(\"------- Computing baselines -------\")\n",
    "\n",
    "wandb_tag = f'baselines-{runA}-{runB}'\n",
    "\n",
    "vanilla_averaging_model = baselines_experiment.run_baselines(\n",
    "    datamodule_type=datamodule_type,\n",
    "    datamodule_hparams=datamodule_hparams,\n",
    "    model_type=model_type, \n",
    "    model_hparams=model_hparams,\n",
    "    modelA=modelA,\n",
    "    modelB=modelB,\n",
    "    wandb_tag=wandb_tag,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Computing model fusion -------\n",
      "------- Setting up parameters -------\n",
      "{'seed': 42, 'data_dir': 'data', 'batch_size': 32, 'data_augmentation': True}\n",
      "The parameters are: \n",
      " {'eval_aligned': True, 'num_models': 2, 'width_ratio': 1, 'handle_skips': True, 'exact': True, 'activation_seed': 21, 'activation_histograms': True, 'ground_metric': 'euclidean', 'ground_metric_normalize': 'none', 'same_model': False, 'geom_ensemble_type': 'acts', 'act_num_samples': 200, 'skip_last_layer': False, 'skip_last_layer_type': 'average', 'softmax_temperature': 1, 'past_correction': True, 'correction': True, 'normalize_acts': False, 'normalize_wts': False, 'activation_normalize': False, 'center_acts': False, 'prelu_acts': False, 'pool_acts': False, 'pool_relu': False, 'importance': None, 'proper_marginals': False, 'not_squared': True, 'ground_metric_eff': False, 'dist_normalize': False, 'clip_gm': False, 'clip_min': 0, 'clip_max': 5, 'tmap_stats': False, 'ensemble_step': 0.5, 'reg': 0.01}\n",
      "------- OT model fusion -------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Computing activations\n",
      "this was continued,  \n",
      "this was continued,  loss_module\n",
      "this was continued,  accuracy\n",
      "this was continued,  model\n",
      "set forward hook for layer named:  model.conv1\n",
      "this was continued,  model.bn1\n",
      "this was continued,  model.layer1\n",
      "this was continued,  model.layer1.0\n",
      "set forward hook for layer named:  model.layer1.0.conv1\n",
      "this was continued,  model.layer1.0.bn1\n",
      "set forward hook for layer named:  model.layer1.0.conv2\n",
      "this was continued,  model.layer1.0.bn2\n",
      "this was continued,  model.layer1.0.shortcut\n",
      "this was continued,  model.layer1.1\n",
      "set forward hook for layer named:  model.layer1.1.conv1\n",
      "this was continued,  model.layer1.1.bn1\n",
      "set forward hook for layer named:  model.layer1.1.conv2\n",
      "this was continued,  model.layer1.1.bn2\n",
      "this was continued,  model.layer1.1.shortcut\n",
      "this was continued,  model.layer2\n",
      "this was continued,  model.layer2.0\n",
      "set forward hook for layer named:  model.layer2.0.conv1\n",
      "this was continued,  model.layer2.0.bn1\n",
      "set forward hook for layer named:  model.layer2.0.conv2\n",
      "this was continued,  model.layer2.0.bn2\n",
      "this was continued,  model.layer2.0.shortcut\n",
      "set forward hook for layer named:  model.layer2.0.shortcut.0\n",
      "this was continued,  model.layer2.0.shortcut.1\n",
      "this was continued,  model.layer2.1\n",
      "set forward hook for layer named:  model.layer2.1.conv1\n",
      "this was continued,  model.layer2.1.bn1\n",
      "set forward hook for layer named:  model.layer2.1.conv2\n",
      "this was continued,  model.layer2.1.bn2\n",
      "this was continued,  model.layer2.1.shortcut\n",
      "this was continued,  model.layer3\n",
      "this was continued,  model.layer3.0\n",
      "set forward hook for layer named:  model.layer3.0.conv1\n",
      "this was continued,  model.layer3.0.bn1\n",
      "set forward hook for layer named:  model.layer3.0.conv2\n",
      "this was continued,  model.layer3.0.bn2\n",
      "this was continued,  model.layer3.0.shortcut\n",
      "set forward hook for layer named:  model.layer3.0.shortcut.0\n",
      "this was continued,  model.layer3.0.shortcut.1\n",
      "this was continued,  model.layer3.1\n",
      "set forward hook for layer named:  model.layer3.1.conv1\n",
      "this was continued,  model.layer3.1.bn1\n",
      "set forward hook for layer named:  model.layer3.1.conv2\n",
      "this was continued,  model.layer3.1.bn2\n",
      "this was continued,  model.layer3.1.shortcut\n",
      "this was continued,  model.layer4\n",
      "this was continued,  model.layer4.0\n",
      "set forward hook for layer named:  model.layer4.0.conv1\n",
      "this was continued,  model.layer4.0.bn1\n",
      "set forward hook for layer named:  model.layer4.0.conv2\n",
      "this was continued,  model.layer4.0.bn2\n",
      "this was continued,  model.layer4.0.shortcut\n",
      "set forward hook for layer named:  model.layer4.0.shortcut.0\n",
      "this was continued,  model.layer4.0.shortcut.1\n",
      "this was continued,  model.layer4.1\n",
      "set forward hook for layer named:  model.layer4.1.conv1\n",
      "this was continued,  model.layer4.1.bn1\n",
      "set forward hook for layer named:  model.layer4.1.conv2\n",
      "this was continued,  model.layer4.1.bn2\n",
      "this was continued,  model.layer4.1.shortcut\n",
      "set forward hook for layer named:  model.fc\n",
      "this was continued,  \n",
      "this was continued,  loss_module\n",
      "this was continued,  accuracy\n",
      "this was continued,  model\n",
      "set forward hook for layer named:  model.conv1\n",
      "this was continued,  model.bn1\n",
      "this was continued,  model.layer1\n",
      "this was continued,  model.layer1.0\n",
      "set forward hook for layer named:  model.layer1.0.conv1\n",
      "this was continued,  model.layer1.0.bn1\n",
      "set forward hook for layer named:  model.layer1.0.conv2\n",
      "this was continued,  model.layer1.0.bn2\n",
      "this was continued,  model.layer1.0.shortcut\n",
      "this was continued,  model.layer1.1\n",
      "set forward hook for layer named:  model.layer1.1.conv1\n",
      "this was continued,  model.layer1.1.bn1\n",
      "set forward hook for layer named:  model.layer1.1.conv2\n",
      "this was continued,  model.layer1.1.bn2\n",
      "this was continued,  model.layer1.1.shortcut\n",
      "this was continued,  model.layer2\n",
      "this was continued,  model.layer2.0\n",
      "set forward hook for layer named:  model.layer2.0.conv1\n",
      "this was continued,  model.layer2.0.bn1\n",
      "set forward hook for layer named:  model.layer2.0.conv2\n",
      "this was continued,  model.layer2.0.bn2\n",
      "this was continued,  model.layer2.0.shortcut\n",
      "set forward hook for layer named:  model.layer2.0.shortcut.0\n",
      "this was continued,  model.layer2.0.shortcut.1\n",
      "this was continued,  model.layer2.1\n",
      "set forward hook for layer named:  model.layer2.1.conv1\n",
      "this was continued,  model.layer2.1.bn1\n",
      "set forward hook for layer named:  model.layer2.1.conv2\n",
      "this was continued,  model.layer2.1.bn2\n",
      "this was continued,  model.layer2.1.shortcut\n",
      "this was continued,  model.layer3\n",
      "this was continued,  model.layer3.0\n",
      "set forward hook for layer named:  model.layer3.0.conv1\n",
      "this was continued,  model.layer3.0.bn1\n",
      "set forward hook for layer named:  model.layer3.0.conv2\n",
      "this was continued,  model.layer3.0.bn2\n",
      "this was continued,  model.layer3.0.shortcut\n",
      "set forward hook for layer named:  model.layer3.0.shortcut.0\n",
      "this was continued,  model.layer3.0.shortcut.1\n",
      "this was continued,  model.layer3.1\n",
      "set forward hook for layer named:  model.layer3.1.conv1\n",
      "this was continued,  model.layer3.1.bn1\n",
      "set forward hook for layer named:  model.layer3.1.conv2\n",
      "this was continued,  model.layer3.1.bn2\n",
      "this was continued,  model.layer3.1.shortcut\n",
      "this was continued,  model.layer4\n",
      "this was continued,  model.layer4.0\n",
      "set forward hook for layer named:  model.layer4.0.conv1\n",
      "this was continued,  model.layer4.0.bn1\n",
      "set forward hook for layer named:  model.layer4.0.conv2\n",
      "this was continued,  model.layer4.0.bn2\n",
      "this was continued,  model.layer4.0.shortcut\n",
      "set forward hook for layer named:  model.layer4.0.shortcut.0\n",
      "this was continued,  model.layer4.0.shortcut.1\n",
      "this was continued,  model.layer4.1\n",
      "set forward hook for layer named:  model.layer4.1.conv1\n",
      "this was continued,  model.layer4.1.bn1\n",
      "set forward hook for layer named:  model.layer4.1.conv2\n",
      "this was continued,  model.layer4.1.bn2\n",
      "this was continued,  model.layer4.1.shortcut\n",
      "set forward hook for layer named:  model.fc\n",
      "Activations computed across 200 samples out of 45000\n",
      "***********\n",
      "min of act: -13.026793479919434, max: 12.658839225769043, mean: -0.011049232445657253\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 12.658839225769043, mean: 0.34468042850494385\n",
      "***********\n",
      "min of act: -45.22306442260742, max: 14.352783203125, mean: -3.4580273628234863\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 14.352783203125, mean: 0.008328213356435299\n",
      "***********\n",
      "min of act: -7.304907321929932, max: 11.420360565185547, mean: 0.2823680341243744\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 11.420360565185547, mean: 0.3249450623989105\n",
      "***********\n",
      "min of act: -38.53377151489258, max: 12.634749412536621, mean: -4.005962371826172\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 12.634749412536621, mean: 0.010698075406253338\n",
      "***********\n",
      "min of act: -8.301993370056152, max: 12.032195091247559, mean: 0.21421976387500763\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 12.032195091247559, mean: 0.29388222098350525\n",
      "***********\n",
      "min of act: -46.63582992553711, max: 33.3905029296875, mean: -1.7405743598937988\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 33.3905029296875, mean: 0.3049854040145874\n",
      "***********\n",
      "min of act: -71.04664611816406, max: 55.62591552734375, mean: -2.255397081375122\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 55.62591552734375, mean: 0.8692861795425415\n",
      "***********\n",
      "min of act: -10.31888198852539, max: 13.215635299682617, mean: 0.05767606571316719\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 13.215635299682617, mean: 0.381287157535553\n",
      "***********\n",
      "min of act: -112.18091583251953, max: 70.82884216308594, mean: -10.714159965515137\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 70.82884216308594, mean: 0.05492167919874191\n",
      "***********\n",
      "min of act: -38.31587600708008, max: 74.54537963867188, mean: 0.13982723653316498\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 74.54537963867188, mean: 0.7429721355438232\n",
      "***********\n",
      "min of act: -118.89129638671875, max: 102.9465560913086, mean: -6.734028339385986\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 102.9465560913086, mean: 0.5499641299247742\n",
      "***********\n",
      "min of act: -132.30538940429688, max: 181.24139404296875, mean: -7.196269512176514\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 181.24139404296875, mean: 1.1007720232009888\n",
      "***********\n",
      "min of act: -35.06045913696289, max: 47.8276481628418, mean: -1.1339137554168701\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 47.8276481628418, mean: 0.6998069286346436\n",
      "***********\n",
      "min of act: -190.14639282226562, max: 175.56961059570312, mean: -16.45050811767578\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 175.56961059570312, mean: 0.31269580125808716\n",
      "***********\n",
      "min of act: -98.90692138671875, max: 135.78260803222656, mean: -3.881181240081787\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 135.78260803222656, mean: 0.7402786016464233\n",
      "***********\n",
      "min of act: -126.8451919555664, max: 145.42166137695312, mean: -6.850537300109863\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 145.42166137695312, mean: 0.6469621062278748\n",
      "***********\n",
      "min of act: -247.1476593017578, max: 186.6340789794922, mean: -10.058123588562012\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 186.6340789794922, mean: 0.5912513136863708\n",
      "***********\n",
      "min of act: -52.54418182373047, max: 53.638397216796875, mean: -1.7984520196914673\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 53.638397216796875, mean: 0.34126004576683044\n",
      "***********\n",
      "min of act: -133.46449279785156, max: 81.48041534423828, mean: -3.174445152282715\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 81.48041534423828, mean: 0.41496211290359497\n",
      "***********\n",
      "min of act: -98.95993041992188, max: 153.10983276367188, mean: -5.541122913360596\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 153.10983276367188, mean: 0.2872031033039093\n",
      "***********\n",
      "min of act: -32.613067626953125, max: 91.81171417236328, mean: 0.02171914651989937\n",
      "***********\n",
      "min of act: -12.390865325927734, max: 12.232508659362793, mean: -0.008048836141824722\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 12.232508659362793, mean: 0.34377017617225647\n",
      "***********\n",
      "min of act: -44.56227111816406, max: 12.885454177856445, mean: -3.285630226135254\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 12.885454177856445, mean: 0.0076347943395376205\n",
      "***********\n",
      "min of act: -5.196724891662598, max: 13.402826309204102, mean: 0.3004600405693054\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 13.402826309204102, mean: 0.33253031969070435\n",
      "***********\n",
      "min of act: -38.25092315673828, max: 12.513218879699707, mean: -3.963014602661133\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 12.513218879699707, mean: 0.009059297852218151\n",
      "***********\n",
      "min of act: -7.419241905212402, max: 11.985696792602539, mean: 0.2492215782403946\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 11.985696792602539, mean: 0.3076939880847931\n",
      "***********\n",
      "min of act: -42.19990158081055, max: 31.274038314819336, mean: -1.9827204942703247\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 31.274038314819336, mean: 0.3033415675163269\n",
      "***********\n",
      "min of act: -78.2854232788086, max: 66.97758483886719, mean: -2.4800803661346436\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 66.97758483886719, mean: 0.8429401516914368\n",
      "***********\n",
      "min of act: -9.670333862304688, max: 21.076824188232422, mean: 0.04337766021490097\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 21.076824188232422, mean: 0.3875148296356201\n",
      "***********\n",
      "min of act: -133.8597412109375, max: 96.66165924072266, mean: -11.871809959411621\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 96.66165924072266, mean: 0.050094932317733765\n",
      "***********\n",
      "min of act: -45.999698638916016, max: 94.19615173339844, mean: 0.12017098069190979\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 94.19615173339844, mean: 0.7312096953392029\n",
      "***********\n",
      "min of act: -104.4450454711914, max: 108.24341583251953, mean: -7.2762770652771\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 108.24341583251953, mean: 0.6034337878227234\n",
      "***********\n",
      "min of act: -161.3336181640625, max: 190.91329956054688, mean: -8.600397109985352\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 190.91329956054688, mean: 1.2131638526916504\n",
      "***********\n",
      "min of act: -31.71039581298828, max: 45.65843963623047, mean: -1.0020331144332886\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 45.65843963623047, mean: 0.6645083427429199\n",
      "***********\n",
      "min of act: -242.84664916992188, max: 256.30291748046875, mean: -21.209680557250977\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 256.30291748046875, mean: 0.3272608816623688\n",
      "***********\n",
      "min of act: -157.604736328125, max: 197.98486328125, mean: -4.857811450958252\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 197.98486328125, mean: 0.8245385885238647\n",
      "***********\n",
      "min of act: -145.77000427246094, max: 185.31356811523438, mean: -8.68858814239502\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 185.31356811523438, mean: 0.7225456237792969\n",
      "***********\n",
      "min of act: -247.51318359375, max: 207.95852661132812, mean: -11.924413681030273\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 207.95852661132812, mean: 0.7034064531326294\n",
      "***********\n",
      "min of act: -54.81087112426758, max: 47.87141036987305, mean: -2.124443769454956\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 47.87141036987305, mean: 0.3849148452281952\n",
      "***********\n",
      "min of act: -180.32669067382812, max: 122.21449279785156, mean: -3.9225049018859863\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 122.21449279785156, mean: 0.5127108097076416\n",
      "***********\n",
      "min of act: -172.65704345703125, max: 168.78504943847656, mean: -8.073349952697754\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 168.78504943847656, mean: 0.3148908019065857\n",
      "***********\n",
      "min of act: -27.038724899291992, max: 89.19212341308594, mean: -0.01596127264201641\n",
      "activations for idx 1 at layer model.fc have the following shape  torch.Size([200, 1, 10])\n",
      "-----------\n",
      "INIT\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 0 ------------- \n",
      " \n",
      "Previous layer shape is  None\n",
      "In layer model.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 12.666603088378906, Mean : 4.105017185211182, Min : 0.5784119963645935, Std: 2.0506348609924316\n",
      "At layer idx 0 and shape torch.Size([64, 3, 3, 3]), the OT cost is  203.64209878444672\n",
      "Tmap stats (before correction) \n",
      ": For layer model.conv1.weight, frobenius norm from the joe's transport map is 0.12401959300041199\n",
      "shape of T_var is  torch.Size([64, 64])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999935626983643, min 0.0, mean 0.015624897554516792, std 0.12403393536806107 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([64, 3, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 1 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([64, 3, 3, 3])\n",
      "In layer model.layer1.0.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 4.144085884094238, Mean : 0.3315039873123169, Min : 0.0, Std: 0.6451191902160645\n",
      "At layer idx 1 and shape torch.Size([64, 64, 3, 3]), the OT cost is  46.657057012373116\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer1.0.conv1.weight, frobenius norm from the joe's transport map is 0.12401959300041199\n",
      "shape of T_var is  torch.Size([64, 64])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999935626983643, min 0.0, mean 0.015624897554516792, std 0.12403393536806107 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([64, 64, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 2 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([64, 64, 3, 3])\n",
      "In layer model.layer1.0.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 11.959114074707031, Mean : 3.9293651580810547, Min : 0.5784220695495605, Std: 1.947691559791565\n",
      "At layer idx 2 and shape torch.Size([64, 64, 3, 3]), the OT cost is  209.04969906806946\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer1.0.conv2.weight, frobenius norm from the joe's transport map is 0.12401959300041199\n",
      "shape of T_var is  torch.Size([64, 64])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999935626983643, min 0.0, mean 0.015624897554516792, std 0.12403393536806107 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([64, 64, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 3 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([64, 64, 3, 3])\n",
      "In layer model.layer1.1.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 5.8241753578186035, Mean : 0.4527479410171509, Min : 5.085201451038301e-07, Std: 0.8871043920516968\n",
      "At layer idx 3 and shape torch.Size([64, 64, 3, 3]), the OT cost is  66.02325678130728\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer1.1.conv1.weight, frobenius norm from the joe's transport map is 0.12401959300041199\n",
      "shape of T_var is  torch.Size([64, 64])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999935626983643, min 0.0, mean 0.015624897554516792, std 0.12403393536806107 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([64, 64, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 4 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([64, 64, 3, 3])\n",
      "In layer model.layer1.1.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 11.475240707397461, Mean : 3.741708755493164, Min : 0.5366857051849365, Std: 1.8847906589508057\n",
      "At layer idx 4 and shape torch.Size([64, 64, 3, 3]), the OT cost is  212.03622007369995\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer1.1.conv2.weight, frobenius norm from the joe's transport map is 0.12401959300041199\n",
      "shape of T_var is  torch.Size([64, 64])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999935626983643, min 0.0, mean 0.015624897554516792, std 0.12403393536806107 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([64, 64, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 5 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([64, 64, 3, 3])\n",
      "In layer model.layer2.0.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 18.092260360717773, Mean : 4.440986633300781, Min : 0.06446777284145355, Std: 3.1886911392211914\n",
      "At layer idx 5 and shape torch.Size([128, 64, 3, 3]), the OT cost is  197.77342501282692\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer2.0.conv1.weight, frobenius norm from the joe's transport map is 0.08804240077733994\n",
      "shape of T_var is  torch.Size([128, 128])\n",
      "T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0078,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var stats: max 0.9999872446060181, min 0.0, mean 0.007812399882823229, std 0.08804396539926529 \n",
      "the transport map is  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "Shape of aligned wt is  torch.Size([128, 64, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 6 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([128, 64, 3, 3])\n",
      "In layer model.layer2.0.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 36.1326789855957, Mean : 9.943266868591309, Min : 0.388879656791687, Std: 6.20470666885376\n",
      "At layer idx 6 and shape torch.Size([128, 128, 3, 3]), the OT cost is  504.07282119989395\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer2.0.conv2.weight, frobenius norm from the joe's transport map is 0.08804240077733994\n",
      "shape of T_var is  torch.Size([128, 128])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999872446060181, min 0.0, mean 0.007812399882823229, std 0.08804396539926529 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([128, 128, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 7 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([128, 128, 3, 3])\n",
      "In layer model.layer2.0.shortcut.0.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 9.809375762939453, Mean : 3.092564582824707, Min : 0.37606003880500793, Std: 1.7303475141525269\n",
      "At layer idx 7 and shape torch.Size([128, 64, 1, 1]), the OT cost is  86.01517649390735\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer2.0.shortcut.0.weight, frobenius norm from the joe's transport map is 0.08804240077733994\n",
      "shape of T_var is  torch.Size([128, 128])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999872446060181, min 0.0, mean 0.007812399882823229, std 0.08804396539926529 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([128, 64, 1])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 8 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([128, 64, 1, 1])\n",
      "In layer model.layer2.1.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 20.036476135253906, Mean : 1.2306718826293945, Min : 1.671264908509329e-05, Std: 2.7867558002471924\n",
      "averaging multiple T_var's\n",
      "At layer idx 8 and shape torch.Size([128, 128, 3, 3]), the OT cost is  151.85569756361656\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer2.1.conv1.weight, frobenius norm from the joe's transport map is 0.08804240077733994\n",
      "shape of T_var is  torch.Size([128, 128])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999872446060181, min 0.0, mean 0.007812399882823229, std 0.08804396539926529 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([128, 128, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 9 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([128, 128, 3, 3])\n",
      "In layer model.layer2.1.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 33.92799758911133, Mean : 8.879992485046387, Min : 0.29881566762924194, Std: 5.815326690673828\n",
      "At layer idx 9 and shape torch.Size([128, 128, 3, 3]), the OT cost is  471.8562556505203\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer2.1.conv2.weight, frobenius norm from the joe's transport map is 0.08804240077733994\n",
      "shape of T_var is  torch.Size([128, 128])\n",
      "T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0078, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var stats: max 0.9999872446060181, min 0.0, mean 0.007812399882823229, std 0.08804396539926529 \n",
      "the transport map is  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "Shape of aligned wt is  torch.Size([128, 128, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 10 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([128, 128, 3, 3])\n",
      "In layer model.layer3.0.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 35.16767883300781, Mean : 5.995887756347656, Min : 0.0008404137333855033, Std: 6.236684799194336\n",
      "At layer idx 10 and shape torch.Size([256, 128, 3, 3]), the OT cost is  273.26036665961146\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer3.0.conv1.weight, frobenius norm from the joe's transport map is 0.06237781047821045\n",
      "shape of T_var is  torch.Size([256, 256])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237668916583061 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([256, 128, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 11 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([256, 128, 3, 3])\n",
      "In layer model.layer3.0.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 54.97061538696289, Mean : 10.568811416625977, Min : 0.0039894296787679195, Std: 9.57552719116211\n",
      "At layer idx 11 and shape torch.Size([256, 256, 3, 3]), the OT cost is  471.82013216614723\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer3.0.conv2.weight, frobenius norm from the joe's transport map is 0.06237781047821045\n",
      "shape of T_var is  torch.Size([256, 256])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237668916583061 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([256, 256, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 12 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([256, 256, 3, 3])\n",
      "In layer model.layer3.0.shortcut.0.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 19.023170471191406, Mean : 4.830225944519043, Min : 0.16056124866008759, Std: 3.373405933380127\n",
      "At layer idx 12 and shape torch.Size([256, 128, 1, 1]), the OT cost is  146.61597125418484\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer3.0.shortcut.0.weight, frobenius norm from the joe's transport map is 0.06237781047821045\n",
      "shape of T_var is  torch.Size([256, 256])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237668916583061 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([256, 128, 1])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 13 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([256, 128, 1, 1])\n",
      "In layer model.layer3.1.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 46.43029022216797, Mean : 3.886664628982544, Min : 2.637815214256989e-06, Std: 6.977875709533691\n",
      "averaging multiple T_var's\n",
      "At layer idx 13 and shape torch.Size([256, 256, 3, 3]), the OT cost is  287.6853074133396\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer3.1.conv1.weight, frobenius norm from the joe's transport map is 0.06237781047821045\n",
      "shape of T_var is  torch.Size([256, 256])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237668916583061 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([256, 256, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 14 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([256, 256, 3, 3])\n",
      "In layer model.layer3.1.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 53.595272064208984, Mean : 7.871861934661865, Min : 0.00160401058383286, Std: 8.8024320602417\n",
      "At layer idx 14 and shape torch.Size([256, 256, 3, 3]), the OT cost is  413.3186370432377\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer3.1.conv2.weight, frobenius norm from the joe's transport map is 0.06237781047821045\n",
      "shape of T_var is  torch.Size([256, 256])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237668916583061 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([256, 256, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 15 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([256, 256, 3, 3])\n",
      "In layer model.layer4.0.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 38.81106185913086, Mean : 4.302982807159424, Min : 2.1529317564272787e-06, Std: 6.2055487632751465\n",
      "At layer idx 15 and shape torch.Size([512, 256, 3, 3]), the OT cost is  179.09623831138015\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer4.0.conv1.weight, frobenius norm from the joe's transport map is 0.04415099322795868\n",
      "shape of T_var is  torch.Size([512, 512])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999488592147827, min 0.0, mean 0.0019530252320691943, std 0.044148821383714676 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([512, 256, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 16 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([512, 256, 3, 3])\n",
      "In layer model.layer4.0.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 46.13599395751953, Mean : 4.208648204803467, Min : 1.159344606094237e-06, Std: 7.091593265533447\n",
      "At layer idx 16 and shape torch.Size([512, 512, 3, 3]), the OT cost is  192.29355880385265\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer4.0.conv2.weight, frobenius norm from the joe's transport map is 0.04415099322795868\n",
      "shape of T_var is  torch.Size([512, 512])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999488592147827, min 0.0, mean 0.0019530252320691943, std 0.044148821383714676 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([512, 512, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 17 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([512, 512, 3, 3])\n",
      "In layer model.layer4.0.shortcut.0.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 13.195202827453613, Mean : 1.9799113273620605, Min : 0.017688222229480743, Std: 2.14676833152771\n",
      "At layer idx 17 and shape torch.Size([512, 256, 1, 1]), the OT cost is  65.17101731710136\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer4.0.shortcut.0.weight, frobenius norm from the joe's transport map is 0.04415099322795868\n",
      "shape of T_var is  torch.Size([512, 512])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999488592147827, min 0.0, mean 0.0019530252320691943, std 0.044148821383714676 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([512, 256, 1])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 18 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([512, 256, 1, 1])\n",
      "In layer model.layer4.1.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 22.779102325439453, Mean : 2.6830265522003174, Min : 0.0006086252396926284, Std: 3.5978715419769287\n",
      "averaging multiple T_var's\n",
      "At layer idx 18 and shape torch.Size([512, 512, 3, 3]), the OT cost is  103.48459875583649\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer4.1.conv1.weight, frobenius norm from the joe's transport map is 0.04415099322795868\n",
      "shape of T_var is  torch.Size([512, 512])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999488592147827, min 0.0, mean 0.0019530252320691943, std 0.044148821383714676 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([512, 512, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 19 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([512, 512, 3, 3])\n",
      "In layer model.layer4.1.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 37.37333679199219, Mean : 2.146085023880005, Min : 0.0, Std: 5.177140235900879\n",
      "At layer idx 19 and shape torch.Size([512, 512, 3, 3]), the OT cost is  135.3231154344976\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer4.1.conv2.weight, frobenius norm from the joe's transport map is 0.04415099322795868\n",
      "shape of T_var is  torch.Size([512, 512])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999488592147827, min 0.0, mean 0.0019530252320691943, std 0.044148821383714676 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([512, 512, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 20 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([512, 512, 3, 3])\n",
      "In layer model.fc.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 291.1380920410156, Mean : 200.16757202148438, Min : 50.6240119934082, Std: 69.2433090209961\n",
      "At layer idx 20 and shape torch.Size([10, 512]), the OT cost is  50.62401008605957\n",
      "Tmap stats (before correction) \n",
      ": For layer model.fc.weight, frobenius norm from the joe's transport map is 0.30000001192092896\n",
      "shape of T_var is  torch.Size([10, 10])\n",
      "T_var before correction  tensor([[0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.1000]])\n",
      "T_var after correction  tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]])\n",
      "T_var stats: max 0.9999990463256836, min 0.0, mean 0.09999990463256836, std 0.3015110492706299 \n",
      "the transport map is  tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]])\n",
      "Shape of aligned wt is  torch.Size([10, 512])\n",
      "EXIT\n",
      "len of model_state_dict is  21\n",
      "len of new_params is  21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240104_182401-9qxdwj99</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/model-fusion/Model%20Fusion/runs/9qxdwj99' target=\"_blank\">resnet18_cifar10_batch_size_32_aligned_modelA</a></strong> to <a href='https://wandb.ai/model-fusion/Model%20Fusion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/model-fusion/Model%20Fusion' target=\"_blank\">https://wandb.ai/model-fusion/Model%20Fusion</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/model-fusion/Model%20Fusion/runs/9qxdwj99' target=\"_blank\">https://wandb.ai/model-fusion/Model%20Fusion/runs/9qxdwj99</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 313/313 [00:06<00:00, 45.05it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy          0.6895999908447266\n",
      "        val_loss            0.9318432807922363\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>trainer/global_step</td><td>0</td></tr><tr><td>val_accuracy</td><td>0.6896</td></tr><tr><td>val_loss</td><td>0.93184</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18_cifar10_batch_size_32_aligned_modelA</strong> at: <a href='https://wandb.ai/model-fusion/Model%20Fusion/runs/9qxdwj99' target=\"_blank\">https://wandb.ai/model-fusion/Model%20Fusion/runs/9qxdwj99</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240104_182401-9qxdwj99\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# model parameters:  21\n",
      "# new parameters:  21\n",
      "fusing:  model.conv1.weight\n",
      "fusing:  model.layer1.0.conv1.weight\n",
      "fusing:  model.layer1.0.conv2.weight\n",
      "fusing:  model.layer1.1.conv1.weight\n",
      "fusing:  model.layer1.1.conv2.weight\n",
      "fusing:  model.layer2.0.conv1.weight\n",
      "fusing:  model.layer2.0.conv2.weight\n",
      "fusing:  model.layer2.0.shortcut.0.weight\n",
      "fusing:  model.layer2.1.conv1.weight\n",
      "fusing:  model.layer2.1.conv2.weight\n",
      "fusing:  model.layer3.0.conv1.weight\n",
      "fusing:  model.layer3.0.conv2.weight\n",
      "fusing:  model.layer3.0.shortcut.0.weight\n",
      "fusing:  model.layer3.1.conv1.weight\n",
      "fusing:  model.layer3.1.conv2.weight\n",
      "fusing:  model.layer4.0.conv1.weight\n",
      "fusing:  model.layer4.0.conv2.weight\n",
      "fusing:  model.layer4.0.shortcut.0.weight\n",
      "fusing:  model.layer4.1.conv1.weight\n",
      "fusing:  model.layer4.1.conv2.weight\n",
      "fusing:  model.fc.weight\n",
      "------- Evaluating ot fusion model -------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240104_182417-xrd3g6cw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/model-fusion/Model%20Fusion/runs/xrd3g6cw' target=\"_blank\">resnet18_cifar10_batch_size_32_ot_model_fusion-bbecqkxs-k9q16yq1</a></strong> to <a href='https://wandb.ai/model-fusion/Model%20Fusion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/model-fusion/Model%20Fusion' target=\"_blank\">https://wandb.ai/model-fusion/Model%20Fusion</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/model-fusion/Model%20Fusion/runs/xrd3g6cw' target=\"_blank\">https://wandb.ai/model-fusion/Model%20Fusion/runs/xrd3g6cw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 313/313 [00:05<00:00, 52.73it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy          0.7246000170707703\n",
      "        val_loss            0.9455535411834717\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>trainer/global_step</td><td>0</td></tr><tr><td>val_accuracy</td><td>0.7246</td></tr><tr><td>val_loss</td><td>0.94555</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18_cifar10_batch_size_32_ot_model_fusion-bbecqkxs-k9q16yq1</strong> at: <a href='https://wandb.ai/model-fusion/Model%20Fusion/runs/xrd3g6cw' target=\"_blank\">https://wandb.ai/model-fusion/Model%20Fusion/runs/xrd3g6cw</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240104_182417-xrd3g6cw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OT model fusion + eval aligned model \n",
    "print(\"------- Computing model fusion -------\")\n",
    "\n",
    "wandb_tag = f\"ot_model_fusion-{runA}-{runB}\"\n",
    "\n",
    "ofused_model, aligned_base_model = otfusion_experiment.run_otfusion(\n",
    "    batch_size=batch_size,\n",
    "    datamodule_type=datamodule_type,\n",
    "    datamodule_hparams=datamodule_hparams,\n",
    "    model_type=model_type, \n",
    "    model_hparams=model_hparams,\n",
    "    modelA=modelA,\n",
    "    modelB=modelB,\n",
    "    wandb_tag=wandb_tag\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Computing Pyhessian I -------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "------- Computing Pyhessian II -------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:251: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at ..\\torch\\csrc\\autograd\\engine.cpp:1176.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top Hessian eigenvalue of this model is 4.3001\n",
      "\n",
      "***Trace:  156.6295593261719\n"
     ]
    }
   ],
   "source": [
    "# Pyhessian I (compute sharpness and eigenspectrum of base models, vanilla avg and ot fusion solutions)\n",
    "print(\"------- Computing Pyhessian I -------\")\n",
    "hessian_comp = pyhessian_experiment.run_pyhessian(datamodule_type=datamodule_type,model=modelA)\n",
    "\n",
    "print(\"------- Computing Pyhessian II -------\")\n",
    "\n",
    "top_eigenvalues, top_eigenvector = hessian_comp.eigenvalues()\n",
    "print(\"The top Hessian eigenvalue of this model is %.4f\"%top_eigenvalues[-1])\n",
    "\n",
    "trace = hessian_comp.trace()\n",
    "\n",
    "print('\\n***Trace: ', np.mean(trace))\n",
    "\n",
    "density_eigen, density_weight = hessian_comp.density()\n",
    "\n",
    "get_esd_plot(density_eigen, density_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison II (compute sharpness of finetuned solutions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
