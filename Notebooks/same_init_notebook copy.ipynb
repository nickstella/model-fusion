{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alecabodi/ethz_model_fusion/.venv/lib/python3.11/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "/Users/alecabodi/ethz_model_fusion/.venv/lib/python3.11/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "/Users/alecabodi/ethz_model_fusion/.venv/lib/python3.11/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
      "/Users/alecabodi/ethz_model_fusion/.venv/lib/python3.11/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
      "/Users/alecabodi/ethz_model_fusion/.venv/lib/python3.11/site-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.nce_loss = AmdimNCELoss(tclip)\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from model_fusion.config import BASE_DATA_DIR, CHECKPOINT_DIR\n",
    "from model_fusion.datasets import DataModuleType\n",
    "from model_fusion.models import ModelType\n",
    "from model_fusion.models.lightning import BaseModel \n",
    "from Experiments import lmc_experiment\n",
    "from Experiments import baselines_experiment\n",
    "from Experiments import otfusion_experiment\n",
    "import pyhessian as hessian\n",
    "from Experiments import pyhessian_experiment\n",
    "\n",
    "# set seed for numpy based calculations\n",
    "NUMPY_SEED = 100\n",
    "np.random.seed(NUMPY_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Loading models -------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.025, 'momentum': 0.9, 'optimizer': 'sgd', 'max_epochs': 200, 'min_epochs': 50, 'model_seed': 42, 'model_type': 'ModelType.RESNET18', 'loss_module': 'CrossEntropyLoss', 'lr_scheduler': 'plateau', 'weight_decay': 0.0001, 'model_hparams': {'bias': False, 'num_classes': 10, 'num_channels': 3}, 'early_stopping': True, 'datamodule_type': 'DataModuleType.CIFAR10', 'lr_decay_factor': 0.1, 'lightning_params': {'lr': 0.025, 'momentum': 0.9, 'optimizer': 'sgd', 'model_seed': 42, 'lr_scheduler': 'plateau', 'weight_decay': 0.0001, 'lr_decay_factor': 0.1, 'lr_monitor_metric': 'val_loss'}, 'lr_monitor_metric': 'val_loss', 'datamodule_hparams': {'seed': 42, 'data_dir': 'data', 'batch_size': 32, 'data_augmentation': True}, 'model_hparams/bias': False, 'model_hparams/num_classes': 10, 'model_hparams/num_channels': 3}\n",
      "{'seed': 42, 'data_dir': 'data', 'batch_size': 32, 'data_augmentation': True}\n",
      "{'bias': False, 'num_classes': 10, 'num_channels': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33macabodi\u001b[0m (\u001b[33mmodel-fusion\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/alecabodi/ethz_model_fusion/Notebooks/wandb/run-20240104_180036-lqw22vuw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/model-fusion/ethz_model_fusion-Notebooks/runs/lqw22vuw' target=\"_blank\">radiant-dream-111</a></strong> to <a href='https://wandb.ai/model-fusion/ethz_model_fusion-Notebooks' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/model-fusion/ethz_model_fusion-Notebooks' target=\"_blank\">https://wandb.ai/model-fusion/ethz_model_fusion-Notebooks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/model-fusion/ethz_model_fusion-Notebooks/runs/lqw22vuw' target=\"_blank\">https://wandb.ai/model-fusion/ethz_model_fusion-Notebooks/runs/lqw22vuw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-bbecqkxs:best_k, 85.20MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-k9q16yq1:best_k, 85.20MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"------- Loading models -------\")\n",
    "\n",
    "# select wandb run names\n",
    "runA = 'bbecqkxs'\n",
    "runB = 'k9q16yq1'\n",
    "\n",
    "api = wandb.Api()\n",
    "run = api.run(f'model-fusion/Model Fusion/{runA}')\n",
    "\n",
    "print(run.config)\n",
    "\n",
    "batch_size = run.config['datamodule_hparams'].get('batch_size')\n",
    "\n",
    "datamodule_type_str = run.config['datamodule_type'].split('.')[1].lower()\n",
    "datamodule_type = DataModuleType(datamodule_type_str)\n",
    "datamodule_hparams = run.config['datamodule_hparams']\n",
    "\n",
    "model_type_str = run.config['model_type'].split('.')[1].lower()\n",
    "model_type = ModelType(model_type_str)\n",
    "\n",
    "# model_hparams = list(filter(lambda x: 'model_hparams/' in x[0], run.config.items()))\n",
    "# model_hparams = {k.split('/')[1]: v for k, v in model_hparams}\n",
    "\n",
    "model_hparams = run.config['model_hparams']\n",
    "\n",
    "print(datamodule_hparams)\n",
    "print(model_hparams)\n",
    "\n",
    "checkpointA = f'model-fusion/Model Fusion/model-{runA}:best_k'\n",
    "checkpointB = f'model-fusion/Model Fusion/model-{runB}:best_k'\n",
    "\n",
    "run = wandb.init()\n",
    "\n",
    "artifact = run.use_artifact(checkpointA, type='model')\n",
    "artifact_dir = artifact.download(root=CHECKPOINT_DIR)\n",
    "modelA = BaseModel.load_from_checkpoint(Path(artifact_dir)/\"model.ckpt\")\n",
    "\n",
    "torch.save(modelA.model.state_dict(), 'model0.ckpt')\n",
    "\n",
    "artifact = run.use_artifact(checkpointB, type='model')\n",
    "artifact_dir = artifact.download(root=CHECKPOINT_DIR)\n",
    "modelB = BaseModel.load_from_checkpoint(Path(artifact_dir)/\"model.ckpt\")\n",
    "\n",
    "torch.save(modelB.model.state_dict(), 'model1.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Computing LMC barrier -------\n"
     ]
    }
   ],
   "source": [
    "# LMC barrier\n",
    "print(\"------- Computing LMC barrier -------\")\n",
    "\n",
    "# # lmc_experiment.run_lmc(\n",
    "#     datamodule_type=datamodule_type,\n",
    "#     modelA=modelA,\n",
    "#     modelB=modelB,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Computing baselines -------\n",
      "------- Prediction based ensembling -------\n",
      "------- Naive ensembling of weights -------\n",
      "------- Evaluating baselines -------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alecabodi/ethz_model_fusion/.venv/lib/python3.11/site-packages/pytorch_lightning/loggers/wandb.py:395: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alecabodi/ethz_model_fusion/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Evaluating base models -------\n",
      "Testing DataLoader 0: 100%|██████████| 10/10 [03:06<00:00,  0.05it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy           0.906499981880188\n",
      "        val_loss            0.3702908754348755\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Testing DataLoader 0: 100%|██████████| 10/10 [03:15<00:00,  0.05it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy          0.9190000295639038\n",
      "        val_loss            0.36544451117515564\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "------- Evaluating prediction ensembling -------\n"
     ]
    }
   ],
   "source": [
    "# Baselines (prediction ensembling, vanilla averaging)\n",
    "print(\"------- Computing baselines -------\")\n",
    "\n",
    "wandb_tag = f'baselines-{runA}-{runB}'\n",
    "\n",
    "vanilla_averaging_model = baselines_experiment.run_baselines(\n",
    "    datamodule_type=datamodule_type,\n",
    "    datamodule_hparams=datamodule_hparams,\n",
    "    model_type=model_type, \n",
    "    model_hparams=model_hparams,\n",
    "    modelA=modelA,\n",
    "    modelB=modelB,\n",
    "    wandb_tag=wandb_tag,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Computing model fusion -------\n",
      "------- Setting up parameters -------\n",
      "{'seed': 42, 'data_dir': 'data', 'batch_size': 32, 'data_augmentation': True}\n",
      "The parameters are: \n",
      " {'eval_aligned': True, 'num_models': 2, 'width_ratio': 1, 'handle_skips': True, 'exact': True, 'activation_seed': 21, 'activation_histograms': True, 'ground_metric': 'euclidean', 'ground_metric_normalize': 'none', 'same_model': False, 'geom_ensemble_type': 'acts', 'act_num_samples': 200, 'skip_last_layer': False, 'skip_last_layer_type': 'average', 'softmax_temperature': 1, 'past_correction': True, 'correction': True, 'normalize_acts': False, 'normalize_wts': False, 'activation_normalize': False, 'center_acts': False, 'prelu_acts': False, 'pool_acts': False, 'pool_relu': False, 'importance': None, 'proper_marginals': False, 'not_squared': True, 'ground_metric_eff': False, 'dist_normalize': False, 'clip_gm': False, 'clip_min': 0, 'clip_max': 5, 'tmap_stats': False, 'ensemble_step': 0.5, 'reg': 0.01}\n",
      "------- OT model fusion -------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Computing activations\n",
      "this was continued,  \n",
      "this was continued,  loss_module\n",
      "this was continued,  accuracy\n",
      "this was continued,  model\n",
      "set forward hook for layer named:  model.conv1\n",
      "this was continued,  model.bn1\n",
      "this was continued,  model.layer1\n",
      "this was continued,  model.layer1.0\n",
      "set forward hook for layer named:  model.layer1.0.conv1\n",
      "this was continued,  model.layer1.0.bn1\n",
      "set forward hook for layer named:  model.layer1.0.conv2\n",
      "this was continued,  model.layer1.0.bn2\n",
      "this was continued,  model.layer1.0.shortcut\n",
      "this was continued,  model.layer1.1\n",
      "set forward hook for layer named:  model.layer1.1.conv1\n",
      "this was continued,  model.layer1.1.bn1\n",
      "set forward hook for layer named:  model.layer1.1.conv2\n",
      "this was continued,  model.layer1.1.bn2\n",
      "this was continued,  model.layer1.1.shortcut\n",
      "this was continued,  model.layer2\n",
      "this was continued,  model.layer2.0\n",
      "set forward hook for layer named:  model.layer2.0.conv1\n",
      "this was continued,  model.layer2.0.bn1\n",
      "set forward hook for layer named:  model.layer2.0.conv2\n",
      "this was continued,  model.layer2.0.bn2\n",
      "this was continued,  model.layer2.0.shortcut\n",
      "set forward hook for layer named:  model.layer2.0.shortcut.0\n",
      "this was continued,  model.layer2.0.shortcut.1\n",
      "this was continued,  model.layer2.1\n",
      "set forward hook for layer named:  model.layer2.1.conv1\n",
      "this was continued,  model.layer2.1.bn1\n",
      "set forward hook for layer named:  model.layer2.1.conv2\n",
      "this was continued,  model.layer2.1.bn2\n",
      "this was continued,  model.layer2.1.shortcut\n",
      "this was continued,  model.layer3\n",
      "this was continued,  model.layer3.0\n",
      "set forward hook for layer named:  model.layer3.0.conv1\n",
      "this was continued,  model.layer3.0.bn1\n",
      "set forward hook for layer named:  model.layer3.0.conv2\n",
      "this was continued,  model.layer3.0.bn2\n",
      "this was continued,  model.layer3.0.shortcut\n",
      "set forward hook for layer named:  model.layer3.0.shortcut.0\n",
      "this was continued,  model.layer3.0.shortcut.1\n",
      "this was continued,  model.layer3.1\n",
      "set forward hook for layer named:  model.layer3.1.conv1\n",
      "this was continued,  model.layer3.1.bn1\n",
      "set forward hook for layer named:  model.layer3.1.conv2\n",
      "this was continued,  model.layer3.1.bn2\n",
      "this was continued,  model.layer3.1.shortcut\n",
      "this was continued,  model.layer4\n",
      "this was continued,  model.layer4.0\n",
      "set forward hook for layer named:  model.layer4.0.conv1\n",
      "this was continued,  model.layer4.0.bn1\n",
      "set forward hook for layer named:  model.layer4.0.conv2\n",
      "this was continued,  model.layer4.0.bn2\n",
      "this was continued,  model.layer4.0.shortcut\n",
      "set forward hook for layer named:  model.layer4.0.shortcut.0\n",
      "this was continued,  model.layer4.0.shortcut.1\n",
      "this was continued,  model.layer4.1\n",
      "set forward hook for layer named:  model.layer4.1.conv1\n",
      "this was continued,  model.layer4.1.bn1\n",
      "set forward hook for layer named:  model.layer4.1.conv2\n",
      "this was continued,  model.layer4.1.bn2\n",
      "this was continued,  model.layer4.1.shortcut\n",
      "set forward hook for layer named:  model.fc\n",
      "this was continued,  \n",
      "this was continued,  loss_module\n",
      "this was continued,  accuracy\n",
      "this was continued,  model\n",
      "set forward hook for layer named:  model.conv1\n",
      "this was continued,  model.bn1\n",
      "this was continued,  model.layer1\n",
      "this was continued,  model.layer1.0\n",
      "set forward hook for layer named:  model.layer1.0.conv1\n",
      "this was continued,  model.layer1.0.bn1\n",
      "set forward hook for layer named:  model.layer1.0.conv2\n",
      "this was continued,  model.layer1.0.bn2\n",
      "this was continued,  model.layer1.0.shortcut\n",
      "this was continued,  model.layer1.1\n",
      "set forward hook for layer named:  model.layer1.1.conv1\n",
      "this was continued,  model.layer1.1.bn1\n",
      "set forward hook for layer named:  model.layer1.1.conv2\n",
      "this was continued,  model.layer1.1.bn2\n",
      "this was continued,  model.layer1.1.shortcut\n",
      "this was continued,  model.layer2\n",
      "this was continued,  model.layer2.0\n",
      "set forward hook for layer named:  model.layer2.0.conv1\n",
      "this was continued,  model.layer2.0.bn1\n",
      "set forward hook for layer named:  model.layer2.0.conv2\n",
      "this was continued,  model.layer2.0.bn2\n",
      "this was continued,  model.layer2.0.shortcut\n",
      "set forward hook for layer named:  model.layer2.0.shortcut.0\n",
      "this was continued,  model.layer2.0.shortcut.1\n",
      "this was continued,  model.layer2.1\n",
      "set forward hook for layer named:  model.layer2.1.conv1\n",
      "this was continued,  model.layer2.1.bn1\n",
      "set forward hook for layer named:  model.layer2.1.conv2\n",
      "this was continued,  model.layer2.1.bn2\n",
      "this was continued,  model.layer2.1.shortcut\n",
      "this was continued,  model.layer3\n",
      "this was continued,  model.layer3.0\n",
      "set forward hook for layer named:  model.layer3.0.conv1\n",
      "this was continued,  model.layer3.0.bn1\n",
      "set forward hook for layer named:  model.layer3.0.conv2\n",
      "this was continued,  model.layer3.0.bn2\n",
      "this was continued,  model.layer3.0.shortcut\n",
      "set forward hook for layer named:  model.layer3.0.shortcut.0\n",
      "this was continued,  model.layer3.0.shortcut.1\n",
      "this was continued,  model.layer3.1\n",
      "set forward hook for layer named:  model.layer3.1.conv1\n",
      "this was continued,  model.layer3.1.bn1\n",
      "set forward hook for layer named:  model.layer3.1.conv2\n",
      "this was continued,  model.layer3.1.bn2\n",
      "this was continued,  model.layer3.1.shortcut\n",
      "this was continued,  model.layer4\n",
      "this was continued,  model.layer4.0\n",
      "set forward hook for layer named:  model.layer4.0.conv1\n",
      "this was continued,  model.layer4.0.bn1\n",
      "set forward hook for layer named:  model.layer4.0.conv2\n",
      "this was continued,  model.layer4.0.bn2\n",
      "this was continued,  model.layer4.0.shortcut\n",
      "set forward hook for layer named:  model.layer4.0.shortcut.0\n",
      "this was continued,  model.layer4.0.shortcut.1\n",
      "this was continued,  model.layer4.1\n",
      "set forward hook for layer named:  model.layer4.1.conv1\n",
      "this was continued,  model.layer4.1.bn1\n",
      "set forward hook for layer named:  model.layer4.1.conv2\n",
      "this was continued,  model.layer4.1.bn2\n",
      "this was continued,  model.layer4.1.shortcut\n",
      "set forward hook for layer named:  model.fc\n",
      "Activations computed across 200 samples out of 45000\n",
      "***********\n",
      "min of act: -13.026793479919434, max: 12.658839225769043, mean: -0.011049232445657253\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 12.658839225769043, mean: 0.34468042850494385\n",
      "***********\n",
      "min of act: -45.22306442260742, max: 14.352783203125, mean: -3.4580271244049072\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 14.352783203125, mean: 0.008328212425112724\n",
      "***********\n",
      "min of act: -7.304907321929932, max: 11.420360565185547, mean: 0.282368004322052\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 11.420360565185547, mean: 0.3249450623989105\n",
      "***********\n",
      "min of act: -38.53377151489258, max: 12.634749412536621, mean: -4.005962371826172\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 12.634749412536621, mean: 0.010698075406253338\n",
      "***********\n",
      "min of act: -8.301993370056152, max: 12.032195091247559, mean: 0.21421977877616882\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 12.032195091247559, mean: 0.29388222098350525\n",
      "***********\n",
      "min of act: -46.63582992553711, max: 33.3905029296875, mean: -1.7405742406845093\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 33.3905029296875, mean: 0.3049854040145874\n",
      "***********\n",
      "min of act: -71.0466537475586, max: 55.625911712646484, mean: -2.255397081375122\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 55.625911712646484, mean: 0.8692861199378967\n",
      "***********\n",
      "min of act: -10.31888198852539, max: 13.215635299682617, mean: 0.05767606571316719\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 13.215635299682617, mean: 0.38128721714019775\n",
      "***********\n",
      "min of act: -112.180908203125, max: 70.82884216308594, mean: -10.714159965515137\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 70.82884216308594, mean: 0.054921675473451614\n",
      "***********\n",
      "min of act: -38.31587219238281, max: 74.54537963867188, mean: 0.13982725143432617\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 74.54537963867188, mean: 0.7429721355438232\n",
      "***********\n",
      "min of act: -118.89129638671875, max: 102.94654846191406, mean: -6.734028339385986\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 102.94654846191406, mean: 0.5499641299247742\n",
      "***********\n",
      "min of act: -132.305419921875, max: 181.24142456054688, mean: -7.196269512176514\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 181.24142456054688, mean: 1.1007720232009888\n",
      "***********\n",
      "min of act: -35.060462951660156, max: 47.8276481628418, mean: -1.1339137554168701\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 47.8276481628418, mean: 0.699806809425354\n",
      "***********\n",
      "min of act: -190.14639282226562, max: 175.56959533691406, mean: -16.450510025024414\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 175.56959533691406, mean: 0.31269577145576477\n",
      "***********\n",
      "min of act: -98.90692138671875, max: 135.7825927734375, mean: -3.881181001663208\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 135.7825927734375, mean: 0.7402786016464233\n",
      "***********\n",
      "min of act: -126.84518432617188, max: 145.42166137695312, mean: -6.850537300109863\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 145.42166137695312, mean: 0.6469621062278748\n",
      "***********\n",
      "min of act: -247.1476593017578, max: 186.63409423828125, mean: -10.058123588562012\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 186.63409423828125, mean: 0.5912513136863708\n",
      "***********\n",
      "min of act: -52.54417037963867, max: 53.63840103149414, mean: -1.7984519004821777\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 53.63840103149414, mean: 0.34126007556915283\n",
      "***********\n",
      "min of act: -133.4644775390625, max: 81.48041534423828, mean: -3.1744449138641357\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 81.48041534423828, mean: 0.41496211290359497\n",
      "***********\n",
      "min of act: -98.95993041992188, max: 153.10983276367188, mean: -5.541122913360596\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 153.10983276367188, mean: 0.2872031331062317\n",
      "***********\n",
      "min of act: -32.61306381225586, max: 91.81171417236328, mean: 0.02171914651989937\n",
      "***********\n",
      "min of act: -12.390865325927734, max: 12.232508659362793, mean: -0.008048836141824722\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 12.232508659362793, mean: 0.34377017617225647\n",
      "***********\n",
      "min of act: -44.56227111816406, max: 12.885454177856445, mean: -3.285630226135254\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 12.885454177856445, mean: 0.0076347943395376205\n",
      "***********\n",
      "min of act: -5.196724891662598, max: 13.402826309204102, mean: 0.3004600405693054\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 13.402826309204102, mean: 0.33253031969070435\n",
      "***********\n",
      "min of act: -38.25092315673828, max: 12.513218879699707, mean: -3.963014602661133\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 12.513218879699707, mean: 0.009059297852218151\n",
      "***********\n",
      "min of act: -7.419240951538086, max: 11.985696792602539, mean: 0.2492215782403946\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 11.985696792602539, mean: 0.3076939284801483\n",
      "***********\n",
      "min of act: -42.19990921020508, max: 31.27404022216797, mean: -1.9827204942703247\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 31.27404022216797, mean: 0.3033415377140045\n",
      "***********\n",
      "min of act: -78.28540802001953, max: 66.97758483886719, mean: -2.4800803661346436\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 66.97758483886719, mean: 0.8429401516914368\n",
      "***********\n",
      "min of act: -9.670333862304688, max: 21.076824188232422, mean: 0.04337766766548157\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 21.076824188232422, mean: 0.3875148892402649\n",
      "***********\n",
      "min of act: -133.8597412109375, max: 96.6616439819336, mean: -11.871809959411621\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 96.6616439819336, mean: 0.05009493976831436\n",
      "***********\n",
      "min of act: -45.99969482421875, max: 94.19615173339844, mean: 0.12017098069190979\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 94.19615173339844, mean: 0.7312096953392029\n",
      "***********\n",
      "min of act: -104.44505310058594, max: 108.24342346191406, mean: -7.276277542114258\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 108.24342346191406, mean: 0.6034337878227234\n",
      "***********\n",
      "min of act: -161.3336181640625, max: 190.91329956054688, mean: -8.600397109985352\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 190.91329956054688, mean: 1.2131638526916504\n",
      "***********\n",
      "min of act: -31.71039581298828, max: 45.6584358215332, mean: -1.0020331144332886\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 45.6584358215332, mean: 0.6645083427429199\n",
      "***********\n",
      "min of act: -242.84664916992188, max: 256.30291748046875, mean: -21.20968246459961\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 256.30291748046875, mean: 0.3272608816623688\n",
      "***********\n",
      "min of act: -157.604736328125, max: 197.98486328125, mean: -4.85781192779541\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 197.98486328125, mean: 0.8245385885238647\n",
      "***********\n",
      "min of act: -145.76998901367188, max: 185.31356811523438, mean: -8.688587188720703\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 185.31356811523438, mean: 0.7225456237792969\n",
      "***********\n",
      "min of act: -247.51321411132812, max: 207.9585418701172, mean: -11.924413681030273\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 207.9585418701172, mean: 0.7034065127372742\n",
      "***********\n",
      "min of act: -54.81086730957031, max: 47.87140655517578, mean: -2.124444007873535\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 47.87140655517578, mean: 0.3849148154258728\n",
      "***********\n",
      "min of act: -180.32669067382812, max: 122.2145004272461, mean: -3.9225049018859863\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 122.2145004272461, mean: 0.5127107501029968\n",
      "***********\n",
      "min of act: -172.65701293945312, max: 168.78506469726562, mean: -8.073349952697754\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 168.78506469726562, mean: 0.3148908317089081\n",
      "***********\n",
      "min of act: -27.03872299194336, max: 89.19212341308594, mean: -0.015961242839694023\n",
      "activations for idx 1 at layer model.fc have the following shape  torch.Size([200, 1, 10])\n",
      "-----------\n",
      "INIT\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 0 ------------- \n",
      " \n",
      "Previous layer shape is  None\n",
      "torch.Size([200, 1, 64, 32, 32])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m------- Computing model fusion -------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m wandb_tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mot_model_fusion-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunA\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunB\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m ofused_model, aligned_base_model \u001b[38;5;241m=\u001b[39m \u001b[43motfusion_experiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_otfusion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatamodule_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatamodule_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatamodule_hparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatamodule_hparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_hparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_hparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodelA\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodelA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodelB\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodelB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwandb_tag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwandb_tag\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ethz_model_fusion/Experiments/otfusion_experiment.py:35\u001b[0m, in \u001b[0;36mrun_otfusion\u001b[0;34m(batch_size, datamodule_type, datamodule_hparams, model_type, model_hparams, modelA, modelB, wandb_tag)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m------- OT model fusion -------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m activations \u001b[38;5;241m=\u001b[39m compute_activations\u001b[38;5;241m.\u001b[39mget_model_activations(args, models, datamodule_type)\n\u001b[0;32m---> 35\u001b[0m otfused_model, aligned_base_model \u001b[38;5;241m=\u001b[39m \u001b[43mwasserstein_ensemble\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_otfused_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule_hparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m------- Evaluating ot fusion model -------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m experiment_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatamodule_type\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_batch_size_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwandb_tag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/ethz_model_fusion/model_fusion/ot_fusion/wasserstein_ensemble.py:17\u001b[0m, in \u001b[0;36mget_otfused_model\u001b[0;34m(args, networks, activations, datamodule_type, datamodule_hparams)\u001b[0m\n\u001b[1;32m     14\u001b[0m     avg_aligned_layers, aligned_base_model  \u001b[38;5;241m=\u001b[39m get_aligned_layers_wts(args, networks, datamodule_type, datamodule_hparams)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mgeom_ensemble_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124macts\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 17\u001b[0m     avg_aligned_layers, aligned_base_model \u001b[38;5;241m=\u001b[39m \u001b[43mget_aligned_layers_acts\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetworks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule_hparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m otfused_model \u001b[38;5;241m=\u001b[39m helpers\u001b[38;5;241m.\u001b[39mget_network_from_param_list(networks[\u001b[38;5;241m0\u001b[39m], avg_aligned_layers)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m otfused_model, aligned_base_model\n",
      "File \u001b[0;32m~/ethz_model_fusion/model_fusion/ot_fusion/wasserstein_ensemble.py:283\u001b[0m, in \u001b[0;36mget_aligned_layers_acts\u001b[0;34m(args, networks, activations, datamodule_type, datamodule_hparams, eps)\u001b[0m\n\u001b[1;32m    271\u001b[0m layer1_name_reduced \u001b[38;5;241m=\u001b[39m helpers\u001b[38;5;241m.\u001b[39mreduce_layer_name(layer1_name)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# print(layer0_name, layer1_name)\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# print(layer0_name_reduced, layer1_name_reduced)\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# for conv layer I need to make the act_num_samples dimension the last one, but it has the intermediate dimensions for height and width of channels, so that won't work.\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;66;03m# So convert (num_samples, layer_size, ht, wt) -> (layer_size, ht, wt, num_samples)\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m activations_0, activations_1 \u001b[38;5;241m=\u001b[39m \u001b[43mhelpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_activations\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer0_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer1_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# print(\"activations for 1st model are \", activations_0)\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# print(\"activations for 2nd model are \", activations_1)\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m activations_0\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m fc_layer0_weight\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/ethz_model_fusion/model_fusion/ot_fusion/wasserstein_helpers.py:108\u001b[0m, in \u001b[0;36mprocess_activations\u001b[0;34m(args, activations, layer0_name, layer1_name)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mprint\u001b[39m(activations[\u001b[38;5;241m0\u001b[39m][layer0_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m layer0_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    107\u001b[0m activations_0 \u001b[38;5;241m=\u001b[39m activations[\u001b[38;5;241m0\u001b[39m][layer0_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m layer0_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 108\u001b[0m \u001b[43mexit\u001b[49m()\n\u001b[1;32m    109\u001b[0m activations_1 \u001b[38;5;241m=\u001b[39m activations[\u001b[38;5;241m1\u001b[39m][layer1_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m layer1_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# assert activations_0.shape == activations_1.shape\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "# OT model fusion + eval aligned model \n",
    "print(\"------- Computing model fusion -------\")\n",
    "\n",
    "wandb_tag = f\"ot_model_fusion-{runA}-{runB}\"\n",
    "\n",
    "ofused_model, aligned_base_model = otfusion_experiment.run_otfusion(\n",
    "    batch_size=batch_size,\n",
    "    datamodule_type=datamodule_type,\n",
    "    datamodule_hparams=datamodule_hparams,\n",
    "    model_type=model_type, \n",
    "    model_hparams=model_hparams,\n",
    "    modelA=modelA,\n",
    "    modelB=modelB,\n",
    "    wandb_tag=wandb_tag\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pyhessian I (compute sharpness and eigenspectrum of base models, vanilla avg and ot fusion solutions)\n",
    "print(\"------- Computing Pyhessian I -------\")\n",
    "hessian_comp = pyhessian_experiment.run_pyhessian(datamodule_type=datamodule_type,model=modelA)\n",
    "\n",
    "top_eigenvalues, top_eigenvector = hessian_comp.eigenvalues()\n",
    "print(\"The top Hessian eigenvalue of this model is %.4f\"%top_eigenvalues[-1])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison II (compute sharpness of finetuned solutions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
