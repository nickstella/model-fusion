{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pl_bolts\\__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pl_bolts\\__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pl_bolts\\models\\self_supervised\\amdim\\amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pl_bolts\\models\\self_supervised\\amdim\\amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pl_bolts\\losses\\self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.nce_loss = AmdimNCELoss(tclip)\n"
     ]
    }
   ],
   "source": [
    "import wandb   \n",
    "import numpy as np\n",
    "import torch\n",
    "import lightning\n",
    "import copy\n",
    "from pathlib import Path\n",
    "from model_fusion.config import BASE_DATA_DIR, CHECKPOINT_DIR\n",
    "from model_fusion.datasets import DataModuleType\n",
    "from model_fusion.models import ModelType\n",
    "from model_fusion.models.lightning import BaseModel \n",
    "from Experiments import lmc_experiment\n",
    "from model_fusion import lmc_utils\n",
    "from Experiments import baselines_experiment\n",
    "from Experiments import otfusion_experiment\n",
    "from Experiments import pyhessian_experiment\n",
    "from model_fusion.train import setup_training, setup_testing\n",
    "\n",
    "\n",
    "# set seed for numpy based calculations\n",
    "NUMPY_SEED = 100\n",
    "np.random.seed(NUMPY_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Loading models -------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.1, 'momentum': 0.9, 'optimizer': 'sgd', 'max_epochs': 200, 'min_epochs': 50, 'model_seed': 42, 'model_type': 'ModelType.RESNET18', 'loss_module': 'CrossEntropyLoss', 'lr_scheduler': 'plateau', 'weight_decay': 0.0001, 'model_hparams': {'bias': False, 'num_classes': 10, 'num_channels': 3}, 'early_stopping': True, 'datamodule_type': 'DataModuleType.CIFAR10', 'lr_decay_factor': 0.1, 'lightning_params': {'lr': 0.1, 'momentum': 0.9, 'optimizer': 'sgd', 'model_seed': 42, 'lr_scheduler': 'plateau', 'weight_decay': 0.0001, 'lr_decay_factor': 0.1, 'lr_monitor_metric': 'val_loss'}, 'lr_monitor_metric': 'val_loss', 'datamodule_hparams': {'seed': 42, 'data_dir': 'data', 'batch_size': 128, 'data_augmentation': True}, 'model_hparams/bias': False, 'model_hparams/num_classes': 10, 'model_hparams/num_channels': 3}\n",
      "{'seed': 42, 'data_dir': 'data', 'batch_size': 128, 'data_augmentation': False}\n",
      "{'bias': False, 'num_classes': 10, 'num_channels': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mframbelli\u001b[0m (\u001b[33mmodel-fusion\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\Notebooks\\wandb\\run-20240108_211927-0pdlr3hn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/model-fusion/model-fusion/runs/0pdlr3hn' target=\"_blank\">radiant-brook-116</a></strong> to <a href='https://wandb.ai/model-fusion/model-fusion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/model-fusion/model-fusion' target=\"_blank\">https://wandb.ai/model-fusion/model-fusion</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/model-fusion/model-fusion/runs/0pdlr3hn' target=\"_blank\">https://wandb.ai/model-fusion/model-fusion/runs/0pdlr3hn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-3bsofnmw:best_k, 85.20MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:4.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-q2135wcz:best_k, 85.20MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:5.0\n"
     ]
    }
   ],
   "source": [
    "print(\"------- Loading models -------\")\n",
    "\n",
    "# select wandb run names\n",
    "runA = '3bsofnmw'\n",
    "runB = 'q2135wcz'#diff init\n",
    "\n",
    "api = wandb.Api()\n",
    "run = api.run(f'model-fusion/Model Fusion/{runA}')\n",
    "\n",
    "print(run.config)\n",
    "\n",
    "batch_size = run.config['datamodule_hparams'].get('batch_size')\n",
    "\n",
    "datamodule_type_str = run.config['datamodule_type'].split('.')[1].lower()\n",
    "datamodule_type = DataModuleType(datamodule_type_str)\n",
    "datamodule_hparams = run.config['datamodule_hparams']\n",
    "datamodule_hparams['data_augmentation'] = False\n",
    "\n",
    "model_type_str = run.config['model_type'].split('.')[1].lower()\n",
    "model_type = ModelType(model_type_str)\n",
    "\n",
    "model_hparams = run.config['model_hparams']\n",
    "\n",
    "print(datamodule_hparams)\n",
    "print(model_hparams)\n",
    "\n",
    "checkpointA = f'model-fusion/Model Fusion/model-{runA}:best_k'\n",
    "checkpointB = f'model-fusion/Model Fusion/model-{runB}:best_k'\n",
    "\n",
    "run = wandb.init()\n",
    "\n",
    "artifact = run.use_artifact(checkpointA, type='model')\n",
    "artifact_dir = artifact.download(root=CHECKPOINT_DIR)\n",
    "modelA = BaseModel.load_from_checkpoint(Path(artifact_dir)/\"model.ckpt\")\n",
    "\n",
    "artifact = run.use_artifact(checkpointB, type='model')\n",
    "artifact_dir = artifact.download(root=CHECKPOINT_DIR)\n",
    "modelB = BaseModel.load_from_checkpoint(Path(artifact_dir)/\"model.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Computing LMC barrier before alignment-------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Alpha: 0.00 (model 2), Train average loss: 0.04328 Train barrier:  0\n",
      "Alpha: 1.00 (model 1), Train average loss: 0.02649 Train barrier:  0\n",
      "Alpha: 0.05, Train average loss: 0.06320 Train barrier 0.020756960068096714\n",
      "Alpha: 0.10, Train average loss: 0.12675 Train barrier 0.085140895196365\n",
      "Alpha: 0.15, Train average loss: 0.28354 Train barrier 0.242778211255057\n",
      "Alpha: 0.20, Train average loss: 0.60314 Train barrier 0.563210910737978\n",
      "Alpha: 0.25, Train average loss: 1.09206 Train barrier 1.05297285503058\n",
      "Alpha: 0.30, Train average loss: 1.60480 Train barrier 1.5665566241387194\n",
      "Alpha: 0.35, Train average loss: 1.97396 Train barrier 1.936549768437594\n",
      "Alpha: 0.40, Train average loss: 2.17371 Train barrier 2.1371441627279917\n",
      "Alpha: 0.45, Train average loss: 2.26074 Train barrier 2.2250134103220867\n",
      "Alpha: 0.50, Train average loss: 2.28929 Train barrier 2.2544046237907476\n",
      "Alpha: 0.55, Train average loss: 2.27244 Train barrier 2.238388280895137\n",
      "Alpha: 0.60, Train average loss: 2.18821 Train barrier 2.1550012696306573\n",
      "Alpha: 0.65, Train average loss: 1.98541 Train barrier 1.9530430666632288\n",
      "Alpha: 0.70, Train average loss: 1.60037 Train barrier 1.5688420872913134\n",
      "Alpha: 0.75, Train average loss: 1.05709 Train barrier 1.026399212243739\n",
      "Alpha: 0.80, Train average loss: 0.55130 Train barrier 0.5214461249442895\n",
      "Alpha: 0.85, Train average loss: 0.23943 Train barrier 0.21042366527433196\n",
      "Alpha: 0.90, Train average loss: 0.09712 Train barrier 0.06895225383947293\n",
      "Alpha: 0.95, Train average loss: 0.04314 Train barrier 0.015811002573420604\n",
      "Loss model 1: 0.02649, Loss model 2: 0.04328, Alpha argmax: 0.50000\n",
      "Barrier: 2.25440\n"
     ]
    }
   ],
   "source": [
    "# LMC barrier\n",
    "print(\"------- Computing LMC barrier before alignment-------\")\n",
    "\n",
    "lmc_experiment.run_lmc(\n",
    "    datamodule_type=datamodule_type,\n",
    "    modelA=modelA,\n",
    "    modelB=modelB,\n",
    "    granularity=21\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Computing baselines -------\n",
      "------- Prediction based ensembling -------\n",
      "------- Naive ensembling of weights -------\n",
      "------- Evaluating baselines -------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:395: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Evaluating base models -------\n",
      "Testing DataLoader 0: 100%|██████████| 10/10 [00:02<00:00,  4.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy          0.9126999974250793\n",
      "        val_loss            0.40655699372291565\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Testing DataLoader 0: 100%|██████████| 10/10 [00:02<00:00,  4.44it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy          0.9027000069618225\n",
      "        val_loss            0.40986424684524536\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "------- Evaluating prediction ensembling -------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.3291, Accuracy: 92.09%\n",
      "------- Evaluating vanilla averaging -------\n",
      "Testing DataLoader 0: 100%|██████████| 10/10 [00:03<00:00,  3.09it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy          0.11840000003576279\n",
      "        val_loss             2.289398431777954\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁</td></tr><tr><td>val_accuracy</td><td>██▁</td></tr><tr><td>val_loss</td><td>▁▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>trainer/global_step</td><td>0</td></tr><tr><td>val_accuracy</td><td>0.1184</td></tr><tr><td>val_loss</td><td>2.2894</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">radiant-brook-116</strong> at: <a href='https://wandb.ai/model-fusion/model-fusion/runs/0pdlr3hn' target=\"_blank\">https://wandb.ai/model-fusion/model-fusion/runs/0pdlr3hn</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240108_211927-0pdlr3hn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Baselines (prediction ensembling, vanilla averaging)\n",
    "print(\"------- Computing baselines -------\")\n",
    "\n",
    "wandb_tag = f'baselines-{runA}-{runB}'\n",
    "\n",
    "vanilla_averaging_model = baselines_experiment.run_baselines(\n",
    "    datamodule_type=datamodule_type,\n",
    "    datamodule_hparams=datamodule_hparams,\n",
    "    model_type=model_type, \n",
    "    model_hparams=model_hparams,\n",
    "    modelA=modelA,\n",
    "    modelB=modelB,\n",
    "    wandb_tag=wandb_tag,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Computing model fusion -------\n",
      "------- Setting up parameters -------\n",
      "{'seed': 42, 'data_dir': 'data', 'batch_size': 128, 'data_augmentation': False}\n",
      "The parameters are: \n",
      " {'eval_aligned': True, 'num_models': 2, 'width_ratio': 1, 'handle_skips': True, 'exact': True, 'activation_seed': 21, 'activation_histograms': True, 'ground_metric': 'euclidean', 'ground_metric_normalize': 'none', 'same_model': False, 'geom_ensemble_type': 'acts', 'act_num_samples': 200, 'skip_last_layer': False, 'skip_last_layer_type': 'average', 'softmax_temperature': 1, 'past_correction': True, 'correction': True, 'normalize_acts': False, 'normalize_wts': False, 'activation_normalize': False, 'center_acts': False, 'prelu_acts': False, 'pool_acts': False, 'pool_relu': False, 'importance': None, 'proper_marginals': False, 'not_squared': True, 'ground_metric_eff': False, 'dist_normalize': False, 'clip_gm': False, 'clip_min': 0, 'clip_max': 5, 'tmap_stats': False, 'ensemble_step': 0.5, 'reg': 0.01}\n",
      "------- OT model fusion -------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Computing activations\n",
      "this was continued,  \n",
      "this was continued,  loss_module\n",
      "this was continued,  accuracy\n",
      "this was continued,  model\n",
      "set forward hook for layer named:  model.conv1\n",
      "this was continued,  model.bn1\n",
      "this was continued,  model.layer1\n",
      "this was continued,  model.layer1.0\n",
      "set forward hook for layer named:  model.layer1.0.conv1\n",
      "this was continued,  model.layer1.0.bn1\n",
      "set forward hook for layer named:  model.layer1.0.conv2\n",
      "this was continued,  model.layer1.0.bn2\n",
      "this was continued,  model.layer1.0.shortcut\n",
      "this was continued,  model.layer1.1\n",
      "set forward hook for layer named:  model.layer1.1.conv1\n",
      "this was continued,  model.layer1.1.bn1\n",
      "set forward hook for layer named:  model.layer1.1.conv2\n",
      "this was continued,  model.layer1.1.bn2\n",
      "this was continued,  model.layer1.1.shortcut\n",
      "this was continued,  model.layer2\n",
      "this was continued,  model.layer2.0\n",
      "set forward hook for layer named:  model.layer2.0.conv1\n",
      "this was continued,  model.layer2.0.bn1\n",
      "set forward hook for layer named:  model.layer2.0.conv2\n",
      "this was continued,  model.layer2.0.bn2\n",
      "this was continued,  model.layer2.0.shortcut\n",
      "set forward hook for layer named:  model.layer2.0.shortcut.0\n",
      "this was continued,  model.layer2.0.shortcut.1\n",
      "this was continued,  model.layer2.1\n",
      "set forward hook for layer named:  model.layer2.1.conv1\n",
      "this was continued,  model.layer2.1.bn1\n",
      "set forward hook for layer named:  model.layer2.1.conv2\n",
      "this was continued,  model.layer2.1.bn2\n",
      "this was continued,  model.layer2.1.shortcut\n",
      "this was continued,  model.layer3\n",
      "this was continued,  model.layer3.0\n",
      "set forward hook for layer named:  model.layer3.0.conv1\n",
      "this was continued,  model.layer3.0.bn1\n",
      "set forward hook for layer named:  model.layer3.0.conv2\n",
      "this was continued,  model.layer3.0.bn2\n",
      "this was continued,  model.layer3.0.shortcut\n",
      "set forward hook for layer named:  model.layer3.0.shortcut.0\n",
      "this was continued,  model.layer3.0.shortcut.1\n",
      "this was continued,  model.layer3.1\n",
      "set forward hook for layer named:  model.layer3.1.conv1\n",
      "this was continued,  model.layer3.1.bn1\n",
      "set forward hook for layer named:  model.layer3.1.conv2\n",
      "this was continued,  model.layer3.1.bn2\n",
      "this was continued,  model.layer3.1.shortcut\n",
      "this was continued,  model.layer4\n",
      "this was continued,  model.layer4.0\n",
      "set forward hook for layer named:  model.layer4.0.conv1\n",
      "this was continued,  model.layer4.0.bn1\n",
      "set forward hook for layer named:  model.layer4.0.conv2\n",
      "this was continued,  model.layer4.0.bn2\n",
      "this was continued,  model.layer4.0.shortcut\n",
      "set forward hook for layer named:  model.layer4.0.shortcut.0\n",
      "this was continued,  model.layer4.0.shortcut.1\n",
      "this was continued,  model.layer4.1\n",
      "set forward hook for layer named:  model.layer4.1.conv1\n",
      "this was continued,  model.layer4.1.bn1\n",
      "set forward hook for layer named:  model.layer4.1.conv2\n",
      "this was continued,  model.layer4.1.bn2\n",
      "this was continued,  model.layer4.1.shortcut\n",
      "set forward hook for layer named:  model.fc\n",
      "this was continued,  \n",
      "this was continued,  loss_module\n",
      "this was continued,  accuracy\n",
      "this was continued,  model\n",
      "set forward hook for layer named:  model.conv1\n",
      "this was continued,  model.bn1\n",
      "this was continued,  model.layer1\n",
      "this was continued,  model.layer1.0\n",
      "set forward hook for layer named:  model.layer1.0.conv1\n",
      "this was continued,  model.layer1.0.bn1\n",
      "set forward hook for layer named:  model.layer1.0.conv2\n",
      "this was continued,  model.layer1.0.bn2\n",
      "this was continued,  model.layer1.0.shortcut\n",
      "this was continued,  model.layer1.1\n",
      "set forward hook for layer named:  model.layer1.1.conv1\n",
      "this was continued,  model.layer1.1.bn1\n",
      "set forward hook for layer named:  model.layer1.1.conv2\n",
      "this was continued,  model.layer1.1.bn2\n",
      "this was continued,  model.layer1.1.shortcut\n",
      "this was continued,  model.layer2\n",
      "this was continued,  model.layer2.0\n",
      "set forward hook for layer named:  model.layer2.0.conv1\n",
      "this was continued,  model.layer2.0.bn1\n",
      "set forward hook for layer named:  model.layer2.0.conv2\n",
      "this was continued,  model.layer2.0.bn2\n",
      "this was continued,  model.layer2.0.shortcut\n",
      "set forward hook for layer named:  model.layer2.0.shortcut.0\n",
      "this was continued,  model.layer2.0.shortcut.1\n",
      "this was continued,  model.layer2.1\n",
      "set forward hook for layer named:  model.layer2.1.conv1\n",
      "this was continued,  model.layer2.1.bn1\n",
      "set forward hook for layer named:  model.layer2.1.conv2\n",
      "this was continued,  model.layer2.1.bn2\n",
      "this was continued,  model.layer2.1.shortcut\n",
      "this was continued,  model.layer3\n",
      "this was continued,  model.layer3.0\n",
      "set forward hook for layer named:  model.layer3.0.conv1\n",
      "this was continued,  model.layer3.0.bn1\n",
      "set forward hook for layer named:  model.layer3.0.conv2\n",
      "this was continued,  model.layer3.0.bn2\n",
      "this was continued,  model.layer3.0.shortcut\n",
      "set forward hook for layer named:  model.layer3.0.shortcut.0\n",
      "this was continued,  model.layer3.0.shortcut.1\n",
      "this was continued,  model.layer3.1\n",
      "set forward hook for layer named:  model.layer3.1.conv1\n",
      "this was continued,  model.layer3.1.bn1\n",
      "set forward hook for layer named:  model.layer3.1.conv2\n",
      "this was continued,  model.layer3.1.bn2\n",
      "this was continued,  model.layer3.1.shortcut\n",
      "this was continued,  model.layer4\n",
      "this was continued,  model.layer4.0\n",
      "set forward hook for layer named:  model.layer4.0.conv1\n",
      "this was continued,  model.layer4.0.bn1\n",
      "set forward hook for layer named:  model.layer4.0.conv2\n",
      "this was continued,  model.layer4.0.bn2\n",
      "this was continued,  model.layer4.0.shortcut\n",
      "set forward hook for layer named:  model.layer4.0.shortcut.0\n",
      "this was continued,  model.layer4.0.shortcut.1\n",
      "this was continued,  model.layer4.1\n",
      "set forward hook for layer named:  model.layer4.1.conv1\n",
      "this was continued,  model.layer4.1.bn1\n",
      "set forward hook for layer named:  model.layer4.1.conv2\n",
      "this was continued,  model.layer4.1.bn2\n",
      "this was continued,  model.layer4.1.shortcut\n",
      "set forward hook for layer named:  model.fc\n",
      "Activations computed across 200 samples out of 45000\n",
      "***********\n",
      "min of act: -12.322234153747559, max: 13.622495651245117, mean: -0.011927484534680843\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 13.622495651245117, mean: 0.34956347942352295\n",
      "***********\n",
      "min of act: -48.6121940612793, max: 13.048929214477539, mean: -1.9648733139038086\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 13.048929214477539, mean: 0.0030343818943947554\n",
      "***********\n",
      "min of act: -4.934177398681641, max: 12.303272247314453, mean: 0.33137208223342896\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 12.303272247314453, mean: 0.34402620792388916\n",
      "***********\n",
      "min of act: -44.44187927246094, max: 13.813010215759277, mean: -2.986146926879883\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 13.813010215759277, mean: 0.005436650477349758\n",
      "***********\n",
      "min of act: -9.528399467468262, max: 12.314553260803223, mean: 0.28625184297561646\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 12.314553260803223, mean: 0.3258112370967865\n",
      "***********\n",
      "min of act: -66.04761505126953, max: 41.478614807128906, mean: -1.9951603412628174\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 41.478614807128906, mean: 0.30170342326164246\n",
      "***********\n",
      "min of act: -89.4123764038086, max: 64.98352813720703, mean: -2.999631881713867\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 64.98352813720703, mean: 0.8763092756271362\n",
      "***********\n",
      "min of act: -13.225959777832031, max: 19.745973587036133, mean: -0.0015753635670989752\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 19.745973587036133, mean: 0.46635258197784424\n",
      "***********\n",
      "min of act: -131.06976318359375, max: 91.29762268066406, mean: -11.371171951293945\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 91.29762268066406, mean: 0.04420502111315727\n",
      "***********\n",
      "min of act: -35.86493682861328, max: 81.6374282836914, mean: 0.21670158207416534\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 81.6374282836914, mean: 0.7731320261955261\n",
      "***********\n",
      "min of act: -107.29345703125, max: 95.92242431640625, mean: -6.822930812835693\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 95.92242431640625, mean: 0.6780681014060974\n",
      "***********\n",
      "min of act: -167.65255737304688, max: 233.40301513671875, mean: -10.095845222473145\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 233.40301513671875, mean: 1.3429522514343262\n",
      "***********\n",
      "min of act: -35.88563537597656, max: 79.43902587890625, mean: -1.0702978372573853\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 79.43902587890625, mean: 0.7195919156074524\n",
      "***********\n",
      "min of act: -300.0367431640625, max: 263.74493408203125, mean: -21.358335494995117\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 263.74493408203125, mean: 0.33377188444137573\n",
      "***********\n",
      "min of act: -149.064453125, max: 236.14511108398438, mean: -4.7550177574157715\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 236.14511108398438, mean: 0.9239875078201294\n",
      "***********\n",
      "min of act: -142.58746337890625, max: 195.91905212402344, mean: -9.37077522277832\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 195.91905212402344, mean: 0.8217593431472778\n",
      "***********\n",
      "min of act: -212.504638671875, max: 265.8879699707031, mean: -14.209223747253418\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 265.8879699707031, mean: 0.7886229157447815\n",
      "***********\n",
      "min of act: -53.223724365234375, max: 75.47221374511719, mean: -2.5132668018341064\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 75.47221374511719, mean: 0.4092622697353363\n",
      "***********\n",
      "min of act: -150.31674194335938, max: 143.07025146484375, mean: -4.467015266418457\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 143.07025146484375, mean: 0.5998353958129883\n",
      "***********\n",
      "min of act: -149.3478546142578, max: 235.57247924804688, mean: -9.973566055297852\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 235.57247924804688, mean: 0.333976149559021\n",
      "***********\n",
      "min of act: -31.767013549804688, max: 83.02471923828125, mean: 0.011054443195462227\n",
      "***********\n",
      "min of act: -16.9566707611084, max: 17.03517723083496, mean: -0.012075891718268394\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 17.03517723083496, mean: 0.37824904918670654\n",
      "***********\n",
      "min of act: -104.55804443359375, max: 23.723356246948242, mean: -4.319337844848633\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 23.723356246948242, mean: 0.012515529058873653\n",
      "***********\n",
      "min of act: -23.25680160522461, max: 20.373794555664062, mean: 0.20729853212833405\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 20.373794555664062, mean: 0.3606981933116913\n",
      "***********\n",
      "min of act: -51.60673522949219, max: 17.707324981689453, mean: -1.80023193359375\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 17.707324981689453, mean: 0.0012379958061501384\n",
      "***********\n",
      "min of act: -7.45805025100708, max: 20.373794555664062, mean: 0.34855014085769653\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 20.373794555664062, mean: 0.35804080963134766\n",
      "***********\n",
      "min of act: -67.09793853759766, max: 30.227827072143555, mean: -2.3067996501922607\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 30.227827072143555, mean: 0.11588972061872482\n",
      "***********\n",
      "min of act: -45.4825325012207, max: 50.32133483886719, mean: -1.2587077617645264\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 50.32133483886719, mean: 0.5070316195487976\n",
      "***********\n",
      "min of act: -23.225194931030273, max: 27.42045783996582, mean: -0.23753400146961212\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 27.42045783996582, mean: 0.4687330722808838\n",
      "***********\n",
      "min of act: -67.19573211669922, max: 35.71961975097656, mean: -6.197346210479736\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 35.71961975097656, mean: 0.020087668672204018\n",
      "***********\n",
      "min of act: -17.651168823242188, max: 48.57416534423828, mean: 0.25296372175216675\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 48.57416534423828, mean: 0.4715065658092499\n",
      "***********\n",
      "min of act: -81.8100814819336, max: 83.14429473876953, mean: -3.0127570629119873\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 83.14429473876953, mean: 0.5448901653289795\n",
      "***********\n",
      "min of act: -155.33059692382812, max: 133.5614013671875, mean: -8.32954216003418\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 133.5614013671875, mean: 1.1404907703399658\n",
      "***********\n",
      "min of act: -21.63226318359375, max: 33.76889419555664, mean: -0.44920676946640015\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 33.76889419555664, mean: 0.48140308260917664\n",
      "***********\n",
      "min of act: -223.28382873535156, max: 170.7958984375, mean: -21.67229652404785\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 170.7958984375, mean: 0.24401438236236572\n",
      "***********\n",
      "min of act: -104.1087646484375, max: 152.75473022460938, mean: -3.3590521812438965\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 152.75473022460938, mean: 0.840585470199585\n",
      "***********\n",
      "min of act: -120.06925964355469, max: 151.58749389648438, mean: -8.820158958435059\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 151.58749389648438, mean: 0.8071960210800171\n",
      "***********\n",
      "min of act: -246.6518096923828, max: 266.1334228515625, mean: -13.501479148864746\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 266.1334228515625, mean: 0.8032370805740356\n",
      "***********\n",
      "min of act: -39.188316345214844, max: 54.18348693847656, mean: -1.9174952507019043\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 54.18348693847656, mean: 0.394809365272522\n",
      "***********\n",
      "min of act: -150.77806091308594, max: 116.92939758300781, mean: -6.299037933349609\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 116.92939758300781, mean: 0.7312328219413757\n",
      "***********\n",
      "min of act: -214.52337646484375, max: 331.57275390625, mean: -13.480202674865723\n",
      "applying relu ---------------\n",
      "after RELU: min of act: 0.0, max: 331.57275390625, mean: 0.26597100496292114\n",
      "***********\n",
      "min of act: -26.30194664001465, max: 68.90176391601562, mean: -0.0168114323168993\n",
      "activations for idx 1 at layer model.fc have the following shape  torch.Size([200, 1, 10])\n",
      "-----------\n",
      "INIT\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 0 ------------- \n",
      " \n",
      "Previous layer shape is  None\n",
      "In layer model.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 14.314419746398926, Mean : 4.463467597961426, Min : 0.5996456742286682, Std: 2.3452258110046387\n",
      "At layer idx 0 and shape torch.Size([64, 3, 3, 3]), the OT cost is  236.6833848953247\n",
      "Tmap stats (before correction) \n",
      ": For layer model.conv1.weight, frobenius norm from the joe's transport map is 0.12401959300041199\n",
      "shape of T_var is  torch.Size([64, 64])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999935626983643, min 0.0, mean 0.015624897554516792, std 0.12403393536806107 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([64, 3, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 1 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([64, 3, 3, 3])\n",
      "In layer model.layer1.0.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 4.521824836730957, Mean : 0.32043054699897766, Min : 4.205993263894925e-06, Std: 0.656061053276062\n",
      "At layer idx 1 and shape torch.Size([64, 64, 3, 3]), the OT cost is  59.37736925528225\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer1.0.conv1.weight, frobenius norm from the joe's transport map is 0.12401959300041199\n",
      "shape of T_var is  torch.Size([64, 64])\n",
      "T_var before correction  tensor([[0.0000, 0.0156, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0156, 0.0000]])\n",
      "T_var after correction  tensor([[0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000]])\n",
      "T_var stats: max 0.9999935626983643, min 0.0, mean 0.015624897554516792, std 0.12403393536806107 \n",
      "the transport map is  tensor([[0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000]])\n",
      "Shape of aligned wt is  torch.Size([64, 64, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 2 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([64, 64, 3, 3])\n",
      "In layer model.layer1.0.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 14.461993217468262, Mean : 4.458991050720215, Min : 0.6050035953521729, Std: 2.3588500022888184\n",
      "At layer idx 2 and shape torch.Size([64, 64, 3, 3]), the OT cost is  255.808767080307\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer1.0.conv2.weight, frobenius norm from the joe's transport map is 0.12401959300041199\n",
      "shape of T_var is  torch.Size([64, 64])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999935626983643, min 0.0, mean 0.015624897554516792, std 0.12403393536806107 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([64, 64, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 3 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([64, 64, 3, 3])\n",
      "In layer model.layer1.1.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 3.1718692779541016, Mean : 0.14941507577896118, Min : 0.0, Std: 0.4221550524234772\n",
      "At layer idx 3 and shape torch.Size([64, 64, 3, 3]), the OT cost is  32.771540995741816\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer1.1.conv1.weight, frobenius norm from the joe's transport map is 0.12401959300041199\n",
      "shape of T_var is  torch.Size([64, 64])\n",
      "T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0156, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var stats: max 0.9999935626983643, min 0.0, mean 0.015624897554516792, std 0.12403393536806107 \n",
      "the transport map is  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "Shape of aligned wt is  torch.Size([64, 64, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 4 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([64, 64, 3, 3])\n",
      "In layer model.layer1.1.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 14.121438980102539, Mean : 4.3737616539001465, Min : 0.5890212059020996, Std: 2.323014736175537\n",
      "At layer idx 4 and shape torch.Size([64, 64, 3, 3]), the OT cost is  258.3996126651764\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer1.1.conv2.weight, frobenius norm from the joe's transport map is 0.12401959300041199\n",
      "shape of T_var is  torch.Size([64, 64])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999935626983643, min 0.0, mean 0.015624897554516792, std 0.12403393536806107 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([64, 64, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 5 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([64, 64, 3, 3])\n",
      "In layer model.layer2.0.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 16.917713165283203, Mean : 3.542923927307129, Min : 0.0203228946775198, Std: 3.008723020553589\n",
      "At layer idx 5 and shape torch.Size([128, 64, 3, 3]), the OT cost is  204.42795684360976\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer2.0.conv1.weight, frobenius norm from the joe's transport map is 0.08804240077733994\n",
      "shape of T_var is  torch.Size([128, 128])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999872446060181, min 0.0, mean 0.007812399882823229, std 0.08804396539926529 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([128, 64, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 6 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([128, 64, 3, 3])\n",
      "In layer model.layer2.0.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 34.0101432800293, Mean : 8.567483901977539, Min : 0.25331687927246094, Std: 5.80631160736084\n",
      "At layer idx 6 and shape torch.Size([128, 128, 3, 3]), the OT cost is  480.40355801582336\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer2.0.conv2.weight, frobenius norm from the joe's transport map is 0.08804240077733994\n",
      "shape of T_var is  torch.Size([128, 128])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999872446060181, min 0.0, mean 0.007812399882823229, std 0.08804396539926529 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([128, 128, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 7 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([128, 128, 3, 3])\n",
      "In layer model.layer2.0.shortcut.0.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 15.242483139038086, Mean : 4.358911514282227, Min : 0.39593204855918884, Std: 2.664000988006592\n",
      "At layer idx 7 and shape torch.Size([128, 64, 1, 1]), the OT cost is  161.58916080958443\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer2.0.shortcut.0.weight, frobenius norm from the joe's transport map is 0.08804240077733994\n",
      "shape of T_var is  torch.Size([128, 128])\n",
      "T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0078, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "T_var stats: max 0.9999872446060181, min 0.0, mean 0.007812399882823229, std 0.08804396539926529 \n",
      "the transport map is  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "Shape of aligned wt is  torch.Size([128, 64, 1])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 8 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([128, 64, 1, 1])\n",
      "In layer model.layer2.1.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 15.327232360839844, Mean : 0.7928034663200378, Min : 1.2180205430922797e-06, Std: 2.0364434719085693\n",
      "averaging multiple T_var's\n",
      "At layer idx 8 and shape torch.Size([128, 128, 3, 3]), the OT cost is  114.39143762431922\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer2.1.conv1.weight, frobenius norm from the joe's transport map is 0.08804240077733994\n",
      "shape of T_var is  torch.Size([128, 128])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999872446060181, min 0.0, mean 0.007812399882823229, std 0.08804396539926529 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([128, 128, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 9 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([128, 128, 3, 3])\n",
      "In layer model.layer2.1.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 31.850650787353516, Mean : 7.798271656036377, Min : 0.2427198588848114, Std: 5.420299053192139\n",
      "At layer idx 9 and shape torch.Size([128, 128, 3, 3]), the OT cost is  447.6453068256378\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer2.1.conv2.weight, frobenius norm from the joe's transport map is 0.08804240077733994\n",
      "shape of T_var is  torch.Size([128, 128])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999872446060181, min 0.0, mean 0.007812399882823229, std 0.08804396539926529 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([128, 128, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 10 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([128, 128, 3, 3])\n",
      "In layer model.layer3.0.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 34.838233947753906, Mean : 6.144598007202148, Min : 0.0007132161990739405, Std: 6.18563175201416\n",
      "At layer idx 10 and shape torch.Size([256, 128, 3, 3]), the OT cost is  274.90927817502234\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer3.0.conv1.weight, frobenius norm from the joe's transport map is 0.06237781047821045\n",
      "shape of T_var is  torch.Size([256, 256])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237668916583061 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([256, 128, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 11 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([256, 128, 3, 3])\n",
      "In layer model.layer3.0.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 60.08253860473633, Mean : 11.514325141906738, Min : 0.003986269235610962, Std: 10.56574821472168\n",
      "At layer idx 11 and shape torch.Size([256, 256, 3, 3]), the OT cost is  522.2002031803131\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer3.0.conv2.weight, frobenius norm from the joe's transport map is 0.06237781047821045\n",
      "shape of T_var is  torch.Size([256, 256])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237668916583061 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([256, 256, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 12 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([256, 256, 3, 3])\n",
      "In layer model.layer3.0.shortcut.0.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 17.12362289428711, Mean : 4.2340168952941895, Min : 0.15598684549331665, Std: 3.067216157913208\n",
      "At layer idx 12 and shape torch.Size([256, 128, 1, 1]), the OT cost is  139.74175299331546\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer3.0.shortcut.0.weight, frobenius norm from the joe's transport map is 0.06237781047821045\n",
      "shape of T_var is  torch.Size([256, 256])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237668916583061 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([256, 128, 1])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 13 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([256, 128, 1, 1])\n",
      "In layer model.layer3.1.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 47.56507873535156, Mean : 3.632972002029419, Min : 9.226570227838238e-07, Std: 7.057363510131836\n",
      "averaging multiple T_var's\n",
      "At layer idx 13 and shape torch.Size([256, 256, 3, 3]), the OT cost is  289.9763543517256\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer3.1.conv1.weight, frobenius norm from the joe's transport map is 0.06237781047821045\n",
      "shape of T_var is  torch.Size([256, 256])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237668916583061 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([256, 256, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 14 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([256, 256, 3, 3])\n",
      "In layer model.layer3.1.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 57.846675872802734, Mean : 8.795186042785645, Min : 0.002075900323688984, Std: 9.583839416503906\n",
      "At layer idx 14 and shape torch.Size([256, 256, 3, 3]), the OT cost is  457.80353805422783\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer3.1.conv2.weight, frobenius norm from the joe's transport map is 0.06237781047821045\n",
      "shape of T_var is  torch.Size([256, 256])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237668916583061 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([256, 256, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 15 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([256, 256, 3, 3])\n",
      "In layer model.layer4.0.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 45.764949798583984, Mean : 5.119429588317871, Min : 1.5218049611576134e-06, Std: 7.348784923553467\n",
      "At layer idx 15 and shape torch.Size([512, 256, 3, 3]), the OT cost is  209.7591278301552\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer4.0.conv1.weight, frobenius norm from the joe's transport map is 0.04415099322795868\n",
      "shape of T_var is  torch.Size([512, 512])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999488592147827, min 0.0, mean 0.0019530252320691943, std 0.044148821383714676 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([512, 256, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 16 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([512, 256, 3, 3])\n",
      "In layer model.layer4.0.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 56.04124450683594, Mean : 5.177221298217773, Min : 0.0, Std: 8.666240692138672\n",
      "At layer idx 16 and shape torch.Size([512, 512, 3, 3]), the OT cost is  239.73762119188905\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer4.0.conv2.weight, frobenius norm from the joe's transport map is 0.04415099322795868\n",
      "shape of T_var is  torch.Size([512, 512])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999488592147827, min 0.0, mean 0.0019530252320691943, std 0.044148821383714676 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([512, 512, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 17 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([512, 512, 3, 3])\n",
      "In layer model.layer4.0.shortcut.0.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 14.415651321411133, Mean : 2.195932388305664, Min : 0.03136086091399193, Std: 2.3712339401245117\n",
      "At layer idx 17 and shape torch.Size([512, 256, 1, 1]), the OT cost is  72.37461720220745\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer4.0.shortcut.0.weight, frobenius norm from the joe's transport map is 0.04415099322795868\n",
      "shape of T_var is  torch.Size([512, 512])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999488592147827, min 0.0, mean 0.0019530252320691943, std 0.044148821383714676 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([512, 256, 1])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 18 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([512, 256, 1, 1])\n",
      "In layer model.layer4.1.conv1.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 32.68023681640625, Mean : 3.8710429668426514, Min : 0.0005486096488311887, Std: 5.199133396148682\n",
      "averaging multiple T_var's\n",
      "At layer idx 18 and shape torch.Size([512, 512, 3, 3]), the OT cost is  153.7929102871567\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer4.1.conv1.weight, frobenius norm from the joe's transport map is 0.04415099322795868\n",
      "shape of T_var is  torch.Size([512, 512])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999488592147827, min 0.0, mean 0.0019530252320691943, std 0.044148821383714676 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([512, 512, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 19 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([512, 512, 3, 3])\n",
      "In layer model.layer4.1.conv2.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 44.1590576171875, Mean : 2.1650478839874268, Min : 0.0, Std: 5.868391990661621\n",
      "At layer idx 19 and shape torch.Size([512, 512, 3, 3]), the OT cost is  156.34385628253222\n",
      "Tmap stats (before correction) \n",
      ": For layer model.layer4.1.conv2.weight, frobenius norm from the joe's transport map is 0.04415099322795868\n",
      "shape of T_var is  torch.Size([512, 512])\n",
      "T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "T_var stats: max 0.9999488592147827, min 0.0, mean 0.0019530252320691943, std 0.044148821383714676 \n",
      "the transport map is  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Shape of aligned wt is  torch.Size([512, 512, 9])\n",
      "NUM LAYERS:  21\n",
      "\n",
      "--------------- At layer index 20 ------------- \n",
      " \n",
      "Previous layer shape is  torch.Size([512, 512, 3, 3])\n",
      "In layer model.fc.weight: getting activation distance statistics\n",
      "Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n",
      "\n",
      "Max : 295.52435302734375, Mean : 210.2861328125, Min : 56.560768127441406, Std: 70.7886734008789\n",
      "At layer idx 20 and shape torch.Size([10, 512]), the OT cost is  56.56077194213867\n",
      "Tmap stats (before correction) \n",
      ": For layer model.fc.weight, frobenius norm from the joe's transport map is 0.30000001192092896\n",
      "shape of T_var is  torch.Size([10, 10])\n",
      "T_var before correction  tensor([[0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.1000]])\n",
      "T_var after correction  tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]])\n",
      "T_var stats: max 0.9999990463256836, min 0.0, mean 0.09999990463256836, std 0.3015110492706299 \n",
      "the transport map is  tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]])\n",
      "Shape of aligned wt is  torch.Size([10, 512])\n",
      "EXIT\n",
      "len of model_state_dict is  21\n",
      "len of new_params is  21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240108_214552-k1xvppgv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/model-fusion/Model%20Fusion/runs/k1xvppgv' target=\"_blank\">resnet18_cifar10_batch_size_128_aligned_modelA</a></strong> to <a href='https://wandb.ai/model-fusion/Model%20Fusion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/model-fusion/Model%20Fusion' target=\"_blank\">https://wandb.ai/model-fusion/Model%20Fusion</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/model-fusion/Model%20Fusion/runs/k1xvppgv' target=\"_blank\">https://wandb.ai/model-fusion/Model%20Fusion/runs/k1xvppgv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 79/79 [00:03<00:00, 23.59it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy          0.6365000009536743\n",
      "        val_loss            1.0784363746643066\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>trainer/global_step</td><td>0</td></tr><tr><td>val_accuracy</td><td>0.6365</td></tr><tr><td>val_loss</td><td>1.07844</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18_cifar10_batch_size_128_aligned_modelA</strong> at: <a href='https://wandb.ai/model-fusion/Model%20Fusion/runs/k1xvppgv' target=\"_blank\">https://wandb.ai/model-fusion/Model%20Fusion/runs/k1xvppgv</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240108_214552-k1xvppgv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# model parameters:  21\n",
      "# new parameters:  21\n",
      "fusing:  model.conv1.weight\n",
      "fusing:  model.layer1.0.conv1.weight\n",
      "fusing:  model.layer1.0.conv2.weight\n",
      "fusing:  model.layer1.1.conv1.weight\n",
      "fusing:  model.layer1.1.conv2.weight\n",
      "fusing:  model.layer2.0.conv1.weight\n",
      "fusing:  model.layer2.0.conv2.weight\n",
      "fusing:  model.layer2.0.shortcut.0.weight\n",
      "fusing:  model.layer2.1.conv1.weight\n",
      "fusing:  model.layer2.1.conv2.weight\n",
      "fusing:  model.layer3.0.conv1.weight\n",
      "fusing:  model.layer3.0.conv2.weight\n",
      "fusing:  model.layer3.0.shortcut.0.weight\n",
      "fusing:  model.layer3.1.conv1.weight\n",
      "fusing:  model.layer3.1.conv2.weight\n",
      "fusing:  model.layer4.0.conv1.weight\n",
      "fusing:  model.layer4.0.conv2.weight\n",
      "fusing:  model.layer4.0.shortcut.0.weight\n",
      "fusing:  model.layer4.1.conv1.weight\n",
      "fusing:  model.layer4.1.conv2.weight\n",
      "fusing:  model.fc.weight\n",
      "------- Evaluating ot fusion model -------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240108_214604-rfsdlc9v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/model-fusion/Model%20Fusion/runs/rfsdlc9v' target=\"_blank\">resnet18_cifar10_batch_size_128_ot_model_fusion-3bsofnmw-q2135wcz</a></strong> to <a href='https://wandb.ai/model-fusion/Model%20Fusion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/model-fusion/Model%20Fusion' target=\"_blank\">https://wandb.ai/model-fusion/Model%20Fusion</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/model-fusion/Model%20Fusion/runs/rfsdlc9v' target=\"_blank\">https://wandb.ai/model-fusion/Model%20Fusion/runs/rfsdlc9v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 79/79 [00:03<00:00, 22.75it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy           0.682200014591217\n",
      "        val_loss             1.075196623802185\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>trainer/global_step</td><td>0</td></tr><tr><td>val_accuracy</td><td>0.6822</td></tr><tr><td>val_loss</td><td>1.0752</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18_cifar10_batch_size_128_ot_model_fusion-3bsofnmw-q2135wcz</strong> at: <a href='https://wandb.ai/model-fusion/Model%20Fusion/runs/rfsdlc9v' target=\"_blank\">https://wandb.ai/model-fusion/Model%20Fusion/runs/rfsdlc9v</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240108_214604-rfsdlc9v\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OT model fusion + eval aligned model \n",
    "print(\"------- Computing model fusion -------\")\n",
    "\n",
    "wandb_tag = f\"ot_model_fusion-{runA}-{runB}\"\n",
    "\n",
    "ot_fused_model, modelA_aligned = otfusion_experiment.run_otfusion(\n",
    "    batch_size=batch_size,\n",
    "    datamodule_type=datamodule_type,\n",
    "    datamodule_hparams=datamodule_hparams,\n",
    "    model_type=model_type, \n",
    "    model_hparams=model_hparams,\n",
    "    modelA=modelA,\n",
    "    modelB=modelB,\n",
    "    wandb_tag=wandb_tag\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Computing LMC barrier after alignment -------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Alpha: 0.00 (model 2), Train average loss: 0.04328 Train barrier:  0\n",
      "Alpha: 1.00 (model 1), Train average loss: 0.95617 Train barrier:  0\n",
      "Alpha: 0.05, Train average loss: 0.05390 Train barrier -0.035025597523550195\n",
      "Alpha: 0.10, Train average loss: 0.07881 Train barrier -0.055758693835271725\n",
      "Alpha: 0.15, Train average loss: 0.12367 Train barrier -0.056544274060626856\n",
      "Alpha: 0.20, Train average loss: 0.19438 Train barrier -0.031476646167967054\n",
      "Alpha: 0.25, Train average loss: 0.29530 Train barrier 0.023795330474277343\n",
      "Alpha: 0.30, Train average loss: 0.42639 Train barrier 0.10923918507556113\n",
      "Alpha: 0.35, Train average loss: 0.58044 Train barrier 0.2176483568731613\n",
      "Alpha: 0.40, Train average loss: 0.74418 Train barrier 0.3357373729495208\n",
      "Alpha: 0.45, Train average loss: 0.90107 Train barrier 0.4469837386759453\n",
      "Alpha: 0.50, Train average loss: 1.03669 Train barrier 0.536964882923166\n",
      "Alpha: 0.55, Train average loss: 1.14167 Train barrier 0.5962937540770569\n",
      "Alpha: 0.60, Train average loss: 1.21229 Train barrier 0.6212747203474573\n",
      "Alpha: 0.65, Train average loss: 1.24928 Train barrier 0.612622675584058\n",
      "Alpha: 0.70, Train average loss: 1.25487 Train barrier 0.5725610275957983\n",
      "Alpha: 0.75, Train average loss: 1.23299 Train barrier 0.5050391269304686\n",
      "Alpha: 0.80, Train average loss: 1.18909 Train barrier 0.4155010671015581\n",
      "Alpha: 0.85, Train average loss: 1.13008 Train barrier 0.3108378212213846\n",
      "Alpha: 0.90, Train average loss: 1.06431 Train barrier 0.199428187859522\n",
      "Alpha: 0.95, Train average loss: 1.00251 Train barrier 0.09198324387957635\n",
      "Loss model 1: 0.95617, Loss model 2: 0.04328, Alpha argmax: 0.60000\n",
      "Barrier: 0.62127\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Vanilla loss pre fine-tuning: 2.2892928655836315\n",
      "Fused loss pre fine-tuning: 1.0366860948350693\n"
     ]
    }
   ],
   "source": [
    "# LMC barrier\n",
    "print(\"------- Computing LMC barrier after alignment -------\")\n",
    "\n",
    "lmc_experiment.run_lmc(\n",
    "    datamodule_type=datamodule_type,\n",
    "    modelA=modelA_aligned,\n",
    "    modelB=modelB,\n",
    "    granularity=21\n",
    ")\n",
    "\n",
    "# Losses for ot fusion model and vanilla averaging model\n",
    "datamodule_hparams_lmc = {'batch_size': 1024, 'data_dir': BASE_DATA_DIR}\n",
    "datamodule_lmc = datamodule_type.get_data_module(**datamodule_hparams)\n",
    "datamodule_lmc.prepare_data()\n",
    "datamodule_lmc.setup('fit')\n",
    "\n",
    "vanilla_loss = lmc_utils.compute_loss(vanilla_averaging_model, datamodule_lmc)\n",
    "fused_loss = lmc_utils.compute_loss(ot_fused_model, datamodule_lmc)\n",
    "\n",
    "print(f\"Vanilla loss pre fine-tuning: {vanilla_loss}\")\n",
    "print(f\"Fused loss pre fine-tuning: {fused_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuning ot fusion model\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "from model_fusion.train import get_wandb_logger\n",
    "\n",
    "_, datamodule, trainer = None, None, None\n",
    "\n",
    "min_epochs = 50\n",
    "max_epochs = 100\n",
    "datamodule_hparams['batch_size'] = 128\n",
    "datamodule_hparams['data_augmentation']=True\n",
    "\n",
    "datamodule = datamodule_type.get_data_module(**datamodule_hparams)\n",
    "lightning_params = {'optimizer': 'sgd', 'lr': 0.075, 'momentum': 0.9, 'weight_decay': 0.0001, 'lr_scheduler': 'plateau', 'lr_decay_factor': 0.5, 'lr_monitor_metric': 'val_loss'}\n",
    "otfused_lit_model = BaseModel(model_type=model_type, model_hparams=model_hparams, model=copy.deepcopy(ot_fused_model.model), **lightning_params)\n",
    "\n",
    "logger_config = {'model_hparams': model_hparams} | {'datamodule_hparams': datamodule_hparams} | {'lightning_params': lightning_params} | {'min_epochs': min_epochs, 'max_epochs': max_epochs, 'model_type': model_type, 'datamodule_type': datamodule_type, 'early_stopping': True}\n",
    "logger = get_wandb_logger(\"otfusion finetuning\", logger_config, [])\n",
    "callbacks = []\n",
    "monitor = 'val_loss'\n",
    "patience = 20\n",
    "callbacks.append(EarlyStopping(monitor=monitor, patience=patience))\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"val_accuracy\", mode=\"max\")\n",
    "callbacks.append(checkpoint_callback)\n",
    "trainer = lightning.Trainer(min_epochs=min_epochs, max_epochs=max_epochs, logger=logger, callbacks=callbacks, deterministic='warn')\n",
    "\n",
    "\n",
    "datamodule.prepare_data()\n",
    "\n",
    "datamodule.setup('fit')\n",
    "\n",
    "trainer.fit(otfused_lit_model, train_dataloaders=datamodule.train_dataloader(), val_dataloaders=datamodule.val_dataloader())\n",
    "\n",
    "datamodule.setup('test')\n",
    "trainer.test(otfused_lit_model, dataloaders=datamodule.test_dataloader())\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240108_230638-30nfxxwe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/model-fusion/Model%20Fusion/runs/30nfxxwe' target=\"_blank\">vanilla finetuning</a></strong> to <a href='https://wandb.ai/model-fusion/Model%20Fusion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/model-fusion/Model%20Fusion' target=\"_blank\">https://wandb.ai/model-fusion/Model%20Fusion</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/model-fusion/Model%20Fusion/runs/30nfxxwe' target=\"_blank\">https://wandb.ai/model-fusion/Model%20Fusion/runs/30nfxxwe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:43: attribute 'model' removed from hparams because it cannot be pickled\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type               | Params\n",
      "---------------------------------------------------\n",
      "0 | loss_module | CrossEntropyLoss   | 0     \n",
      "1 | accuracy    | MulticlassAccuracy | 0     \n",
      "2 | model       | ResNet             | 11.2 M\n",
      "---------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.657    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SGD optimizer with lr=0.05, momentum=0.9, weight_decay=0.0001, nesterov=False\n",
      "Using ReduceLROnPlateau with lr_decay_factor=0.5 and lr_monitor_metric=val_loss\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ..\\aten\\src\\ATen\\Context.cpp:156.)\n",
      "  return F.linear(input, self.weight, self.bias)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   1%|          | 2/352 [00:00<00:29, 11.88it/s, v_num=xxwe, train_loss=2.300, train_accuracy=0.0781]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:251: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ..\\aten\\src\\ATen\\Context.cpp:156.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 352/352 [00:36<00:00,  9.57it/s, v_num=xxwe, train_loss=0.382, train_accuracy=0.889, val_loss=0.412, val_accuracy=0.880, avg_train_loss=0.147] Epoch 00012: reducing learning rate of group 0 to 2.5000e-02.\n",
      "Epoch 20: 100%|██████████| 352/352 [00:37<00:00,  9.33it/s, v_num=xxwe, train_loss=0.0168, train_accuracy=1.000, val_loss=0.391, val_accuracy=0.912, avg_train_loss=0.0423] Epoch 00021: reducing learning rate of group 0 to 1.2500e-02.\n",
      "Epoch 28: 100%|██████████| 352/352 [00:36<00:00,  9.64it/s, v_num=xxwe, train_loss=0.00485, train_accuracy=1.000, val_loss=0.416, val_accuracy=0.920, avg_train_loss=0.0161] Epoch 00029: reducing learning rate of group 0 to 6.2500e-03.\n",
      "Epoch 33:   0%|          | 0/352 [00:00<?, ?it/s, v_num=xxwe, train_loss=0.0357, train_accuracy=0.986, val_loss=0.421, val_accuracy=0.923, avg_train_loss=0.00846]            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer was signaled to stop but the required `min_epochs=50` or `min_steps=None` has not been met. Training will continue...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 352/352 [00:36<00:00,  9.71it/s, v_num=xxwe, train_loss=0.00353, train_accuracy=1.000, val_loss=0.465, val_accuracy=0.919, avg_train_loss=0.00591] Epoch 00037: reducing learning rate of group 0 to 3.1250e-03.\n",
      "Epoch 44: 100%|██████████| 352/352 [00:40<00:00,  8.73it/s, v_num=xxwe, train_loss=0.0176, train_accuracy=0.986, val_loss=0.462, val_accuracy=0.922, avg_train_loss=0.00324]  Epoch 00045: reducing learning rate of group 0 to 1.5625e-03.\n",
      "Epoch 49: 100%|██████████| 352/352 [00:39<00:00,  8.87it/s, v_num=xxwe, train_loss=0.000117, train_accuracy=1.000, val_loss=0.469, val_accuracy=0.922, avg_train_loss=0.00342]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 79/79 [00:03<00:00, 24.59it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy          0.9194999933242798\n",
      "        val_loss            0.5176788568496704\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_train_loss</td><td>█▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▃▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>train_accuracy</td><td>▁▇▆██████▆███▇██████████████████████████</td></tr><tr><td>train_loss</td><td>█▃▂▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▃▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>val_accuracy</td><td>▁▃▄▆▄▅▅▆▆▅▇▇▇▇▇▇▇▇▇▇▇███▇█▇█████████████</td></tr><tr><td>val_loss</td><td>█▄▄▂▅▃▂▃▃▄▁▂▁▂▃▃▄▃▄▄▅▄▄▄▆▅▅▆▆▆▆▆▆▆▆▆▆▆▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_train_loss</td><td>0.00307</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>train_accuracy</td><td>1.0</td></tr><tr><td>train_loss</td><td>0.00012</td></tr><tr><td>trainer/global_step</td><td>17600</td></tr><tr><td>val_accuracy</td><td>0.9195</td></tr><tr><td>val_loss</td><td>0.51768</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vanilla finetuning</strong> at: <a href='https://wandb.ai/model-fusion/Model%20Fusion/runs/30nfxxwe' target=\"_blank\">https://wandb.ai/model-fusion/Model%20Fusion/runs/30nfxxwe</a><br/>Synced 5 W&B file(s), 0 media file(s), 14 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240108_230638-30nfxxwe\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#finetuning vanilla averaged model\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "from model_fusion.train import get_wandb_logger\n",
    "\n",
    "_, datamodule, trainer = None, None, None\n",
    "\n",
    "min_epochs = 50\n",
    "max_epochs = 100\n",
    "datamodule_hparams['batch_size'] = 128\n",
    "datamodule_hparams['data_augmentation']=True\n",
    "\n",
    "datamodule = datamodule_type.get_data_module(**datamodule_hparams)\n",
    "lightning_params = {'optimizer': 'sgd', 'lr': 0.05, 'momentum': 0.9, 'weight_decay': 0.0001, 'lr_scheduler': 'plateau', 'lr_decay_factor': 0.5, 'lr_monitor_metric': 'val_loss'}\n",
    "\n",
    "vanilla_averaged_lit_model = BaseModel(model_type=model_type, model_hparams=model_hparams, model=copy.deepcopy(vanilla_averaging_model.model), **lightning_params)\n",
    "\n",
    "logger_config = {'model_hparams': model_hparams} | {'datamodule_hparams': datamodule_hparams} | {'lightning_params': lightning_params} | {'min_epochs': min_epochs, 'max_epochs': max_epochs, 'model_type': model_type, 'datamodule_type': datamodule_type, 'early_stopping': True}\n",
    "logger = get_wandb_logger(\"vanilla finetuning\", logger_config, [])\n",
    "callbacks = []\n",
    "monitor = 'val_loss'\n",
    "patience = 20\n",
    "callbacks.append(EarlyStopping(monitor=monitor, patience=patience))\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"val_accuracy\", mode=\"max\")\n",
    "callbacks.append(checkpoint_callback)\n",
    "trainer = lightning.Trainer(min_epochs=min_epochs, max_epochs=max_epochs, logger=logger, callbacks=callbacks, deterministic='warn')\n",
    "\n",
    "\n",
    "datamodule.prepare_data()\n",
    "\n",
    "datamodule.setup('fit')\n",
    "\n",
    "\n",
    "trainer.fit(vanilla_averaged_lit_model, train_dataloaders=datamodule.train_dataloader(), val_dataloaders=datamodule.val_dataloader())\n",
    "\n",
    "datamodule.setup('test')\n",
    "\n",
    "trainer.test(vanilla_averaged_lit_model, dataloaders=datamodule.test_dataloader())\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.05, 'model': None, 'momentum': 0.9, 'optimizer': 'sgd', 'max_epochs': 100, 'min_epochs': 50, 'model_type': 'ModelType.RESNET18', 'loss_module': 'CrossEntropyLoss', 'lr_scheduler': 'plateau', 'weight_decay': 0.0001, 'model_hparams': {'bias': False, 'num_classes': 10, 'num_channels': 3}, 'early_stopping': True, 'datamodule_type': 'DataModuleType.CIFAR10', 'lr_decay_factor': 0.5, 'lightning_params': {'lr': 0.05, 'momentum': 0.9, 'optimizer': 'sgd', 'lr_scheduler': 'plateau', 'weight_decay': 0.0001, 'lr_decay_factor': 0.5, 'lr_monitor_metric': 'val_loss'}, 'lr_monitor_metric': 'val_loss', 'datamodule_hparams': {'seed': 42, 'data_dir': 'data', 'batch_size': 128, 'data_augmentation': True}, 'model_hparams/bias': False, 'model_hparams/num_classes': 10, 'model_hparams/num_channels': 3}\n",
      "{'seed': 42, 'data_dir': 'data', 'batch_size': 128, 'data_augmentation': False}\n",
      "{'bias': False, 'num_classes': 10, 'num_channels': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\Notebooks\\wandb\\run-20240108_230604-0kmoqffb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/model-fusion/model-fusion/runs/0kmoqffb' target=\"_blank\">revived-star-119</a></strong> to <a href='https://wandb.ai/model-fusion/model-fusion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/model-fusion/model-fusion' target=\"_blank\">https://wandb.ai/model-fusion/model-fusion</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/model-fusion/model-fusion/runs/0kmoqffb' target=\"_blank\">https://wandb.ai/model-fusion/model-fusion/runs/0kmoqffb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-8z426q3y:best_k, 85.20MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.4\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:395: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ..\\aten\\src\\ATen\\Context.cpp:156.)\n",
      "  return F.linear(input, self.weight, self.bias)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 79/79 [00:02<00:00, 27.37it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy          0.9229000210762024\n",
      "        val_loss            0.4678650498390198\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>trainer/global_step</td><td>0</td></tr><tr><td>val_accuracy</td><td>0.9229</td></tr><tr><td>val_loss</td><td>0.46787</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">revived-star-119</strong> at: <a href='https://wandb.ai/model-fusion/model-fusion/runs/0kmoqffb' target=\"_blank\">https://wandb.ai/model-fusion/model-fusion/runs/0kmoqffb</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240108_230604-0kmoqffb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuned otfusion loss: 0.002464196097915475\n"
     ]
    }
   ],
   "source": [
    "#Testing ot fused model finetuned\n",
    "runFT = '8z426q3y'\n",
    "\n",
    "api = wandb.Api()\n",
    "run = api.run(f'model-fusion/Model Fusion/{runFT}')\n",
    "\n",
    "print(run.config)\n",
    "\n",
    "batch_size = run.config['datamodule_hparams'].get('batch_size')\n",
    "\n",
    "datamodule_type_str = run.config['datamodule_type'].split('.')[1].lower()\n",
    "datamodule_type = DataModuleType(datamodule_type_str)\n",
    "datamodule_hparams = run.config['datamodule_hparams']\n",
    "datamodule_hparams['data_augmentation'] = False\n",
    "\n",
    "model_type_str = run.config['model_type'].split('.')[1].lower()\n",
    "model_type = ModelType(model_type_str)\n",
    "\n",
    "model_hparams = run.config['model_hparams']\n",
    "\n",
    "print(datamodule_hparams)\n",
    "print(model_hparams)\n",
    "\n",
    "checkpointFT = f'model-fusion/Model Fusion/model-{runFT}:best_k'\n",
    "\n",
    "\n",
    "run = wandb.init()\n",
    "\n",
    "artifact = run.use_artifact(checkpointFT, type='model')\n",
    "artifact_dir = artifact.download(root=CHECKPOINT_DIR)\n",
    "otfused_lit_model = BaseModel.load_from_checkpoint(Path(artifact_dir)/\"model.ckpt\")\n",
    "wandb_tags = [f\"{model_type.value}\", f\"{datamodule_type.value}\"]\n",
    "\n",
    "datamodule, trainer = setup_testing(f'eval finetuning {runFT}', model_type, model_hparams, datamodule_type, datamodule_hparams, wandb_tags)\n",
    "\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup('test')\n",
    "\n",
    "trainer.test(otfused_lit_model, dataloaders=datamodule.test_dataloader())\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "finetuned_loss = lmc_utils.compute_loss(otfused_lit_model, datamodule_lmc)\n",
    "\n",
    "print(f\"Finetuned otfusion loss: {finetuned_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.05, 'model': None, 'momentum': 0.9, 'optimizer': 'sgd', 'max_epochs': 100, 'min_epochs': 50, 'model_type': 'ModelType.RESNET18', 'loss_module': 'CrossEntropyLoss', 'lr_scheduler': 'plateau', 'weight_decay': 0.0001, 'model_hparams': {'bias': False, 'num_classes': 10, 'num_channels': 3}, 'early_stopping': True, 'datamodule_type': 'DataModuleType.CIFAR10', 'lr_decay_factor': 0.5, 'lightning_params': {'lr': 0.05, 'momentum': 0.9, 'optimizer': 'sgd', 'lr_scheduler': 'plateau', 'weight_decay': 0.0001, 'lr_decay_factor': 0.5, 'lr_monitor_metric': 'val_loss'}, 'lr_monitor_metric': 'val_loss', 'datamodule_hparams': {'seed': 42, 'data_dir': 'data', 'batch_size': 128, 'data_augmentation': True}, 'model_hparams/bias': False, 'model_hparams/num_classes': 10, 'model_hparams/num_channels': 3}\n",
      "{'seed': 42, 'data_dir': 'data', 'batch_size': 128, 'data_augmentation': False}\n",
      "{'bias': False, 'num_classes': 10, 'num_channels': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\Notebooks\\wandb\\run-20240108_233923-ojknf6bs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/model-fusion/model-fusion/runs/ojknf6bs' target=\"_blank\">true-planet-120</a></strong> to <a href='https://wandb.ai/model-fusion/model-fusion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/model-fusion/model-fusion' target=\"_blank\">https://wandb.ai/model-fusion/model-fusion</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/model-fusion/model-fusion/runs/ojknf6bs' target=\"_blank\">https://wandb.ai/model-fusion/model-fusion/runs/ojknf6bs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-30nfxxwe:best_k, 85.20MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.4\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:395: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ..\\aten\\src\\ATen\\Context.cpp:156.)\n",
      "  return F.linear(input, self.weight, self.bias)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 79/79 [00:02<00:00, 29.30it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy          0.9175000190734863\n",
      "        val_loss            0.4851283133029938\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>trainer/global_step</td><td>0</td></tr><tr><td>val_accuracy</td><td>0.9175</td></tr><tr><td>val_loss</td><td>0.48513</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">true-planet-120</strong> at: <a href='https://wandb.ai/model-fusion/model-fusion/runs/ojknf6bs' target=\"_blank\">https://wandb.ai/model-fusion/model-fusion/runs/ojknf6bs</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240108_233923-ojknf6bs\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuned vanilla loss: 0.0040679713185462684\n"
     ]
    }
   ],
   "source": [
    "#Testing vanilla model finetuned\n",
    "runFT = '30nfxxwe'\n",
    "\n",
    "api = wandb.Api()\n",
    "run = api.run(f'model-fusion/Model Fusion/{runFT}')\n",
    "\n",
    "print(run.config)\n",
    "\n",
    "batch_size = run.config['datamodule_hparams'].get('batch_size')\n",
    "\n",
    "datamodule_type_str = run.config['datamodule_type'].split('.')[1].lower()\n",
    "datamodule_type = DataModuleType(datamodule_type_str)\n",
    "datamodule_hparams = run.config['datamodule_hparams']\n",
    "datamodule_hparams['data_augmentation'] = False\n",
    "\n",
    "model_type_str = run.config['model_type'].split('.')[1].lower()\n",
    "model_type = ModelType(model_type_str)\n",
    "\n",
    "model_hparams = run.config['model_hparams']\n",
    "\n",
    "print(datamodule_hparams)\n",
    "print(model_hparams)\n",
    "\n",
    "checkpointFT = f'model-fusion/Model Fusion/model-{runFT}:best_k'\n",
    "\n",
    "\n",
    "run = wandb.init()\n",
    "\n",
    "artifact = run.use_artifact(checkpointFT, type='model')\n",
    "artifact_dir = artifact.download(root=CHECKPOINT_DIR)\n",
    "vanilla_averaged_lit_model = BaseModel.load_from_checkpoint(Path(artifact_dir)/\"model.ckpt\")\n",
    "wandb_tags = [f\"{model_type.value}\", f\"{datamodule_type.value}\"]\n",
    "\n",
    "datamodule, trainer = setup_testing(f'eval finetuning {runFT}', model_type, model_hparams, datamodule_type, datamodule_hparams, wandb_tags)\n",
    "\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup('test')\n",
    "\n",
    "trainer.test(vanilla_averaged_lit_model, dataloaders=datamodule.test_dataloader())\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "finetuned_loss = lmc_utils.compute_loss(vanilla_averaged_lit_model, datamodule_lmc)\n",
    "\n",
    "print(f\"Finetuned vanilla loss: {finetuned_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Computing sharpness -------\n",
      "------- Model A -------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ..\\aten\\src\\ATen\\Context.cpp:156.)\n",
      "  return F.linear(input, self.weight, self.bias)\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:251: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at ..\\torch\\csrc\\autograd\\engine.cpp:1176.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:251: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ..\\aten\\src\\ATen\\Context.cpp:156.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\filos\\OneDrive\\Desktop\\ETH\\model-fusion\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:394: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ..\\aten\\src\\ATen\\Context.cpp:156.)\n",
      "  result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top Hessian eigenvalue of this model is 2.3668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***Trace:  106.25458991009256\n",
      "------- Model B -------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "The top Hessian eigenvalue of this model is 2.0943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***Trace:  119.8628892444429\n",
      "------- OT fusion model -------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "The top Hessian eigenvalue of this model is 3.8854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***Trace:  129.57992662702287\n",
      "------- Vanilla avg model (finetuned) -------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "The top Hessian eigenvalue of this model is 4.3197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***Trace:  50.977541716202445\n",
      "------- OT fusion model (finetuned) -------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "The top Hessian eigenvalue of this model is 2.5734\n",
      "\n",
      "***Trace:  42.14937800168991\n"
     ]
    }
   ],
   "source": [
    "# Pyhessian (compute sharpness and eigenspectrum of base models, vanilla avg, ot fusion and finetuned solutions)\n",
    "print(\"------- Computing sharpness -------\")\n",
    "\n",
    "print(\"------- Model A -------\")\n",
    "hessian_comp = pyhessian_experiment.run_pyhessian(datamodule_type=datamodule_type, model=modelA,  compute_density=False, figure_name='modelA.pdf') \n",
    "print(\"------- Model B -------\")\n",
    "hessian_comp = pyhessian_experiment.run_pyhessian(datamodule_type=datamodule_type, model=modelB, compute_density=False, figure_name='modelB.pdf')\n",
    "\n",
    "#print(\"------- Model A aligned to B -------\")\n",
    "#hessian_comp = pyhessian_experiment.run_pyhessian(datamodule_type=datamodule_type,model=modelA_aligned,  compute_density=False, figure_name='modelA_aligned.pdf')\n",
    "\n",
    "print(\"------- OT fusion model -------\")\n",
    "hessian_comp = pyhessian_experiment.run_pyhessian(datamodule_type=datamodule_type, model=ot_fused_model,  compute_density=False, figure_name='otmodel128.pdf')\n",
    "\n",
    "print(\"------- Vanilla avg model (finetuned) -------\")\n",
    "hessian_comp = pyhessian_experiment.run_pyhessian(datamodule_type=datamodule_type,model=vanilla_averaged_lit_model, compute_density=False, figure_name='vanilla_finetuned128.pdf')\n",
    "\n",
    "print(\"------- OT fusion model (finetuned) -------\")\n",
    "hessian_comp = pyhessian_experiment.run_pyhessian(datamodule_type=datamodule_type, model=otfused_lit_model,  compute_density=False, figure_name='otmodel_finetuned128.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
