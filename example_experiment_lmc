import wandb

from model_fusion.train import setup_training
from model_fusion.datasets import DataModuleType
from model_fusion.models import ModelType
import lmc_utils as lmc


def run_experiment():
    data_module_type = DataModuleType.MNIST
    data_module_hparams1 = {'batch_size': 16}
    data_module_hparams2 = {'batch_size': 32}


    model_type = ModelType.RESNET18
    model_hparams = {'num_classes': 10, 'num_channels': 1}

    wandb_tags = ['example']

    model1, datamodule1, trainer1 = setup_training('example_experiment', model_type, model_hparams, data_module_type, data_module_hparams1, max_epochs=1, wandb_tags=wandb_tags)
    model2, datamodule2, trainer2 = setup_training('example_experiment', model_type, model_hparams, data_module_type, data_module_hparams2, max_epochs=1, wandb_tags=wandb_tags)

    trainer1.fit(model1, datamodule=datamodule1)
    trainer2.fit(model2, datamodule=datamodule2)

    loss_model1,loss_model2,max_loss, alpha_max = lmc.compute_losses_and_barrier(model1,model2, datamodule2,granularity=5)
    print(f"Loss model 1: {loss_model1:.5f}, Loss model 2: {loss_model2:.5f}, Alpha argmax: {alpha_max:.5f}")
    convex_max_loss = alpha_max*loss_model1 + (1-alpha_max)*loss_model2
    error_barrier = max_loss - convex_max_loss
    print(f"Max loss: {max_loss:.5f}, Convex loss for alpha argmax: {convex_max_loss:.5f}, Error barrier: {error_barrier:.5f}")

    wandb.finish()


if __name__ == '__main__':
    run_experiment()
